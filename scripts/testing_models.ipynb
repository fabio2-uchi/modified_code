{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init pack\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.nn.parallel import DataParallel\n",
    "\n",
    "psi = np.load('/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy')\n",
    "\n",
    "psi = psi[:,1,:]\n",
    "\n",
    "# Normalization\n",
    "mean_psi = np.mean(psi, axis=0, keepdims=True)\n",
    "std_psi = np.std(psi, axis=0, keepdims=True)\n",
    "psi = (psi - mean_psi) / std_psi\n",
    "\n",
    "# Pre-processing\n",
    "lead = 1\n",
    "\n",
    "trainN = 250000\n",
    "valN = 50000\n",
    "index = 63\n",
    "\n",
    "variable_range = [(0,24), (25, 49), (50, 74), (0, 49), (0,74)]\n",
    "\n",
    "# Select the variable: 0 for real perturbation, 1 for imaginary perturbation, 2 for zonal winds\n",
    "variable = 3\n",
    "num_variables = variable_range[variable][1] - variable_range[variable][0] + 1\n",
    "\n",
    "print(psi.shape)\n",
    "\n",
    "np_psi_train_input = psi[0:trainN, variable_range[variable][0]:variable_range[variable][1]+1]\n",
    "plt.plot(np_psi_train_input[:, -1])\n",
    "\n",
    "np_psi_train_label = psi[lead:trainN+lead, :]\n",
    "\n",
    "psi_train_input = torch.tensor(np_psi_train_input)\n",
    "psi_train_label =  torch.tensor(np_psi_train_label)\n",
    "\n",
    "# Make sure input and label lengths match\n",
    "assert psi_train_input.shape[0] == psi_train_label.shape[0], \"Input and label length mismatch\"\n",
    "\n",
    "#shuffle and map indices\\\n",
    "valid_indices = np.arange(0, trainN - lead)\n",
    "np.random.seed(42)  # Optional for reproducibility\n",
    "shuffled_indices = np.random.permutation(valid_indices)\n",
    "\n",
    "np_psi_train_input = psi[shuffled_indices, variable_range[variable][0]:variable_range[variable][1]+1]\n",
    "np_psi_train_label = psi[shuffled_indices + lead, :]\n",
    "\n",
    "psi_train_input = torch.tensor(np_psi_train_input)\n",
    "psi_train_label = torch.tensor(np_psi_train_label)\n",
    "\n",
    "t = shuffled_indices[0]\n",
    "print(torch.allclose(psi_train_input[0], torch.tensor(psi[t, variable_range[variable][0]:variable_range[variable][1]+1])))\n",
    "print(torch.allclose(psi_train_label[0], torch.tensor(psi[t + 1])))\n",
    "\n",
    "np_psi_val_input = psi[trainN:trainN+valN, variable_range[variable][0]:variable_range[variable][1]+1]\n",
    "np_psi_val_label = psi[trainN+lead:trainN+valN+lead, :]\n",
    "psi_val_input = torch.tensor(np_psi_val_input)\n",
    "psi_val_label =  torch.tensor(np_psi_val_label)\n",
    "\n",
    "print(psi_train_input.shape)\n",
    "print(psi_train_label.shape)\n",
    "print(psi_val_input.shape)\n",
    "print(psi_val_label.shape)\n",
    "plt.plot(np_psi_val_input[:,-1])\n",
    "plt.plot(np_psi_val_label[:,-1])\n",
    "plt.show()\n",
    "# plt.plot(psi_val_input[0:50000,63])# Init pack\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "psi = np.load('/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy')\n",
    "\n",
    "# Pre-processing\n",
    "\n",
    "lead = 1\n",
    "\n",
    "trainN = 200000\n",
    "valN = 50000\n",
    "index = 63\n",
    "\n",
    "psi = psi[:,1,:]\n",
    "\n",
    "print(psi.shape)\n",
    "mean_psi = np.mean(psi, axis=0, keepdims=True)\n",
    "std_psi = np.std(psi, axis=0, keepdims=True)\n",
    "psi = (psi - mean_psi) / std_psi\n",
    "\n",
    "psi_train_input = torch.tensor(psi[0:trainN,:])\n",
    "psi_train_label =  torch.tensor(psi[lead:trainN+lead,:])\n",
    "\n",
    "# Make sure input and label lengths match\n",
    "assert psi_train_input.shape[0] == psi_train_label.shape[0], \"Input and label length mismatch\"\n",
    "\n",
    "#shuffle and map indices\\\n",
    "valid_indices = np.arange(0, trainN - lead)\n",
    "np.random.seed(42)  # Optional for reproducibility\n",
    "shuffled_indices = np.random.permutation(valid_indices)\n",
    "psi_train_input = torch.tensor(psi[shuffled_indices, :])\n",
    "psi_train_label = torch.tensor(psi[shuffled_indices + lead, :])\n",
    "\n",
    "\n",
    "t = shuffled_indices[0]\n",
    "print(torch.allclose(psi_train_input[0], torch.tensor(psi[t])))\n",
    "print(torch.allclose(psi_train_label[0], torch.tensor(psi[t + 1])))\n",
    "\n",
    "psi_val_input = torch.tensor(psi[trainN:trainN+valN,:])\n",
    "psi_val_label =  torch.tensor(psi[trainN+lead:trainN+valN+lead,:])\n",
    "\n",
    "print(psi_train_input.shape)\n",
    "print(psi_train_label.shape)\n",
    "print(psi_val_input.shape)\n",
    "print(psi_val_label.shape)\n",
    "\n",
    "# Define the encoder (MLP)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(75, 512)  # Input layer (2 + 2) -> Hidden layer (128)\n",
    "        self.fc2 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc3 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc4 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc5 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc6 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc_mu = nn.Linear(512, latent_dim)  # Hidden layer (128) -> Latent space (2)\n",
    "        self.fc_logvar = nn.Linear(512, latent_dim)  # Hidden layer (128) -> Log variance (2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # Activation function for hidden layer\n",
    "        x = torch.relu(self.fc2(x)) + x\n",
    "        x = torch.relu(self.fc3(x)) + x\n",
    "        x = torch.relu(self.fc4(x)) + x\n",
    "        # x = torch.relu(self.fc5(x)) + x\n",
    "        # x = torch.relu(self.fc6(x)) + x\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "# Define the decoder (MLP)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, condition_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim + condition_dim, 512)  # Input layer (2 + 2) -> Hidden layer (128)\n",
    "        self.fc2 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc3 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc4 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc5 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc6 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc_output = nn.Linear(512, output_dim)  # Hidden layer (128) -> Output layer (2)\n",
    "\n",
    "    def forward(self, z, condition):\n",
    "        z = torch.cat((z, condition), dim=1)  # Concatenate latent vector and condition\n",
    "        z = torch.relu(self.fc1(z))  # Activation function for hidden layer\n",
    "        z = torch.relu(self.fc2(z)) + z\n",
    "        z = torch.relu(self.fc3(z)) + z\n",
    "        z = torch.relu(self.fc4(z)) + z\n",
    "        # z = torch.relu(self.fc5(z)) + z\n",
    "        # z = torch.relu(self.fc6(z)) + z\n",
    "        output = self.fc_output(z)\n",
    "        return output\n",
    "\n",
    "# Define the VAE model\n",
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, condition_dim):\n",
    "        super(ConditionalVAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, output_dim, condition_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def decode(self, z, condition):\n",
    "        return self.decoder(z, condition)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        output = self.decode(z, condition)\n",
    "        return output, mu, logvar\n",
    "\n",
    "output_dim = 75\n",
    "latent_dim = 32\n",
    "condition_dim = num_variables\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a72aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "# Inference\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "latent_dim = 32\n",
    "output_dim = 75\n",
    "condition_dim = num_variables\n",
    "model = ConditionalVAE(latent_dim, output_dim, condition_dim)\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "start, end = variable_range[variable][0], variable_range[variable][1]+1\n",
    "\n",
    "# MODIFY THIS LINE FOR MODEL TESTING\n",
    "past_model = True  # Set to True if you want to load past model weights\n",
    "if past_model:\n",
    "    model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/FINETUNING_Resnet_VAE_model_DELTA_TEST_at_2025-07-01 09:18:34.540044/best_model_combined_distance_with_cycle_1_and_epoch_454.pth\"\n",
    "    if os.path.exists(model_weights_path):\n",
    "        model.load_state_dict(torch.load(model_weights_path))\n",
    "        print(f\"Model weights loaded from {model_weights_path}.\")\n",
    "\n",
    "for _ in range (0,3):\n",
    "\n",
    "    start, end = variable_range[variable][0], variable_range[variable][1]+1\n",
    "    initial_cond = torch.reshape(torch.tensor(psi[0,start:end]), [1, num_variables])\n",
    "    print(initial_cond.shape)\n",
    "    time_step = 300000\n",
    "    z = torch.zeros([1,latent_dim])\n",
    "    num_ens = 1\n",
    "    pred = np.zeros ([time_step, 75, num_ens])\n",
    "\n",
    "    for k in range (0, time_step):\n",
    "\n",
    "        for ens in range (0, num_ens):\n",
    "            if (k ==0):\n",
    "                z = torch.randn_like(z)\n",
    "                print(z.shape, initial_cond.shape)\n",
    "                y = (model.decode(z.float().cuda(non_blocking=True),initial_cond.float().cuda(non_blocking=True))).detach().cpu().numpy()\n",
    "                pred[k,:,ens] = y\n",
    "                y_denorm_contracted = (y[:, start:end] * std_psi[:, start:end] + mean_psi[:, start:end])\n",
    "                initial_cond = torch.tensor((y_denorm_contracted[:, start:end] - mean_psi[:, start:end]) / std_psi[:, start:end])\n",
    "\n",
    "            else:\n",
    "                select_ens = np.random.randint(0,num_ens,1)\n",
    "                z = torch.randn_like(z)\n",
    "                y = (model.decode(z.float().cuda(non_blocking=True),torch.reshape(torch.tensor(pred[k-1,start:end,select_ens]),[1,num_variables]).float().cuda(non_blocking=True))).detach().cpu().numpy()\n",
    "                pred[k,:, ens] = y\n",
    "                y_denorm_contracted = (y[:, start:end] * std_psi[:, start:end] + mean_psi[:, start:end])\n",
    "                initial_cond = torch.tensor((y_denorm_contracted[:, start:end] - mean_psi[:, start:end]) / std_psi[:, start:end])\n",
    "\n",
    "    # Denormalize final preds\n",
    "    pred = pred.reshape(pred.shape[0], pred.shape[1])\n",
    "    print(pred.shape, psi.shape)\n",
    "    pred_mean = pred[:300000, :] * std_psi[:, :] + mean_psi[:, :]\n",
    "    \n",
    "    # Denormalize test labels\n",
    "    actual_values = psi[:300000, :] * std_psi[:, :] + mean_psi[:, :]\n",
    "    print(actual_values)\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(pred_mean[0:30000, 63],'r')\n",
    "    plt.plot(actual_values[0:30000, 63],'b')\n",
    "    plt.grid(True)\n",
    "    plt.title(f\"Predictions vs Actual\")\n",
    "    plt.savefig(f'/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/prediction_vs_actual_{datetime.datetime.now()}.png')\n",
    "    plt.show()\n",
    "\n",
    "    # MODIFY THIS LINE FOR MODEL TESTING\n",
    "    np.save(f'/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/predictions_best_checkpoint_and_cycle_Resnet_VAE_temp.npy', pred_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAGS to determine testing\n",
    "plot_data = 1\n",
    "#what level do you want to plot\n",
    "level = 63\n",
    "CCDF = 1\n",
    "Bi_modal_distribution = 1\n",
    "single_step_profiles = 1\n",
    "#for the single_step_profiles\n",
    "NUM_SAMPLES = 5\n",
    "#what weights do you want to use?\n",
    "MODEL_PATH = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/FINETUNING_Resnet_VAE_model_DELTA_TEST_at_2025-07-01 09:18:34.540044/best_model_combined_distance_with_cycle_1_and_epoch_454.pth\"\n",
    "LEVEL = 63\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Load the data; shape = (300000, 2, 75)\n",
    "real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
    "predictions = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/predictions_best_checkpoint_and_cycle_Resnet_VAE_temp.npy\")\n",
    "\n",
    "#reshape the predictions so that it matches the real_data shape\n",
    "predictions = predictions.reshape(300000, 1, 75)\n",
    "print(predictions.shape)\n",
    "print(real_data.shape)\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S.%f\")\n",
    "folder = f\"testing_at_{timestamp}\"\n",
    "os.mkdir(folder)\n",
    "subfolders = ['timeseries', 'CCDF', 'bi_modal_distribution', 'single_step_profiles']\n",
    "# Create each subdirectory inside the main folder\n",
    "for subfolder in subfolders:\n",
    "    path = os.path.join(folder, subfolder)\n",
    "    os.mkdir(path)\n",
    "    print(f\"Created subfolder: {path}\")\n",
    "SAVE_DIR = os.path.join(folder, \"single_step_profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "model = ConditionalVAE(latent_dim, output_dim, condition_dim)\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "# MODIFY THIS LINE FOR MODEL TESTING\n",
    "model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/FINETUNING_Resnet_VAE_model_DELTA_TEST_at_2025-07-01 09:18:34.540044/best_model_combined_distance_with_cycle_1_and_epoch_454.pth\"\n",
    "\n",
    "if os.path.exists(model_weights_path):\n",
    "    model.load_state_dict(torch.load(model_weights_path))\n",
    "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
    "    \n",
    "if (plot_data):\n",
    "    #note that the value 300000 will have to change depending on the real and predictions data length\n",
    "    u_profile_real = real_data[:300000, 1, level]  # Match time length with predictions\n",
    "    u_profile_pred = predictions[:, 0, level]\n",
    "    time_steps = np.arange(len(u_profile_pred))\n",
    "\n",
    "    # === Plot ===\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.plot(time_steps, u_profile_real, label='Real Data', alpha=0.7)\n",
    "    plt.plot(time_steps, u_profile_pred, label='Predictions', linestyle='--')\n",
    "\n",
    "\n",
    "    # Labels, legend, and formatting\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('U (m/s)')\n",
    "    plt.title(f'Time Series of U at Vertical Level {level}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder, \"timeseries\")\n",
    "    save_path = os.path.join(save_path, \"real_prediction_plot\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "if (CCDF):\n",
    "    real_data_1d = real_data[:, 1, 63]  # Now shape is (309700,)\n",
    "    predictions_1d = predictions[:, 0, 63]  # shape (300000,)\n",
    "\n",
    "    # Define bounds (assuming they apply to both datasets)\n",
    "    upper_bound = 53.8 / 2.8935\n",
    "    lower_bound = 1.75 / 2.8935\n",
    "\n",
    "    # Function to calculate transition durations\n",
    "    def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
    "        times_between_transitions = []\n",
    "        transition_start = None\n",
    "        above_upper = False\n",
    "        below_lower = False\n",
    "\n",
    "        for i in range(1, len(y_values)):\n",
    "            if y_values[i] < lower_bound:  \n",
    "                below_lower = True\n",
    "                above_upper = False\n",
    "            elif y_values[i] > upper_bound:  \n",
    "                if below_lower and transition_start is not None:\n",
    "                    times_between_transitions.append(i - transition_start)\n",
    "                    transition_start = None  \n",
    "                above_upper = True\n",
    "                below_lower = False\n",
    "\n",
    "            if below_lower and transition_start is None:\n",
    "                transition_start = i\n",
    "\n",
    "        return times_between_transitions\n",
    "\n",
    "    # Compute transition durations for real data\n",
    "    real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
    "\n",
    "    # Compute transition durations for predictions data\n",
    "    pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
    "\n",
    "    # Plot setup\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # === REAL DATA CCDF AND FIT ===\n",
    "    if len(real_durations) == 0:\n",
    "        print(\"No transitions detected in real data with current bounds!\")\n",
    "    else:\n",
    "        real_data_sorted = np.sort(real_durations)\n",
    "        x_line_real = np.linspace(min(real_data_sorted), max(real_data_sorted), 100)\n",
    "        exponential_fit_real = 1/np.mean(real_data_sorted)\n",
    "        y_values_real = exponential_fit_real*x_line_real\n",
    "        plt.plot(x_line_real, y_values_real, 'b-', label=f'Real Exp Fit (slope={exponential_fit_real:.4f})', linewidth=2)\n",
    "\n",
    "    # === PREDICTIONS CCDF AND FIT ===\n",
    "    if len(pred_durations) == 0:\n",
    "        print(\"No transitions detected in predictions with current bounds!\")\n",
    "    else:\n",
    "        pred_data_sorted = np.sort(pred_durations)\n",
    "        x_line_pred = np.linspace(min(pred_data_sorted), max(pred_data_sorted), 100)\n",
    "        exponential_fit_pred = 1/np.mean(pred_data_sorted)\n",
    "        y_values_pred = exponential_fit_pred*x_line_pred\n",
    "        plt.plot(x_line_pred, y_values_pred, 'r-', label=f'Pred Exp Fit (slope={exponential_fit_pred:.4f})', linewidth=2)\n",
    "\n",
    "    print(1/np.mean(real_data_sorted))\n",
    "    print(1/np.mean(pred_data_sorted))\n",
    "    # Plot labels and formatting\n",
    "    plt.xlabel('Time Duration (Steps)')\n",
    "    plt.ylabel('CCDF')\n",
    "    plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
    "    plt.yscale(\"linear\")  # y-axis log scale\n",
    "    plt.xscale(\"linear\")  # x-axis linear scale\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder, \"CCDF\")\n",
    "    save_path = os.path.join(save_path, \"CCDF_plot\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "if (Bi_modal_distribution):\n",
    "    zonal_wind_data_real = real_data[:, 1, 63]  # variable index 1 (e.g., zonal wind), level 60\n",
    "    zonal_wind_data_predictions = predictions[:, 0, 63]  # variable index 0 (predictions), level 60\n",
    "\n",
    "    print(f\"Shape of zonal_wind_data_real: {zonal_wind_data_real.shape}\")\n",
    "    print(f\"Shape of zonal_wind_data_predictions: {zonal_wind_data_predictions.shape}\")\n",
    "\n",
    "    # Plot the bimodal histogram\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create histograms (overlaid)\n",
    "    sns.histplot(zonal_wind_data_real, bins=50, kde=True, color='black', alpha=0.6, element='step', label='Real Data')\n",
    "    sns.histplot(zonal_wind_data_predictions, bins=50, kde=True, color='red', alpha=0.6, element='step', label='Predictions')\n",
    "\n",
    "    # Customize plot labels and title\n",
    "    plt.title('Distribution of Zonal Winds For Real Data and Predictions', fontsize=16)\n",
    "    plt.xlabel('Zonal Wind (m/s)', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "    # Add vertical lines at means\n",
    "    plt.axvline(np.mean(zonal_wind_data_real), color='black', linestyle='--', label=f'Real Mean: {np.mean(zonal_wind_data_real):.2f}')\n",
    "    plt.axvline(np.mean(zonal_wind_data_predictions), color='red', linestyle='--', label=f'Pred Mean: {np.mean(zonal_wind_data_predictions):.2f}')\n",
    "\n",
    "    # Final plot settings\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder, \"bi_modal_distribution\")\n",
    "    save_path = os.path.join(save_path, \"bi_modal_distribution_plot\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "if (single_step_profiles):\n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    # === Load model weights ===\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.eval()\n",
    "\n",
    "    # === Randomly sample time points from real data ===\n",
    "    time_indices = random.sample(range(0, real_data.shape[0] - 2), NUM_SAMPLES)\n",
    "    print(f\"Randomly sampled time steps: {time_indices}\")\n",
    "\n",
    "    # === Time series visualization ===\n",
    "    real_data_timeseries = real_data[:, 1, LEVEL]\n",
    "    time_steps_all = np.arange(len(real_data_timeseries))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(time_steps_all, real_data_timeseries, label=\"Real Data at Level 61\", color='blue')\n",
    "\n",
    "    # Mark sample points\n",
    "    for idx_num, idx in enumerate(time_indices):\n",
    "        plt.axvline(x=idx, color='green', linestyle='--', linewidth=2)\n",
    "    if len(time_indices) > 0:\n",
    "        plt.axvline(x=time_indices[0], color='green', linestyle='--', linewidth=2, label='Sampled Points')\n",
    "\n",
    "    plt.title(\"Real Data Time Series with Sampled Points Highlighted\")\n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.ylabel(\"U (m/s) at Level 61\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(SAVE_DIR, \"real_data_timeseries_with_samples.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "    # === Iterate over each sampled time point ===\n",
    "    for i, time_step in enumerate(time_indices):\n",
    "        next_time_step = time_step + 1\n",
    "\n",
    "        # === Real data: current and next ===\n",
    "        real_current = real_data[time_step, 1, :]       \n",
    "        real_next = real_data[next_time_step, 1, :]      \n",
    "\n",
    "        # === Normalize real_current and make prediction for next step ===\n",
    "        initial_cond = torch.reshape(torch.tensor(psi[time_step,start:end]), [1, num_variables])\n",
    "        z = torch.zeros([1,latent_dim])\n",
    "        num_ens = 1\n",
    "        pred = np.zeros ([time_step, num_variables, num_ens])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn_like(z)\n",
    "            print(z.shape, initial_cond.shape)\n",
    "            y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
    "\n",
    "        # === Denormalize predicted next ===\n",
    "        pred_next_denorm = y.squeeze() * std_psi.squeeze() + mean_psi.squeeze()\n",
    "\n",
    "        # === Extract U, Re(Psi), Im(Psi) components ===\n",
    "        # U profiles\n",
    "        U_current_real = real_current[51:74]\n",
    "        U_next_real = real_next[51:74]\n",
    "        U_next_pred = pred_next_denorm[51:74]\n",
    "\n",
    "        # Re(Psi) profiles\n",
    "        RePsi_current_real = real_current[0:24]\n",
    "        RePsi_next_real = real_next[0:24]\n",
    "        RePsi_next_pred = pred_next_denorm[0:24]\n",
    "\n",
    "        # Im(Psi) profiles\n",
    "        ImPsi_current_real = real_current[25:50]\n",
    "        ImPsi_next_real = real_next[25:50]\n",
    "        ImPsi_next_pred = pred_next_denorm[25:50]\n",
    "\n",
    "        # === Differences ===\n",
    "        U_diff_real = U_next_real - U_current_real\n",
    "        U_diff_pred = U_next_pred - U_current_real\n",
    "\n",
    "        RePsi_diff_real = RePsi_next_real - RePsi_current_real\n",
    "        RePsi_diff_pred = RePsi_next_pred - RePsi_current_real\n",
    "\n",
    "        ImPsi_diff_real = ImPsi_next_real - ImPsi_current_real\n",
    "        ImPsi_diff_pred = ImPsi_next_pred - ImPsi_current_real\n",
    "\n",
    "        # === Create a single figure with 3 rows (U, Re(Psi), Im(Psi)) ===\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(16, 18))  # 3 rows, 2 columns (Profile and Difference)\n",
    "\n",
    "        z_levels_U = np.linspace(0, 70, 23)\n",
    "        z_levels_RePsi = np.linspace(0, 70, 24)\n",
    "        z_levels_ImPsi = np.linspace(0, 70, 25)\n",
    "\n",
    "        # --- U ---\n",
    "        axes[0, 0].plot(U_current_real, z_levels_U, 'x-', label=\"Real Current\")\n",
    "        axes[0, 0].plot(U_next_real, z_levels_U, 'd-', label=\"Real Next\")\n",
    "        axes[0, 0].plot(U_next_pred, z_levels_U, 's--', label=\"Predicted Next\")\n",
    "        axes[0, 0].set_title(f\"U Profiles @ Step {time_step}\")\n",
    "        axes[0, 0].set_xlabel(\"U (m/s)\")\n",
    "        axes[0, 0].set_ylabel(\"Vertical Levels (km)\")\n",
    "        axes[0, 0].legend()\n",
    "\n",
    "        axes[0, 1].plot(U_diff_real, z_levels_U, 'xb', label=\"Real Δ (Next - Current)\")\n",
    "        axes[0, 1].plot(U_diff_pred, z_levels_U, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
    "        axes[0, 1].set_title(\"U Difference (Next - Current)\")\n",
    "        axes[0, 1].set_xlabel(\"ΔU (m/s)\")\n",
    "        axes[0, 1].legend()\n",
    "\n",
    "        # --- Re(Psi) ---\n",
    "        axes[1, 0].plot(RePsi_current_real, z_levels_RePsi, 'x-', label=\"Real Current\")\n",
    "        axes[1, 0].plot(RePsi_next_real, z_levels_RePsi, 'd-', label=\"Real Next\")\n",
    "        axes[1, 0].plot(RePsi_next_pred, z_levels_RePsi, 's--', label=\"Predicted Next\")\n",
    "        axes[1, 0].set_title(f\"Re(Psi) Profiles @ Step {time_step}\")\n",
    "        axes[1, 0].set_xlabel(\"Re(Psi)\")\n",
    "        axes[1, 0].set_ylabel(\"Vertical Levels (km)\")\n",
    "        axes[1, 0].legend()\n",
    "\n",
    "        axes[1, 1].plot(RePsi_diff_real, z_levels_RePsi, 'xb', label=\"Real Δ (Next - Current)\")\n",
    "        axes[1, 1].plot(RePsi_diff_pred, z_levels_RePsi, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
    "        axes[1, 1].set_title(\"Re(Psi) Difference (Next - Current)\")\n",
    "        axes[1, 1].set_xlabel(\"ΔRe(Psi)\")\n",
    "        axes[1, 1].legend()\n",
    "\n",
    "        # --- Im(Psi) ---\n",
    "        axes[2, 0].plot(ImPsi_current_real, z_levels_ImPsi, 'x-', label=\"Real Current\")\n",
    "        axes[2, 0].plot(ImPsi_next_real, z_levels_ImPsi, 'd-', label=\"Real Next\")\n",
    "        axes[2, 0].plot(ImPsi_next_pred, z_levels_ImPsi, 's--', label=\"Predicted Next\")\n",
    "        axes[2, 0].set_title(f\"Im(Psi) Profiles @ Step {time_step}\")\n",
    "        axes[2, 0].set_xlabel(\"Im(Psi)\")\n",
    "        axes[2, 0].set_ylabel(\"Vertical Levels (km)\")\n",
    "        axes[2, 0].legend()\n",
    "\n",
    "        axes[2, 1].plot(ImPsi_diff_real, z_levels_ImPsi, 'xb', label=\"Real Δ (Next - Current)\")\n",
    "        axes[2, 1].plot(ImPsi_diff_pred, z_levels_ImPsi, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
    "        axes[2, 1].set_title(\"Im(Psi) Difference (Next - Current)\")\n",
    "        axes[2, 1].set_xlabel(\"ΔIm(Psi)\")\n",
    "        axes[2, 1].legend()\n",
    "\n",
    "        # === Finalize and Save ===\n",
    "        plt.suptitle(f\"Single Step Profile Comparisons at Time Step {time_step}\", fontsize=18)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "\n",
    "        save_path = os.path.join(SAVE_DIR, f\"Profile_Summary_point_{time_step}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Combined plot saved for sampled point {time_step}\")\n",
    "\n",
    "    # Final debug\n",
    "    print(\"Finished processing all sampled points.\")\n",
    "        # Debugging prints\n",
    "    print(predictions.shape) \n",
    "    print(real_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe152fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
