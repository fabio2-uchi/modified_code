{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init pack\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.nn.parallel import DataParallel\n",
    "\n",
    "psi = np.load('/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy')\n",
    "\n",
    "# Pre-processing\n",
    "\n",
    "psi = psi[:,1,:]\n",
    "\n",
    "mean_psi = np.mean(psi, axis=0, keepdims=True)\n",
    "std_psi = np.std(psi, axis=0, keepdims=True)\n",
    "psi = (psi - mean_psi) / std_psi\n",
    "\n",
    "lead = 1\n",
    "trainN = 250000\n",
    "valN = 50000\n",
    "index = 63\n",
    "\n",
    "# Defining the variable ranges\n",
    "variable_range = [(0,24), (25, 49), (50, 74), (0, 49), (0,74)]\n",
    "\n",
    "# Select the variable: 0 for real perturbation, 1 for imaginary perturbation, 2 for zonal winds\n",
    "variable = 3\n",
    "num_variables = variable_range[variable][1] - variable_range[variable][0] + 1\n",
    "print(num_variables)\n",
    "\n",
    "# Shuffle and map indices\n",
    "np.random.seed(42)\n",
    "valid_indices = np.arange(0, trainN - lead)\n",
    "shuffled_indices = np.random.permutation(valid_indices)\n",
    "\n",
    "# Now constrain the shuffled indices to the variable range\n",
    "np_psi_train_input = psi[shuffled_indices, variable_range[variable][0]:variable_range[variable][1]+1]\n",
    "np_psi_train_label = psi[shuffled_indices + lead, :]\n",
    "\n",
    "psi_train_input = torch.tensor(np_psi_train_input)\n",
    "psi_train_label = torch.tensor(np_psi_train_label)\n",
    "\n",
    "np_psi_val_input = psi[trainN:trainN+valN, variable_range[variable][0]:variable_range[variable][1]+1]\n",
    "np_psi_val_label = psi[trainN+lead:trainN+valN+lead, :]\n",
    "psi_val_input = torch.tensor(np_psi_val_input)\n",
    "psi_val_label =  torch.tensor(np_psi_val_label)\n",
    "\n",
    "print(psi.shape)\n",
    "print(psi_train_input.shape)\n",
    "print(psi_train_label.shape)\n",
    "print(psi_val_input.shape)\n",
    "print(psi_val_label.shape)\n",
    "\n",
    "# Define the encoder (MLP)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim, num_neurons):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(75, num_neurons)  # Input layer (2 + 2) -> Hidden layer (128)\n",
    "        self.fc2 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc3 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc4 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc5 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc6 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc_mu = nn.Linear(num_neurons, latent_dim)  # Hidden layer (128) -> Latent space (2)\n",
    "        self.fc_logvar = nn.Linear(num_neurons, latent_dim)  # Hidden layer (128) -> Log variance (2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # Activation function for hidden layer\n",
    "        x = torch.relu(self.fc2(x)) + x\n",
    "        x = torch.relu(self.fc3(x)) + x\n",
    "        x = torch.relu(self.fc4(x)) + x\n",
    "        x = torch.relu(self.fc5(x)) + x\n",
    "        x = torch.relu(self.fc6(x)) + x\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "# Define the decoder (MLP)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, condition_dim, num_neurons):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim + condition_dim, num_neurons)  # Input layer (2 + 2) -> Hidden layer (128)\n",
    "        self.fc2 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc3 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc4 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc5 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc6 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc_output = nn.Linear(num_neurons, output_dim)  # Hidden layer (128) -> Output layer (2)\n",
    "\n",
    "    def forward(self, z, condition):\n",
    "        z = torch.cat((z, condition[:, :50]), dim=1)  # Concatenate latent vector and condition\n",
    "        z = torch.relu(self.fc1(z))  # Activation function for hidden layer\n",
    "        z = torch.relu(self.fc2(z)) + z\n",
    "        z = torch.relu(self.fc3(z)) + z\n",
    "        z = torch.relu(self.fc4(z)) + z\n",
    "        z = torch.relu(self.fc5(z)) + z\n",
    "        z = torch.relu(self.fc6(z)) + z\n",
    "        output = self.fc_output(z)\n",
    "        return output\n",
    "\n",
    "# Define the VAE model\n",
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, condition_dim, num_neurons):\n",
    "        super(ConditionalVAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim, num_neurons)\n",
    "        self.decoder = Decoder(latent_dim, output_dim, condition_dim, num_neurons)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def decode(self, z, condition):\n",
    "        return self.decoder(z, condition)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        output = self.decode(z, condition)\n",
    "        return output, mu, logvar\n",
    "\n",
    "output_dim = 75\n",
    "latent_dim = 32\n",
    "condition_dim = num_variables\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSING BY EXP FIT\n",
    "# TO-DO: Check if crps is correct\n",
    "\n",
    "from scipy.stats import linregress\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "from scipy.stats import norm\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "def normalize_transition_time(s, neuro_num, r):\n",
    "    \"\"\"\n",
    "    Normalize the transition time based on the specified num_neurons and reference value.\n",
    "\n",
    "    Args:\n",
    "        s (float): The transition time to normalize.\n",
    "        neuro_num (float): The num_neurons value for normalization.\n",
    "        r (float): The reference value for normalization.\n",
    "\n",
    "    Returns:\n",
    "        norm (float): The normalized transition time.\n",
    "    \"\"\"\n",
    "    norm = 1 - np.exp(-np.abs((s - r)) / neuro_num)\n",
    "    return norm\n",
    "\n",
    "# Code from Ira Shokar but slightly changed\n",
    "def crps_score(p, y):\n",
    "    \"\"\"\n",
    "    Calculate CRPS for given predictions and observations.\n",
    "\n",
    "    Args:\n",
    "        p (Tensor): Predictions, shape (N, D) where N = ens_num and D is the dimension of the prediction.\n",
    "        y (Tensor): Observations, shape (D) where D is the dimension of the observation.\n",
    "\n",
    "    Returns:\n",
    "        crps (float): The CRPS score.\n",
    "    \"\"\"\n",
    "    y  = y.unsqueeze(0)\n",
    "    # First term: mean distance from observations to ensemble members\n",
    "    mae     = torch.cdist(y, p, 1).mean()\n",
    "    # Second term: mean distance between ensemble members (properly normalized)\n",
    "    ens_var = torch.cdist(p, p, 1).mean()\n",
    "    \n",
    "    return mae - 0.5 * ens_var\n",
    "\n",
    "# Function to calculate transition durations\n",
    "def calculate_transition_durations(y, u, l):\n",
    "    \"\"\"\n",
    "    Calculate the return periods with user-defined upper and lower bounds.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): The time series data.\n",
    "        u (float): The upper bound for the transition.\n",
    "        l (float): The lower bound for the transition.\n",
    "\n",
    "    Returns:\n",
    "        t_times (list): The list of return periods for transitions.\n",
    "    \"\"\"\n",
    "\n",
    "    t_times = []\n",
    "    s = None\n",
    "    above_u = False\n",
    "    below_l = False\n",
    "    for i in range(1, len(y)):\n",
    "        if y[i] < l:  \n",
    "            if above_u and s is not None:\n",
    "                t_times.append(i-s)\n",
    "                s = None\n",
    "                print(i)\n",
    "            below_l = True\n",
    "            above_u = False\n",
    "        elif y[i] > u:  \n",
    "            if below_l and s is not None:\n",
    "                t_times.append(i - s)\n",
    "                s = None \n",
    "                print(i)\n",
    "            above_u = True\n",
    "            below_l = False\n",
    "\n",
    "        if below_l and s is None:\n",
    "            s = i\n",
    "\n",
    "        if above_u and s is None:\n",
    "            s = i\n",
    "    return t_times\n",
    "\n",
    "def KL_coefficient(r, p, num_neurons, cycle, KL_by_dim_cycle, L1_by_dym_cycle):\n",
    "    \"\"\"\n",
    "    Calculate the KL divergence between two distributions and normalize it.\n",
    "\n",
    "    Args:\n",
    "        r (np.array): Real distribution.\n",
    "        p (np.array): Predicted distribution.\n",
    "        num_neurons (float): num_neurons value for normalization.\n",
    "        cycle (int): Cycle number for tracking.\n",
    "        KL_by_dim_cycle (dict): Dictionary to store KL divergence values by dimension and cycle.\n",
    "\n",
    "    Returns:\n",
    "        r (np.array): Processed real distribution.\n",
    "        p (np.array): Processed predicted distribution.\n",
    "        nkl (float): Normalized KL divergence.\n",
    "    \"\"\"\n",
    "    # Calculating KL divergence\n",
    "    r = r[:300000, 1, 63]\n",
    "    p = p[:300000]\n",
    "    \n",
    "    rh, b = np.histogram(r, bins=100, density=True)\n",
    "    ph, _ = np.histogram(p, bins=b, density=True)\n",
    "\n",
    "    abs_diff = np.abs(rh-ph)\n",
    "    max_diff = np.max(abs_diff)\n",
    "    norm_diff = max_diff / (np.max(rh) + np.max(ph))\n",
    "\n",
    "    e = 1e-10\n",
    "    rh += e\n",
    "    ph += e\n",
    "\n",
    "    # Calculate KL divergence between the two histograms\n",
    "    kl = np.sum(rh * np.log(rh / ph))\n",
    "    nkl = normalize_transition_time(kl, 1, 0)\n",
    "\n",
    "    KL_by_dim_cycle[num_neurons][cycle].append(nkl)\n",
    "    L1_by_dym_cycle[num_neurons][cycle].append(norm_diff)\n",
    "    \n",
    "    return r, p, nkl, norm_diff\n",
    "\n",
    "def CCDF_fit(p_times, s):\n",
    "    \"\"\"\n",
    "    Calculate the slope of the CCDF of transition times and normalize it.\n",
    "\n",
    "    Args:\n",
    "        p_times (list): Transition times from predictions.\n",
    "        s (float): Real value for normalization.\n",
    "    \n",
    "    Returns:\n",
    "        np_slope (float): Normalized slope of the CCDF.\n",
    "    \"\"\"\n",
    "    # === PREDICTIONS CCDF AND FIT ===\n",
    "    if len(p_times) > 0 and len(np.unique(p_times)) > 1:\n",
    "        sp_times = np.sort(p_times)\n",
    "        p_ccdf = 1 - np.arange(1, len(sp_times) + 1) / len(sp_times)\n",
    "\n",
    "        p_v_indices = p_ccdf > 0\n",
    "        px_fit = sp_times[p_v_indices]\n",
    "        py_fit = np.log(p_ccdf[p_v_indices])\n",
    "\n",
    "        p_slope, _, *_ = linregress(px_fit, py_fit)\n",
    "        np_slope = normalize_transition_time(p_slope, 0.005, s)\n",
    "        return np_slope\n",
    "\n",
    "    else:\n",
    "        print(\"No transitions detected in predictions for CCDF slope evaluation.\")\n",
    "\n",
    "def Mean_and_std_of_predictions(p_times, r_times, neuro_num, cc, transitions_by_dim_cycle, transitions_normalized_by_dim_cycle, transitions_normalized_std_by_dim_cycle):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of transition times from predictions and normalize them.\n",
    "\n",
    "    Args:\n",
    "        p_times (list): Transition times from predictions.\n",
    "        r_times (list): Transition times from real data.\n",
    "        neuro_num (float): num_neurons value for normalization.\n",
    "        cc (int): Cycle number for tracking.\n",
    "        transitions_by_dim_cycle (dict): Dictionary to store transition times by dimension and cycle.\n",
    "        transitions_normalized_by_dim_cycle (dict): Dictionary to store normalized transition times by dimension and cycle.\n",
    "        transitions_normalized_std_by_dim_cycle (dict): Dictionary to store normalized standard deviations by dimension and cycle.\n",
    "\n",
    "    Returns:\n",
    "        npd_mean (float): Normalized mean of transition times.\n",
    "        npd_std (float): Normalized standard deviation of transition times.\n",
    "    \"\"\"\n",
    "    p_mean = np.mean(p_times)\n",
    "    p_std = np.std(p_times)\n",
    "\n",
    "    pd_mean = abs(p_mean - np.mean(r_times))\n",
    "    pd_std = abs(p_std - np.std(r_times))\n",
    "\n",
    "    npd_mean = normalize_transition_time(pd_mean, 1000, np.mean(r_times))\n",
    "    npd_std = normalize_transition_time(pd_std, 1000, np.std(r_times))\n",
    "\n",
    "    npd_std = 1 if npd_std == 0 else npd_std\n",
    "\n",
    "    transitions_by_dim_cycle[neuro_num][cc].append(pd_mean)\n",
    "    transitions_normalized_by_dim_cycle[neuro_num][cc].append(npd_mean)\n",
    "    transitions_normalized_std_by_dim_cycle[neuro_num][cc].append(npd_std)\n",
    "\n",
    "    return npd_mean, npd_std\n",
    "\n",
    "# KL Annealing (FROM PAPER)\n",
    "def frange_cycle_linear(start, stop, n_epoch, n_cycle=4, ratio=0.5):\n",
    "    \"\"\"\n",
    "    Generate a linear schedule for KL annealing over multiple cycles.\n",
    "\n",
    "    Args:\n",
    "        start (float): Starting value of the schedule.\n",
    "        stop (float): Stopping value of the schedule.\n",
    "        n_epoch (int): Total number of epochs.\n",
    "        n_cycle (int): Number of cycles for the schedule.\n",
    "        ratio (float): Ratio of the cycle length to the total number of epochs.\n",
    "\n",
    "    Returns:\n",
    "        L (np.array): Array containing the linear schedule values for each epoch.\n",
    "    \"\"\"\n",
    "    L = np.ones(n_epoch)\n",
    "    period = n_epoch/n_cycle\n",
    "    step = (stop-start)/(period*ratio) # linear schedule\n",
    "\n",
    "    for c in range(n_cycle):\n",
    "\n",
    "        v , i = start , 0\n",
    "        while v <=stop and (int(i+c*period) < n_epoch):\n",
    "            L[int(i+c*period)] = v\n",
    "            v += step\n",
    "            i += 1\n",
    "    return L\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "def Timeseries_plot(y, p, fig):\n",
    "    \"\"\"\n",
    "    Plot the timeseries.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): Actual zonal wind values.\n",
    "        p (np.array): Predicted zonal wind values.\n",
    "        ep (int): Current epoch number.\n",
    "        ax (matplotlib.axes.Axes): Axes object to plot on.\n",
    "\n",
    "    Returns:\n",
    "        None. Just plots the timeseries on the provided axes.\n",
    "    \"\"\"\n",
    "    fig.add_trace(go.Scatter(y=y[:60000], mode='lines', name=\"Actual\", line=dict(color='blue')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(y=p[:60000], mode='lines', name=\"Predictions\", line=dict(color='red')), row=1, col=1)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Days\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Zonal Wind Value\", row=1, col=1)\n",
    "\n",
    "    # ax.legend(['Predictions', 'Actual'])\n",
    "    # ax.grid(True)\n",
    "\n",
    "    # save_path = os.path.join(folder, \"timeseries\")\n",
    "    # save_path = os.path.join(save_path, f\"timeseries_plot_{epoch+1}.png\")\n",
    "\n",
    "    # plt.savefig(save_path)\n",
    "\n",
    "    # plt.show()75\n",
    "\n",
    "def PDF_plot(yv, p, pdf_dt, fig):\n",
    "    \"\"\"\n",
    "    Plot PDFs of the zonal wind values.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): Actual zonal wind values.\n",
    "        p (np.array): Predicted zonal wind values.\n",
    "        ep (int): Current epoch number.\n",
    "        pdf_dt (float): KL diff between the PDFs of actual and predicted values.\n",
    "        ax (matplotlib.axes.Axes): Axes object to plot on.\n",
    "\n",
    "    Returns:\n",
    "        None. Just plots the PDFs on the provided axes.\n",
    "    \"\"\"\n",
    "\n",
    "    # sns.histplot(y, bins=100, kde=True, color='black', alpha=0.6, element='step', label='Real Data', ax=ax)\n",
    "    # sns.histplot(p, bins=100, kde=True, color='red', alpha=0.6, element='step', label='Predictions', ax=ax)\n",
    "\n",
    "    fig.add_trace(go.Histogram(x=yv, histnorm='probability density', name='Actual Data', opacity=0.6, marker_color='black'), row=2, col=1)\n",
    "    fig.add_trace(go.Histogram(x=p, histnorm='probability density', name='Predictions', opacity=0.6, marker_color='red'), row=2, col=1)\n",
    "\n",
    "    fig.update_layout(title_text=f\"Probability Distribution Functions (PDFs) | KL Error: {pdf_dt:.4f}\")\n",
    "    fig.update_xaxes(title_text='Zonal Wind (m/s)', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Frequency', row=2, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=[np.mean(yv), np.mean(yv)], y=[0,0.18], mode='lines', line=dict(color='black', width=2, dash='dash'), name=f'Actual Mean: {np.mean(yv):.2f}'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=[np.mean(p), np.mean(p)], y=[0,0.18], mode='lines', line=dict(color='red', width=2, dash='dash'), name=f'Pred Mean: {np.mean(p):.2f}'), row=2, col=1)\n",
    "\n",
    "    fig.update_layout(legend=dict())\n",
    "    fig.update_xaxes(showgrid=True, gridcolor='lightgray', gridwidth=1)\n",
    "\n",
    "    # save_path = os.path.join(folder, \"bi_modal_distri\")\n",
    "    # save_path = os.path.join(save_path, f\"bi_modal_distribution_plot_{epoch+1}.png\")\n",
    "    # plt.savefig(save_path)\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "def Exp_fit_plot(xlp, yvp, xlr, yvr, p_exp_fit, r_exp_fit, exp_d, range_d, fig):\n",
    "    \"\"\"\n",
    "    Plot the exponential fits of transition return periods.\n",
    "\n",
    "    Args:\n",
    "        xlp (np.array): X values for predicted exponential fit.\n",
    "        yvp (np.array): Y values for predicted exponential fit.\n",
    "        xlr (np.array): X values for real exponential fit.\n",
    "        yvr (np.array): Y values for real exponential fit.\n",
    "        p_exp_fit (float): Slope of the predicted exponential fit.\n",
    "        r_exp_fit (float): Slope of the real exponential fit.\n",
    "        ep (int): Current epoch number.\n",
    "        exp_d (float): Exponential fit error for predictions.\n",
    "        range_d (float): Range error for predictions.\n",
    "        ax (matplotlib.axes.Axes): Axes object to plot on.\n",
    "\n",
    "    Returns:\n",
    "        None. Just plots the exponential fits on the provided axes.\n",
    "    \"\"\"\n",
    "    fig.add_trace(go.Scatter(x=xlp, y=yvp, mode='lines', name='Predicted Fit', line=dict(color='blue')), row=2, col=2)\n",
    "    fig.add_trace(go.Scatter(x=xlr, y=yvr, mode='lines', name='Real Fit', line=dict(color='red')), row=2, col=2)\n",
    "\n",
    "    fig.update_xaxes(title_text='Time Duration (Steps)', row=2, col=2)\n",
    "    fig.update_yaxes(title_text='Exponential Fit', row=2, col=2)\n",
    "    fig.update_layout(title_text=f\"Exponential Fits of Transition Return Periods | Exp Error: {exp_d:.4f} | Range Error: {range_d:.4f}\", title_fontsize=16)\n",
    "\n",
    "    fig.update_yaxes(type=\"linear\", row=2, col=2)  # y-axis log scale\n",
    "    fig.update_xaxes(type=\"linear\", row=2, col=2)  # x-axis linear scale\n",
    "\n",
    "    # save_path = os.path.join(folder, \"expo_fit\")\n",
    "    # save_path = os.path.join(save_path, f\"expo_fit_plot_{epoch}.png\")\n",
    "    # plt.savefig(save_path)\n",
    "    # plt.show()\n",
    "\n",
    "def PCA_plot(fig, mu_np, labels):\n",
    "    # PCA\n",
    "    num_components = 3\n",
    "    pca = PCA(n_components=num_components)\n",
    "    print(f\"==>> pca: {pca}\")\n",
    "\n",
    "    #mu\n",
    "    latent_3d = pca.fit_transform(mu_np)\n",
    "    print(f\"==>> latent_3d: {latent_3d.shape}\")\n",
    "\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    total_explained = np.sum(explained)\n",
    "    print(f\"Explained variance by PC1: {explained[0]:.4f}\")\n",
    "    print(f\"Explained variance by PC2: {explained[1]:.4f}\")\n",
    "    print(f\"Explained variance by PC3: {explained[2]:.4f}\")\n",
    "    print(f\"Total explained variance (PC1+2+3): {total_explained:.4f}\")\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(latent_3d[:, 0:num_components], columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "    print(mu_np, labels, df)\n",
    "    df[\"Category\"] = labels\n",
    "    px_fig = px.scatter_3d(df, x=\"PC1\", y=\"PC2\", z=\"PC3\", color=\"Category\",\n",
    "                    opacity=0.75,\n",
    "                    title=\"Latent Space Projection: 4-Way Classification, mu\",\n",
    "                    width=1500, height=1400)\n",
    "    for trace in px_fig.data:\n",
    "        fig.add_trace(trace, row=1, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='PC1',\n",
    "            yaxis_title='PC2',\n",
    "            zaxis_title='PC3'\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=0),\n",
    "    )\n",
    "\n",
    "\n",
    "def Final_KL_PDF_plot(KL_by_dim_cycle, r, neuro_num, ncc, f):\n",
    "    \"\"\"\n",
    "    Plot the average transition values across all cycles.\n",
    "\n",
    "    Args:\n",
    "        KL_by_dim_cycle (dict): Dictionary containing KL PDF values by dimension and cycle.\n",
    "        r (float): Real data value for comparison.\n",
    "        neuro_num (float): num_neurons coefficient for normalization.\n",
    "        ncc (int): Number of cycles.\n",
    "        f (str): Folder path to save the plot.\n",
    "    \n",
    "    Returns:\n",
    "        None. Just plots the average transition values and saves the figure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for c in range(ncc):\n",
    "        plt.plot(KL_by_dim_cycle[neuro_num][c], 'o-', label=f'Cycle {c}')\n",
    "    \n",
    "    plt.xlabel('Epoch within Cycle')\n",
    "    plt.ylabel('KL Difference Normalized')\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(f'KL Difference Value between PDFs Normalized)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    f = os.path.join(f, f\"KL_diff_all_cycles.png\")\n",
    "    plt.savefig(f)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def Final_exp_fit_plot(exp_fit_by_dim_cycle, r_exp_fit, neuro_num, ncc, f):\n",
    "    \"\"\"\n",
    "    Plot the exponential fit values across all cycles.\n",
    "\n",
    "    Args:\n",
    "        exp_fit_by_dim_cycle (dict): Dictionary containing exponential fit values by dimension and cycle.\n",
    "        r_exp_fit (float): Real data value for comparison.\n",
    "        neuro_num (float): num_neurons coefficient for normalization.\n",
    "        ncc (int): Number of cycles.\n",
    "        f (str): Folder path to save the plot.\n",
    "\n",
    "    Returns:\n",
    "        None. Just plots the exponential fit values and saves the figure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for c in range(ncc):\n",
    "        plt.plot(exp_fit_by_dim_cycle[neuro_num][c], 'o-', label=f'Cycle {c}')\n",
    "    \n",
    "    plt.axhline(y=r_exp_fit, color='r', linestyle='--', label='Real Data')\n",
    "\n",
    "    plt.xlabel('Epoch within Cycle')\n",
    "    plt.ylabel('Exponential Fit Value')\n",
    "    plt.title(f'Exponential Fit Progress (num_neurons Coefficient={neuro_num})')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "\n",
    "    f = os.path.join(f, f\"exponential_fit_plot_all_cycles.png\")\n",
    "    plt.savefig(f)\n",
    "    plt.close()\n",
    "    \n",
    "def all_plot(y, p, xlp, yvp, xlr, yvr, \n",
    "             p_exp_fit, r_exp_fit, pdf_dt, exp_dt, range_dt, mu_np, labels, folder):\n",
    "    \"\"\"\n",
    "    Comprehensive plot with timeseries, PDF, and exponential fit.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): Actual zonal wind values.\n",
    "        p (np.array): Predicted zonal wind values.\n",
    "        xlp (np.array): X values for predicted exponential fit.\n",
    "        yvp (np.array): Y values for predicted exponential fit.\n",
    "        xlr (np.array): X values for real exponential fit.\n",
    "        yvr (np.array): Y values for real exponential fit.\n",
    "        p_exp_fit (float): Slope of the predicted exponential fit.\n",
    "        r_exp_fit (float): Slope of the real exponential fit.\n",
    "        pdf_dt (float): KL divergence between the PDFs of actual and predicted values.\n",
    "        exp_dt (float): Exponential fit error for predictions.\n",
    "        range_dt (float): Range error for predictions.\n",
    "        ep (int): Current epoch number.\n",
    "        folder (str): Folder path to save the plot.\n",
    "    \n",
    "    Returns:\n",
    "        None. Just plots the timeseries, PDF, and exponential fit and saves the figure.\n",
    "    \"\"\"\n",
    "    fig = make_subplots(rows=2, cols=2, specs=[[{}, {\"type\":\"scene\", \"rowspan\": 2}], [{}, None]],\n",
    "                        subplot_titles=[\"Timeseries of Zonal Wind U(30)\", \"3D PCA Analysis of 32-D Latent Space (mu)\",\n",
    "                                        \"Probability Distribution Functions (PDFs)\"],\n",
    "                        horizontal_spacing=0.02, vertical_spacing=0.14)\n",
    "\n",
    "    Timeseries_plot(y[:30000], p[:30000], fig)\n",
    "    PDF_plot(y, p, pdf_dt, fig)\n",
    "    # Exp_fit_plot(xlp, yvp, xlr, yvr, \n",
    "    #              p_exp_fit, r_exp_fit, exp_dt, range_dt, px)\n",
    "    PCA_plot(fig, mu_np, labels)\n",
    "    \n",
    "    dt = np.sqrt(pdf_dt**2 + exp_dt**2 + range_dt**2)\n",
    "    fig.update_layout(title_text=f\"<b>Comprehensive Analysis of Zonal Wind Predictions | Euclidean Metric Error: {dt:.4f}</b>\",\n",
    "                      title_subtitle=dict(text=f\"PDF/KL Error: {pdf_dt:.4f}, Rate of Transitions Error: {exp_dt:.4f}, Time Range of Return Periods Error: {range_dt:.4f}\",\n",
    "                                          ),\n",
    "                      title_x=0.5,\n",
    "        width=1500, height=850,\n",
    "        margin=dict(l=80, r=50, t=150, b=80),\n",
    "        margin_pad=0.05,\n",
    "        paper_bgcolor='white',\n",
    "        font=dict(family=\"Arial, sans-serif\", size=14, color=\"#444\"),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=-0.15,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5,\n",
    "            font=dict(size=12)\n",
    "        ),\n",
    "        hovermode=\"closest\",)\n",
    "    fig.show()\n",
    "\n",
    "def Loss_plot(t_loss, v_loss, cc, neuro_num, f):\n",
    "    \"\"\"\n",
    "    Plot the training and validation losses.\n",
    "\n",
    "    Args:\n",
    "        t_loss (list): Training loss values.\n",
    "        v_loss (list): Validation loss values.\n",
    "        cc (int): Cycle number for tracking.\n",
    "        neuro_num (float): num_neurons value for normalization.\n",
    "        f (str): Folder path to save the plot.\n",
    "    \n",
    "    Returns:\n",
    "        None. Just plots the training and validation losses and saves the figure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    plt.plot(t_loss, label='Training Loss')\n",
    "    plt.plot(v_loss, label='Validation Loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Losses for Cycle {cc+1} with num_neurons {neuro_num}')\n",
    "    plt.legend()\n",
    "\n",
    "    f = os.path.join(f, f\"loss_plot_cycle_{cc+1}_num_neurons_{neuro_num}.png\")\n",
    "    plt.savefig(f)\n",
    "    plt.close()\n",
    "    \n",
    "# TO-DO: Try to change KL metric to KS. Add all graphs in one figure and add the distance metric to the best model selection to it.\n",
    "\n",
    "# Training\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def model_restore(mp, model):\n",
    "    \"\"\"\n",
    "    Restore the model state from a saved checkpoint.\n",
    "\n",
    "    Args:\n",
    "        mp (str): Path to the model checkpoint.\n",
    "        model (nn.Module): The model to restore.\n",
    "\n",
    "    Returns:\n",
    "        None. The model state is loaded from the checkpoint if it exists.\n",
    "    \"\"\"\n",
    "    if os.path.exists(mp):\n",
    "        print(f\"Loading model from {mp}\")\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "def inference(model, psi, tst, vr, v, nv, ld):\n",
    "    \"\"\"\n",
    "    Perform inference using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained model.\n",
    "        psi (np.array): Input data for inference.\n",
    "        tst (int): Number of time steps.\n",
    "        vr (dict): Variable ranges for the input data.\n",
    "        v (int): Index of the variable to use for inference.\n",
    "        nv (int): Number of variables.\n",
    "        ld (int): Latent dimension of the model.\n",
    "    \n",
    "    Returns:\n",
    "        p (np.array): Predictions made by the model.\n",
    "    \"\"\"\n",
    "    s, e = vr[v][0], vr[v][1]+1\n",
    "    init_c = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
    "    p = np.zeros ([tst, 75])\n",
    "\n",
    "    for k in range (0, tst):\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "\n",
    "            with autocast(device_type='cuda'):\n",
    "\n",
    "                if (k ==0):\n",
    "\n",
    "                    init_c = init_c.float().cuda(non_blocking=True)\n",
    "                    y, _, _ = (model(init_c, init_c))\n",
    "                    y = y.detach().cpu().numpy()\n",
    "                    p[k,:] = y\n",
    "                    init_c = torch.tensor(y[:, s:e])\n",
    "\n",
    "                else:\n",
    "\n",
    "                    init_c = torch.reshape(torch.tensor(p[k-1,:]),[1,75]).float().cuda(non_blocking=True)\n",
    "                    y, _, _ = (model(init_c,init_c))\n",
    "                    y = y.detach().cpu().numpy()\n",
    "                    p[k,:] = y\n",
    "                    init_c = torch.tensor(y[:, s:e])\n",
    "    \n",
    "    return p\n",
    "\n",
    "def euclidean_distance_for_predictions(ms):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance for a list of metrics.\n",
    "\n",
    "    Args:\n",
    "        ms (list): List of computed metrics.\n",
    "\n",
    "    Returns:\n",
    "        dt (float): The Euclidean distance calculated from the given computed metrics.\n",
    "    \"\"\"\n",
    "    s = 0\n",
    "    for m in ms:\n",
    "        s += m ** 2\n",
    "    dt = np.sqrt(s)\n",
    "    return dt\n",
    "\n",
    "def save_best_cycle_epoch(models, neuro_num, cc, ep, f,\n",
    "                          exp_fit_normalized_by_dim_cycle, \n",
    "                          KL_by_dim_cycle, duration_diff_by_dim_cycle, \n",
    "                          best_models_saved, best_models):\n",
    "    \"\"\"\n",
    "    Select the best model from a cycle based on combined distance metrics and save it.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of model paths for the current cycle.\n",
    "        neuro_num (float): num_neurons coefficient for normalization.\n",
    "        cc (int): Current cycle number.\n",
    "        ep (int): Current epoch number.\n",
    "        f (str): Folder path to save the best model.\n",
    "        exp_fit_normalized_by_dim_cycle (dict): Dictionary containing normalized exponential fit values by dimension and cycle.\n",
    "        KL_by_dim_cycle (dict): Dictionary containing KL divergence values by dimension and cycle.\n",
    "        duration_diff_by_dim_cycle (dict): Dictionary containing range differences by dimension and cycle.\n",
    "        best_models_saved (list): List to store the paths of the best models saved.\n",
    "        best_models (list): List to store the best models selected.\n",
    "\n",
    "    Returns:\n",
    "        None. The best model is saved to the specified folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    b_model = None\n",
    "    b_i = -1\n",
    "    b_dt = float('inf')\n",
    "\n",
    "    for i in range(len(models)):  # models contains each epoch's model in the current cycle\n",
    "        print(exp_fit_normalized_by_dim_cycle[neuro_num][cc][i])\n",
    "        print(KL_by_dim_cycle[neuro_num][cc][i])\n",
    "        print(duration_diff_by_dim_cycle[neuro_num][cc][i])\n",
    "        ms = [exp_fit_normalized_by_dim_cycle[neuro_num][cc][i],\n",
    "                   KL_by_dim_cycle[neuro_num][cc][i], \n",
    "                   duration_diff_by_dim_cycle[neuro_num][cc][i]]\n",
    "        \n",
    "        dt = euclidean_distance_for_predictions(ms)\n",
    "        if dt < b_dt:\n",
    "            b_dt = dt\n",
    "            b_i = i\n",
    "            b_model = models[i]\n",
    "\n",
    "    if b_i != -1:\n",
    "        best_models_saved.append(b_model)\n",
    "        best_models.append((cc, b_i))\n",
    "\n",
    "    shutil.copyfile(models[b_i], f\"{f}/best_model_combined_distance_at_cycle_{cc}_and_checkpoint_{ep}.pth\")\n",
    "    print(f\"New best model saved with distance {dt:.4f} at epoch {i+1}\")\n",
    "\n",
    "def save_best_epoch(best_models, best_models_saved, exp_fit_normalized_by_dim_cycle,\n",
    "                    KL_by_dim_cycle, duration_diff_by_dim_cycle, neuro_num, mf):\n",
    "    \n",
    "    \"\"\"\n",
    "    Select the best model from the master training run based on combined distance metrics and save it.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of model paths for the current cycle.\n",
    "        neuro_num (float): num_neurons coefficient for normalization.\n",
    "        cc (int): Current cycle number.\n",
    "        ep (int): Current epoch number.\n",
    "        f (str): Folder path to save the best model.\n",
    "        exp_fit_normalized_by_dim_cycle (dict): Dictionary containing normalized exponential fit values by dimension and cycle.\n",
    "        KL_by_dim_cycle (dict): Dictionary containing KL divergence values by dimension and cycle.\n",
    "        duration_diff_by_dim_cycle (dict): Dictionary containing range differences by dimension and cycle.\n",
    "        best_models_saved (list): List to store the paths of the best models saved.\n",
    "        best_models (list): List to store the best models selected.\n",
    "\n",
    "    Returns:\n",
    "        None. The best model is saved to the specified folder.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Selecting the best model based on combined distance...\")\n",
    "\n",
    "    # Ensure best_models is not empty\n",
    "    if not best_models:\n",
    "        print(\"No best models found.\")\n",
    "        return\n",
    "    \n",
    "    # After all cycles - final best model selection\n",
    "    b_model = None\n",
    "    w_model = (-1, -1)\n",
    "    b_model_dt = float('inf')\n",
    "\n",
    "    print(f\"Number of best models saved: {len(best_models)}\")\n",
    "    for idx, (cc, ep_idx) in enumerate(best_models):\n",
    "\n",
    "        ms = [exp_fit_normalized_by_dim_cycle[neuro_num][cc][ep_idx], \n",
    "                   KL_by_dim_cycle[neuro_num][cc][ep_idx], \n",
    "                   duration_diff_by_dim_cycle[neuro_num][cc][ep_idx]]\n",
    "        \n",
    "        dt = euclidean_distance_for_predictions(ms)        \n",
    "        print(f\"Distance for model from cycle {cc+1}, epoch {ep_idx+1}: {dt:.4f}\")\n",
    "        print(f\"Current best distance: {b_model_dt:.4f}\")\n",
    "        \n",
    "        if dt < b_model_dt:\n",
    "            b_model_dt = dt\n",
    "            b_model = best_models_saved[idx]\n",
    "            w_model = (cc, ep_idx)\n",
    "\n",
    "    # Save the best model  \n",
    "    i,n = w_model\n",
    "    cc = i\n",
    "    ep = n\n",
    "\n",
    "    if cc == -1:\n",
    "        print(\"No best model found.\")\n",
    "    else:\n",
    "        shutil.copyfile(b_model, f\"{mf}/best_{neuro_num}_neurons_model_with_emr_{b_model_dt:.4f}_at_epoch_{ep+1}.pth\")\n",
    "        print(f\"Best model saved with cycle {cc+1} and epoch {ep+1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a72aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "# Inference\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "real_data       = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
    "real_data_1d    = real_data[:, 1, 63]\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "\n",
    "time_step = 10000\n",
    "\n",
    "latent_dim = 32\n",
    "output_dim = 75\n",
    "condition_dim = num_variables\n",
    "num_neurons = 1024\n",
    "\n",
    "model = ConditionalVAE(latent_dim, output_dim, condition_dim, num_neurons)\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "start, end = variable_range[variable][0], variable_range[variable][1]+1\n",
    "\n",
    "# MODIFY THIS LINE FOR MODEL TESTING\n",
    "past_model = True  # Set to True if you want to load past model weights\n",
    "if past_model:\n",
    "    model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/best_models_kinda/checkpoint_11\"\n",
    "    if os.path.exists(model_weights_path):\n",
    "        model.load_state_dict(torch.load(model_weights_path))\n",
    "        print(f\"Model weights loaded from {model_weights_path}.\")\n",
    "\n",
    "for _ in range (0,1):\n",
    "\n",
    "    pred = inference(model, psi, time_step, variable_range, variable, \n",
    "                             condition_dim, latent_dim)\n",
    "    \n",
    "    pred_mean = pred[:time_step, :] * std_psi[:, :] + mean_psi[:, :]\n",
    "    actual_values = real_data[:time_step, 1, :]\n",
    "    predictions_1d = pred_mean[:, 63]\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(pred_mean[0:30000, 63],'r')\n",
    "    plt.plot(actual_values[0:30000, 63],'b')\n",
    "    plt.grid(True)\n",
    "    plt.title(f\"Predictions vs Actual\")\n",
    "    plt.savefig(f'/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnetprediction_vs_actual_{datetime.datetime.now()}.png')\n",
    "    plt.show()\n",
    "\n",
    "    # MODIFY THIS LINE FOR MODEL TESTING\n",
    "    np.save(f'/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/predictions_best_checkpoint_and_cycle_Resnet_VAE_best_epoch_no_finetune.npy', pred_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound = 53.8 / 2.8935\n",
    "lower_bound = 7.41\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(predictions_1d[1200:1400],'r')\n",
    "plt.plot(real_data_1d[1200:1400],'b')\n",
    "# plt.plot(predictions_1d[740:800],'purple')\n",
    "# plt.plot(real_data_1d[740:800],'g')\n",
    "plt.axhline(y=lower_bound)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAGS to determine testing\n",
    "plot_data = 1\n",
    "CCDF = 1\n",
    "Bi_modal_distribution = 1\n",
    "single_step_profiles = 1\n",
    "all_plot_flag = 1\n",
    "\n",
    "NUM_SAMPLES = 5\n",
    "MODEL_PATH = model_weights_path\n",
    "level = 63\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Load the data; shape = (300000, 2, 75)\n",
    "real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
    "zonal_wind = real_data[:, 1, 63]\n",
    "upper, lower = 53.8 / 2.8935, 7.41\n",
    "predictions = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/predictions_best_checkpoint_and_cycle_Resnet_VAE_best_epoch_no_finetune.npy\")\n",
    "\n",
    "#reshape the predictions so that it matches the real_data shape\n",
    "predictions = predictions.reshape(10000, 1, 75)\n",
    "print(predictions.shape)\n",
    "print(real_data.shape)\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S.%f\")\n",
    "folder = f\"testing_at_{timestamp}\"\n",
    "os.mkdir(folder)\n",
    "subfolders = ['timeseries', 'exp_fit', 'bi_modal_distribution', 'single_step_profiles']\n",
    "# Create each subdirectory inside the main folder\n",
    "for subfolder in subfolders:\n",
    "    path = os.path.join(folder, subfolder)\n",
    "    os.mkdir(path)\n",
    "    print(f\"Created subfolder: {path}\")\n",
    "SAVE_DIR = os.path.join(folder, \"single_step_profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25153a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "upper_bound = 53.8 / 2.8935\n",
    "lower_bound = 7.41\n",
    "num_neurons = 1024\n",
    "\n",
    "model = ConditionalVAE(latent_dim, output_dim, condition_dim, num_neurons)\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "if os.path.exists(model_weights_path):\n",
    "    model.load_state_dict(torch.load(model_weights_path))\n",
    "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
    "\n",
    "if (all_plot_flag):\n",
    "\n",
    "    r = real_data[:300000, 1, level]\n",
    "    p = predictions[:, 0, level]\n",
    "    # Compute transition durations for real data\n",
    "    real_durations = calculate_transition_durations(r, upper_bound, lower_bound)\n",
    "\n",
    "    # Compute transition durations for predictions data\n",
    "    pred_durations = calculate_transition_durations(p, upper_bound, lower_bound)\n",
    "\n",
    "    print(pred_durations, real_durations)\n",
    "\n",
    "    # === REAL DATA CCDF AND FIT ===\n",
    "    if len(real_durations) == 0:\n",
    "        print(\"No transitions detected in real data with current bounds!\")\n",
    "    else:\n",
    "        real_data_sorted = np.sort(real_durations)\n",
    "        xlr = np.linspace(min(real_data_sorted), max(real_data_sorted), 100)\n",
    "        exp_fit_r = 1/np.mean(real_data_sorted)\n",
    "        yvr = exp_fit_r*xlr\n",
    "\n",
    "    # === PREDICTIONS CCDF AND FIT ===\n",
    "    if len(pred_durations) == 0:\n",
    "        print(\"No transitions detected in predictions with current bounds!\")\n",
    "    else:\n",
    "        pred_data_sorted = np.sort(pred_durations)\n",
    "        xlp = np.linspace(min(pred_data_sorted), max(pred_data_sorted), 100)\n",
    "        exp_fit_p = 1/np.mean(pred_data_sorted)\n",
    "        yvp = exp_fit_p*xlp\n",
    "\n",
    "    # Compute CCDF\n",
    "    real_data_sorted = np.sort(real_durations)\n",
    "    ccdf_real = 1 - np.arange(1, len(real_data_sorted) + 1) / len(real_data_sorted)\n",
    "\n",
    "    # Filter valid data (exclude zero or negative CCDF values)\n",
    "    valid_indices = ccdf_real > 0  # Avoid log(0) issues\n",
    "    x_fit = real_data_sorted[valid_indices]  # Keep x in linear scale\n",
    "    y_fit = np.log(ccdf_real[valid_indices])  # Apply log transformation to y\n",
    "\n",
    "    # Perform linear regression on log-transformed data\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x_fit, y_fit)\n",
    "\n",
    "    # Convert back to exponential form (y = e^(slope*x + intercept))\n",
    "    x_line = np.linspace(min(x_fit), max(x_fit), 100)\n",
    "    y_line = np.exp(slope * x_line + intercept)  # Convert back from log scale\n",
    "\n",
    "    # Plot CCDF and best-fit line\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.step(real_data_sorted, ccdf_real, where='post', label='Real Data CCDF', linewidth=2, linestyle='--')\n",
    "    plt.plot(x_line, y_line, 'r-', label=f'Exponential Fit (slope={slope:.4f})', linewidth=2)\n",
    "\n",
    "    plt.xlabel('Time Duration (Steps)')\n",
    "    plt.ylabel('CCDF')\n",
    "    plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
    "    plt.yscale(\"log\")  # Keep y-axis in log scale\n",
    "    plt.xscale(\"linear\")  # Keep x-axis in linear scale\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    exp_fit_d = normalize_transition_time(exp_fit_p, 0.005, exp_fit_r)\n",
    "\n",
    "    max_pred = np.max(pred_durations)\n",
    "    min_pred = np.min(pred_durations)\n",
    "    difference = abs(max_pred - min_pred)\n",
    "    dur_diff_n = normalize_transition_time(difference, 10000, abs(np.max(real_durations)-np.min(real_durations)))\n",
    "\n",
    "    rh, b = np.histogram(r, bins=100, density=True)\n",
    "    ph, _ = np.histogram(p, bins=b, density=True)\n",
    "\n",
    "    e = 1e-10\n",
    "    rh += e\n",
    "    ph += e\n",
    "\n",
    "    # Calculate KL divergence between the two histograms\n",
    "    kl = np.sum(rh * np.log(rh / ph))\n",
    "    nkl = normalize_transition_time(kl, 1, 0)\n",
    "\n",
    "    save_path = os.path.join(folder, \"timeseries\")\n",
    "\n",
    "    # Plot 3D PCA\n",
    "    def detect_transitions_A_to_B(u_series, upper, lower):\n",
    "        transitions = []\n",
    "        transition_values = []\n",
    "        i = 0\n",
    "        while i < len(u_series) - 1:\n",
    "            if u_series[i-1] > upper and u_series[i] <= upper:\n",
    "                j = i + 1\n",
    "                while j < len(u_series) and u_series[j] <= upper:\n",
    "                    if u_series[j] < lower:\n",
    "                        transitions.append(i)\n",
    "                        transition_values.append(u_series[i])\n",
    "                        break\n",
    "                    j += 1\n",
    "                i = j\n",
    "            else:\n",
    "                i += 1\n",
    "        return np.array(transitions), np.array(transition_values)\n",
    "\n",
    "    def detect_transitions_B_to_A(u_series, upper, lower):\n",
    "        transitions = []\n",
    "        transition_values = []\n",
    "        i = 0\n",
    "        while i < len(u_series) - 1:\n",
    "            if u_series[i-1] < lower and u_series[i] >= lower:\n",
    "                j = i + 1\n",
    "                while j < len(u_series) and u_series[j] >= lower:\n",
    "                    if u_series[j] > upper:\n",
    "                        transitions.append(i)\n",
    "                        transition_values.append(u_series[i])\n",
    "                        break\n",
    "                    j += 1\n",
    "                i = j\n",
    "            else:\n",
    "                i += 1\n",
    "        return np.array(transitions), np.array(transition_values)\n",
    "\n",
    "    ssw_indices_A1, ssw_transition_values_A1 = detect_transitions_A_to_B(real_data[:, 1, 63], upper, lower)\n",
    "    ssw_indices_A0, ssw_transition_values_A0 = detect_transitions_A_to_B(real_data[:, 0, 63], upper, lower)\n",
    "    ssw_indices_B1, ssw_transition_values_B1 = detect_transitions_B_to_A(real_data[:, 1, 63], upper, lower)\n",
    "    ssw_indices_B0, ssw_transition_values_B0 = detect_transitions_B_to_A(real_data[:, 0, 63], upper, lower)\n",
    "\n",
    "    AB_transitions = np.union1d(ssw_indices_A1, ssw_indices_A0)\n",
    "    BA_transitions = np.union1d(ssw_indices_B1, ssw_indices_B0)\n",
    "    transition_indices = np.union1d(AB_transitions, BA_transitions)\n",
    "    total_len = len(real_data)\n",
    "    non_ssw_indices_A1 = np.where((real_data[:, 1, 63] > upper) & (~np.isin(np.arange(total_len), transition_indices)))[0]\n",
    "    non_ssw_indices_A0 = np.where((real_data[:, 0, 63] > upper) & (~np.isin(np.arange(total_len), transition_indices)))[0]\n",
    "    non_ssw_indices_B1 = np.where((real_data[:, 1, 63] < lower) & (~np.isin(np.arange(total_len), transition_indices)))[0]\n",
    "    non_ssw_indices_B0 = np.where((real_data[:, 0, 63] < lower) & (~np.isin(np.arange(total_len), transition_indices)))[0]\n",
    "\n",
    "    n_samples = min(len(ssw_indices_A1), len(ssw_indices_A0), len(non_ssw_indices_A1), len(non_ssw_indices_A0))\n",
    "    non_ssw_indices_A1 = np.random.choice(non_ssw_indices_A1, size=n_samples, replace=False)\n",
    "    non_ssw_indices_A0 = np.random.choice(non_ssw_indices_A0, size=n_samples, replace=False)\n",
    "    non_ssw_indices_B1 = np.random.choice(non_ssw_indices_B1, size=n_samples, replace=False)\n",
    "    non_ssw_indices_B0 = np.random.choice(non_ssw_indices_B0, size=n_samples, replace=False)\n",
    "    non_ssw_transition_values_A1 = zonal_wind[non_ssw_indices_A1]\n",
    "    non_ssw_transition_values_A0 = zonal_wind[non_ssw_indices_A0]\n",
    "    non_ssw_transition_values_B1 = zonal_wind[non_ssw_indices_B1]\n",
    "    non_ssw_transition_values_B0 = zonal_wind[non_ssw_indices_B0]\n",
    "\n",
    "    print(f\"SSW Transitions A to B: {len(ssw_indices_A1)}, Mean Value: {np.mean(ssw_transition_values_A1):.2f}\")\n",
    "    print(f\"SSW Transitions A to B: {len(ssw_indices_A0)}, Mean Value: {np.mean(ssw_transition_values_A0):.2f}\")\n",
    "    print(f\"SSW Transitions B to A: {len(ssw_indices_B1)}, Mean Value: {np.mean(ssw_transition_values_B1):.2f}\")\n",
    "    print(f\"SSW Transitions B to A: {len(ssw_indices_B0)}, Mean Value: {np.mean(ssw_transition_values_B0):.2f}\")\n",
    "    print(f\"Non-SSW Transitions A: {len(non_ssw_indices_A1)}, Mean Value: {np.mean(non_ssw_transition_values_A1):.2f}\")\n",
    "    print(f\"Non-SSW Transitions A: {len(non_ssw_indices_A0)}, Mean Value: {np.mean(non_ssw_transition_values_A0):.2f}\")\n",
    "    print(f\"Non-SSW Transitions B: {len(non_ssw_indices_B1)}, Mean Value: {np.mean(non_ssw_transition_values_B1):.2f}\")\n",
    "    print(f\"Non-SSW Transitions B: {len(non_ssw_indices_B0)}, Mean Value: {np.mean(non_ssw_transition_values_B0):.2f}\")\n",
    "\n",
    "    X = np.vstack([\n",
    "        real_data[ssw_indices_A1, 1],\n",
    "        real_data[ssw_indices_A0, 0],\n",
    "        real_data[ssw_indices_B1, 1],\n",
    "        real_data[ssw_indices_B0, 0],\n",
    "        real_data[non_ssw_indices_A1, 1],\n",
    "        real_data[non_ssw_indices_A0, 0],\n",
    "        real_data[non_ssw_indices_B1, 1],\n",
    "        real_data[non_ssw_indices_B0, 0]\n",
    "    ]).astype(np.float32)\n",
    "\n",
    "    labels = (\n",
    "        [\"AB\"] * len(ssw_indices_A1) +\n",
    "        [\"AB\"] * len(ssw_indices_A0) +\n",
    "        [\"BA\"] * len(ssw_indices_B1) +\n",
    "        [\"BA\"] * len(ssw_indices_B0) +\n",
    "        [\"A\"] * len(non_ssw_indices_A1) +\n",
    "        [\"A\"] * len(non_ssw_indices_A0) +\n",
    "        [\"B\"] * len(non_ssw_indices_B1) +\n",
    "        [\"B\"] * len(non_ssw_indices_B0)\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    # Encode data\n",
    "    with torch.no_grad():\n",
    "        mu, logvar = model.encode(torch.tensor(X, dtype=torch.float32).cuda())\n",
    "        z = model.reparameterize(mu, logvar)\n",
    "        mu_np = mu.cpu().numpy()\n",
    "        logvar_np = logvar.cpu().numpy()\n",
    "        z_np = z.cpu().numpy()\n",
    "\n",
    "    print(\"Mu shape: \" , mu.shape)\n",
    "\n",
    "    AB_start = 0\n",
    "    AB_end = len(ssw_indices_A1) + len(ssw_indices_A0)\n",
    "    BA_start = AB_end\n",
    "    BA_end = AB_start + len(ssw_indices_B1) + len(ssw_indices_B0)\n",
    "    A_start = BA_end\n",
    "    A_end = A_start + len(non_ssw_indices_A1) + len(non_ssw_indices_A0)\n",
    "    B_start = A_end\n",
    "    B_end = B_start + len(non_ssw_indices_B1) + len(non_ssw_indices_B0)\n",
    "\n",
    "    print(\"Mu values for A_ssw: \", np.mean(mu_np[:AB_end, :]), \n",
    "          \"Mu values for B_ssw: \", np.mean(mu_np[AB_end:BA_end, :]), \n",
    "          \"Mu values for A_noSSW: \", np.mean(mu_np[BA_end:A_end, :]), \n",
    "          \"Mu values for B_noSSW: \", np.mean(mu_np[A_end:B_end, :]))\n",
    "\n",
    "    print(\"Logvar shape for A_ssw: \", np.mean(logvar_np[:AB_end, :]), \n",
    "          \"Logvar shape for B_ssw: \", np.mean(logvar_np[AB_end:BA_end, :]), \n",
    "          \"Logvar shape for A_noSSW: \", np.mean(logvar_np[BA_end:A_end, :]), \n",
    "          \"Logvar shape for B_noSSW: \", np.mean(logvar_np[A_end:B_end, :]))\n",
    "\n",
    "    print(\"Z values for A_ssw: \", np.mean(z_np[:AB_end, :]), \n",
    "          \"Z values for B_ssw: \", np.mean(z_np[AB_end:BA_end, :]), \n",
    "          \"Z values for A_noSSW: \", np.mean(z_np[BA_end:A_end, :]), \n",
    "          \"Z values for B_noSSW: \", np.mean(z_np[A_end:B_end, :]))\n",
    "\n",
    "    all_plot(r, p, xlp, yvp, xlr, yvr, exp_fit_p, exp_fit_r, nkl, exp_fit_d, dur_diff_n, mu_np, labels, save_path)\n",
    "\n",
    "if (CCDF):\n",
    "    real_data_1d = real_data[:, 1, 63]  # Now shape is (309700,)\n",
    "    predictions_1d = predictions[:, 0, 63]  # shape (300000,)\n",
    "    \n",
    "    # Function to calculate transition durations\n",
    "    def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
    "        times_between_transitions = []\n",
    "        transition_start = None\n",
    "        above_upper = False\n",
    "        below_lower = False\n",
    "\n",
    "        for i in range(1, len(y_values)):\n",
    "            if y_values[i] < lower_bound:  \n",
    "                below_lower = True\n",
    "                above_upper = False\n",
    "            elif y_values[i] > upper_bound:  \n",
    "                if below_lower and transition_start is not None:\n",
    "                    times_between_transitions.append(i - transition_start)\n",
    "                    transition_start = None  \n",
    "                above_upper = True\n",
    "                below_lower = False\n",
    "\n",
    "            if below_lower and transition_start is None:\n",
    "                transition_start = i\n",
    "\n",
    "        return times_between_transitions\n",
    "\n",
    "    # Compute transition durations for real data\n",
    "    real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
    "\n",
    "    # Compute transition durations for predictions data\n",
    "    pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
    "\n",
    "    # Plot setup\n",
    "    CCDF_sum = 0\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    def bootstrap_ci(data, num_bootstraps=1000, confidence_level=0.95):\n",
    "        sample_size = len(data)\n",
    "        bootstrap_means = np.zeros(num_bootstraps)\n",
    "        \n",
    "        for i in range(num_bootstraps):\n",
    "            bootstrap_sample = np.random.choice(data, size=sample_size, replace=True)\n",
    "            bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "        \n",
    "        ci_lower = np.percentile(bootstrap_means, (1 - confidence_level) / 2 * 100)\n",
    "        ci_upper = np.percentile(bootstrap_means, (1 + confidence_level) / 2 * 100)\n",
    "        \n",
    "        return np.mean(data), ci_lower, ci_upper\n",
    "\n",
    "    # === REAL DATA CCDF AND FIT ===\n",
    "    if len(real_durations) == 0:\n",
    "        print(\"No transitions detected in real data with current bounds!\")\n",
    "    else:\n",
    "        real_data_sorted = np.sort(real_durations)\n",
    "        ccdf_real = 1 - np.arange(1, len(real_data_sorted) + 1) / len(real_data_sorted)\n",
    "\n",
    "        valid_indices_real = ccdf_real > 0\n",
    "        x_fit_real = real_data_sorted[valid_indices_real]\n",
    "        y_fit_real = np.log(ccdf_real[valid_indices_real])\n",
    "\n",
    "        slope_real, intercept_real, *_ = linregress(x_fit_real, y_fit_real)\n",
    "\n",
    "        x_line_real = np.linspace(min(x_fit_real), max(x_fit_real), 40)\n",
    "        y_line_real = np.exp(slope_real * x_line_real + intercept_real)\n",
    "\n",
    "        # Create a grid of x values (time steps / durations)\n",
    "\n",
    "        bootstrap_mean = []\n",
    "        ci_lower_vals = []\n",
    "        ci_upper_vals = []\n",
    "\n",
    "        for x in x_line_real:\n",
    "            valid_indices = (real_durations > x).astype(float)\n",
    "            mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
    "            bootstrap_mean.append(mean_val)\n",
    "            ci_lower_vals.append(lower)\n",
    "            ci_upper_vals.append(upper)\n",
    "\n",
    "        bootstrap_mean = np.array(bootstrap_mean)\n",
    "        ci_lower_vals = np.array(ci_lower_vals)\n",
    "        ci_upper_vals = np.array(ci_upper_vals)\n",
    "\n",
    "        # Calculate error bars (difference from the bootstrap mean)\n",
    "        error_lower = bootstrap_mean - ci_lower_vals\n",
    "        error_upper = ci_upper_vals - bootstrap_mean\n",
    "\n",
    "        plt.step(real_data_sorted, ccdf_real, where='post', label='Real Data CCDF', linewidth=2, linestyle='--')\n",
    "        plt.errorbar(x_line_real, bootstrap_mean, yerr=[error_lower, error_upper],\n",
    "                fmt='o', color='blue', capsize=3, ecolor='blue', label='Real Bootstrap 95% CI')\n",
    "        plt.plot(x_line_real, y_line_real, 'b-', label=f'Real Exp Fit (slope={slope_real:.4f})', linewidth=2)\n",
    "\n",
    "    # === PREDICTIONS CCDF AND FIT ===\n",
    "    if len(pred_durations) == 0:\n",
    "        print(\"No transitions detected in predictions with current bounds!\")\n",
    "    else:\n",
    "        pred_data_sorted = np.sort(pred_durations)\n",
    "        ccdf_pred = 1 - np.arange(1, len(pred_data_sorted) + 1) / len(pred_data_sorted)\n",
    "\n",
    "        valid_indices_pred = ccdf_pred > 0\n",
    "        x_fit_pred = pred_data_sorted[valid_indices_pred]\n",
    "        y_fit_pred = np.log(ccdf_pred[valid_indices_pred])\n",
    "\n",
    "        slope_pred, intercept_pred, *_ = linregress(x_fit_pred, y_fit_pred)\n",
    "\n",
    "        x_line_pred = np.linspace(min(x_fit_pred), max(x_fit_pred), 40)\n",
    "        y_line_pred = np.exp(slope_pred * x_line_pred + intercept_pred)\n",
    "\n",
    "        # Create a grid of x values (time steps / durations)\n",
    "\n",
    "        bootstrap_mean = []\n",
    "        ci_lower_vals = []\n",
    "        ci_upper_vals = []\n",
    "\n",
    "        for x in x_line_pred:\n",
    "            valid_indices = (pred_durations > x).astype(float)\n",
    "            mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
    "            bootstrap_mean.append(mean_val)\n",
    "            ci_lower_vals.append(lower)\n",
    "            ci_upper_vals.append(upper)\n",
    "\n",
    "        bootstrap_mean = np.array(bootstrap_mean)\n",
    "        ci_lower_vals = np.array(ci_lower_vals)\n",
    "        ci_upper_vals = np.array(ci_upper_vals)\n",
    "\n",
    "        # Calculate error bars (difference from the bootstrap mean)\n",
    "        error_lower = bootstrap_mean - ci_lower_vals\n",
    "        error_upper = ci_upper_vals - bootstrap_mean\n",
    "\n",
    "        plt.step(pred_data_sorted, ccdf_pred, where='post', label='Predictions CCDF', linewidth=2, linestyle='-.', color='red')\n",
    "        plt.errorbar(x_line_pred, bootstrap_mean, yerr=[error_lower, error_upper],\n",
    "                fmt='o', color='red', capsize=3, ecolor='red', label='Pred Bootstrap 95% CI')\n",
    "        plt.plot(x_line_pred, y_line_pred, 'r-', label=f'Pred Exp Fit (slope={slope_pred:.4f})', linewidth=2)\n",
    "\n",
    "        CCDF_sum += slope_pred\n",
    "\n",
    "    # Plot labels and formatting\n",
    "    plt.xlabel('Time Duration (Steps)')\n",
    "    plt.ylabel('CCDF')\n",
    "    plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
    "    plt.yscale(\"log\")  # y-axis log scale\n",
    "    plt.xscale(\"linear\")  # x-axis linear scale\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder, f\"CCDF_plot\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "if (Bi_modal_distribution):\n",
    "    zonal_wind_data_real = real_data[:, 1, 63]  # variable index 1 (e.g., zonal wind), level 60\n",
    "    zonal_wind_data_predictions = predictions[:, 0, 63]  # variable index 0 (predictions), level 60\n",
    "\n",
    "    print(f\"Shape of zonal_wind_data_real: {zonal_wind_data_real.shape}\")\n",
    "    print(f\"Shape of zonal_wind_data_predictions: {zonal_wind_data_predictions.shape}\")\n",
    "\n",
    "    # Plot the bimodal histogram\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create histograms (overlaid)\n",
    "    sns.histplot(zonal_wind_data_real, bins=50, kde=True, color='black', alpha=0.6, element='step', label='Real Data')\n",
    "    sns.histplot(zonal_wind_data_predictions, bins=50, kde=True, color='red', alpha=0.6, element='step', label='Predictions')\n",
    "\n",
    "    # Customize plot labels and title\n",
    "    plt.title('Distribution of Zonal Winds For Real Data and Predictions', fontsize=16)\n",
    "    plt.xlabel('Zonal Wind (m/s)', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "    # Add vertical lines at means\n",
    "    plt.axvline(np.mean(zonal_wind_data_real), color='black', linestyle='--', label=f'Real Mean: {np.mean(zonal_wind_data_real):.2f}')\n",
    "    plt.axvline(np.mean(zonal_wind_data_predictions), color='red', linestyle='--', label=f'Pred Mean: {np.mean(zonal_wind_data_predictions):.2f}')\n",
    "\n",
    "    # Final plot settings\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder, \"bi_modal_distribution\")\n",
    "    save_path = os.path.join(save_path, \"bi_modal_distribution_plot\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "if (single_step_profiles):\n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    # === Load model weights ===\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.eval()\n",
    "\n",
    "    # === Randomly sample time points from real data ===\n",
    "    time_indices = random.sample(range(0, real_data.shape[0] - 2), NUM_SAMPLES)\n",
    "    print(f\"Randomly sampled time steps: {time_indices}\")\n",
    "\n",
    "    # === Time series visualization ===\n",
    "    real_data_timeseries = real_data[:, 1, level]\n",
    "    time_steps_all = np.arange(len(real_data_timeseries))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(time_steps_all, real_data_timeseries, label=\"Real Data at Level 61\", color='blue')\n",
    "\n",
    "    # Mark sample points\n",
    "    for idx_num, idx in enumerate(time_indices):\n",
    "        plt.axvline(x=idx, color='green', linestyle='--', linewidth=2)\n",
    "    if len(time_indices) > 0:\n",
    "        plt.axvline(x=time_indices[0], color='green', linestyle='--', linewidth=2, label='Sampled Points')\n",
    "\n",
    "    plt.title(\"Real Data Time Series with Sampled Points Highlighted\")\n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.ylabel(\"U (m/s) at Level 61\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(SAVE_DIR, \"real_data_timeseries_with_samples.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "    # === Iterate over each sampled time point ===\n",
    "    for i, time_step in enumerate(time_indices):\n",
    "        next_time_step = time_step + 1\n",
    "\n",
    "        # === Real data: current and next ===\n",
    "        real_current = real_data[time_step, 1, :]       \n",
    "        real_next = real_data[next_time_step, 1, :]      \n",
    "\n",
    "        # === Normalize real_current and make prediction for next step ===\n",
    "        initial_cond = torch.reshape(torch.tensor(psi[time_step,start:end]), [1, num_variables])\n",
    "        z = torch.zeros([1,latent_dim])\n",
    "        num_ens = 1\n",
    "        pred = np.zeros ([time_step, num_variables, num_ens])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn_like(z)\n",
    "            print(z.shape, initial_cond.shape)\n",
    "            y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
    "\n",
    "        # === Denormalize predicted next ===\n",
    "        pred_next_denorm = y.squeeze() * std_psi.squeeze() + mean_psi.squeeze()\n",
    "\n",
    "        # === Extract U, Re(Psi), Im(Psi) components ===\n",
    "        # U profiles\n",
    "        U_current_real = real_current[51:74]\n",
    "        U_next_real = real_next[51:74]\n",
    "        U_next_pred = pred_next_denorm[51:74]\n",
    "\n",
    "        # Re(Psi) profiles\n",
    "        RePsi_current_real = real_current[0:24]\n",
    "        RePsi_next_real = real_next[0:24]\n",
    "        RePsi_next_pred = pred_next_denorm[0:24]\n",
    "\n",
    "        # Im(Psi) profiles\n",
    "        ImPsi_current_real = real_current[25:50]\n",
    "        ImPsi_next_real = real_next[25:50]\n",
    "        ImPsi_next_pred = pred_next_denorm[25:50]\n",
    "\n",
    "        # === Differences ===\n",
    "        U_diff_real = U_next_real - U_current_real\n",
    "        U_diff_pred = U_next_pred - U_current_real\n",
    "\n",
    "        RePsi_diff_real = RePsi_next_real - RePsi_current_real\n",
    "        RePsi_diff_pred = RePsi_next_pred - RePsi_current_real\n",
    "\n",
    "        ImPsi_diff_real = ImPsi_next_real - ImPsi_current_real\n",
    "        ImPsi_diff_pred = ImPsi_next_pred - ImPsi_current_real\n",
    "\n",
    "        # === Create a single figure with 3 rows (U, Re(Psi), Im(Psi)) ===\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(16, 18))  # 3 rows, 2 columns (Profile and Difference)\n",
    "\n",
    "        z_levels_U = np.linspace(0, 70, 23)\n",
    "        z_levels_RePsi = np.linspace(0, 70, 24)\n",
    "        z_levels_ImPsi = np.linspace(0, 70, 25)\n",
    "\n",
    "        # --- U ---\n",
    "        axes[0, 0].plot(U_current_real, z_levels_U, 'x-', label=\"Real Current\")\n",
    "        axes[0, 0].plot(U_next_real, z_levels_U, 'd-', label=\"Real Next\")\n",
    "        axes[0, 0].plot(U_next_pred, z_levels_U, 's--', label=\"Predicted Next\")\n",
    "        axes[0, 0].set_title(f\"U Profiles @ Step {time_step}\")\n",
    "        axes[0, 0].set_xlabel(\"U (m/s)\")\n",
    "        axes[0, 0].set_ylabel(\"Vertical Levels (km)\")\n",
    "        axes[0, 0].legend()\n",
    "\n",
    "        axes[0, 1].plot(U_diff_real, z_levels_U, 'xb', label=\"Real  (Next - Current)\")\n",
    "        axes[0, 1].plot(U_diff_pred, z_levels_U, 'o--r', label=\"Pred  (Next - Current)\")\n",
    "        axes[0, 1].set_title(\"U Difference (Next - Current)\")\n",
    "        axes[0, 1].set_xlabel(\"U (m/s)\")\n",
    "        axes[0, 1].legend()\n",
    "\n",
    "        # --- Re(Psi) ---\n",
    "        axes[1, 0].plot(RePsi_current_real, z_levels_RePsi, 'x-', label=\"Real Current\")\n",
    "        axes[1, 0].plot(RePsi_next_real, z_levels_RePsi, 'd-', label=\"Real Next\")\n",
    "        axes[1, 0].plot(RePsi_next_pred, z_levels_RePsi, 's--', label=\"Predicted Next\")\n",
    "        axes[1, 0].set_title(f\"Re(Psi) Profiles @ Step {time_step}\")\n",
    "        axes[1, 0].set_xlabel(\"Re(Psi)\")\n",
    "        axes[1, 0].set_ylabel(\"Vertical Levels (km)\")\n",
    "        axes[1, 0].legend()\n",
    "\n",
    "        axes[1, 1].plot(RePsi_diff_real, z_levels_RePsi, 'xb', label=\"Real  (Next - Current)\")\n",
    "        axes[1, 1].plot(RePsi_diff_pred, z_levels_RePsi, 'o--r', label=\"Pred  (Next - Current)\")\n",
    "        axes[1, 1].set_title(\"Re(Psi) Difference (Next - Current)\")\n",
    "        axes[1, 1].set_xlabel(\"Re(Psi)\")\n",
    "        axes[1, 1].legend()\n",
    "\n",
    "        # --- Im(Psi) ---\n",
    "        axes[2, 0].plot(ImPsi_current_real, z_levels_ImPsi, 'x-', label=\"Real Current\")\n",
    "        axes[2, 0].plot(ImPsi_next_real, z_levels_ImPsi, 'd-', label=\"Real Next\")\n",
    "        axes[2, 0].plot(ImPsi_next_pred, z_levels_ImPsi, 's--', label=\"Predicted Next\")\n",
    "        axes[2, 0].set_title(f\"Im(Psi) Profiles @ Step {time_step}\")\n",
    "        axes[2, 0].set_xlabel(\"Im(Psi)\")\n",
    "        axes[2, 0].set_ylabel(\"Vertical Levels (km)\")\n",
    "        axes[2, 0].legend()\n",
    "\n",
    "        axes[2, 1].plot(ImPsi_diff_real, z_levels_ImPsi, 'xb', label=\"Real  (Next - Current)\")\n",
    "        axes[2, 1].plot(ImPsi_diff_pred, z_levels_ImPsi, 'o--r', label=\"Pred  (Next - Current)\")\n",
    "        axes[2, 1].set_title(\"Im(Psi) Difference (Next - Current)\")\n",
    "        axes[2, 1].set_xlabel(\"Im(Psi)\")\n",
    "        axes[2, 1].legend()\n",
    "\n",
    "        # === Finalize and Save ===\n",
    "        plt.suptitle(f\"Single Step Profile Comparisons at Time Step {time_step}\", fontsize=18)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "\n",
    "        save_path = os.path.join(SAVE_DIR, f\"Profile_Summary_point_{time_step}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Combined plot saved for sampled point {time_step}\")\n",
    "\n",
    "    # Final debug\n",
    "    print(\"Finished processing all sampled points.\")\n",
    "        # Debugging prints\n",
    "    print(predictions.shape) \n",
    "    print(real_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567c739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
