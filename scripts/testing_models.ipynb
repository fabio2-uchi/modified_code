{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init pack\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.nn.parallel import DataParallel\n",
    "\n",
    "psi = np.load('/home/danielboscu/Documents/code/AI_RES/data/actual/long_run_310k.npy')\n",
    "\n",
    "# Pre-processing\n",
    "\n",
    "psi = psi[:,1,:]\n",
    "\n",
    "mean_psi = np.mean(psi, axis=0, keepdims=True)\n",
    "std_psi = np.std(psi, axis=0, keepdims=True)\n",
    "psi = (psi - mean_psi) / std_psi\n",
    "\n",
    "lead = 1\n",
    "trainN = 250000\n",
    "valN = 50000\n",
    "index = 63\n",
    "\n",
    "# Defining the variable ranges\n",
    "variable_range = [(0,24), (25, 49), (50, 74), (0, 49), (0,74)]\n",
    "\n",
    "# Select the variable: 0 for real perturbation, 1 for imaginary perturbation, 2 for zonal winds\n",
    "variable = 3\n",
    "num_variables = variable_range[variable][1] - variable_range[variable][0] + 1\n",
    "print(num_variables)\n",
    "\n",
    "# Shuffle and map indices\n",
    "np.random.seed(42)\n",
    "valid_indices = np.arange(0, trainN - lead)\n",
    "shuffled_indices = np.random.permutation(valid_indices)\n",
    "\n",
    "# Now constrain the shuffled indices to the variable range\n",
    "np_psi_train_input = psi[shuffled_indices, variable_range[variable][0]:variable_range[variable][1]+1]\n",
    "np_psi_train_label = psi[shuffled_indices + lead, :]\n",
    "\n",
    "psi_train_input = torch.tensor(np_psi_train_input)\n",
    "psi_train_label = torch.tensor(np_psi_train_label)\n",
    "\n",
    "np_psi_val_input = psi[trainN:trainN+valN, variable_range[variable][0]:variable_range[variable][1]+1]\n",
    "np_psi_val_label = psi[trainN+lead:trainN+valN+lead, :]\n",
    "psi_val_input = torch.tensor(np_psi_val_input)\n",
    "psi_val_label =  torch.tensor(np_psi_val_label)\n",
    "\n",
    "print(psi.shape)\n",
    "print(psi_train_input.shape)\n",
    "print(psi_train_label.shape)\n",
    "print(psi_val_input.shape)\n",
    "print(psi_val_label.shape)\n",
    "\n",
    "# Define the encoder (MLP)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim, num_neurons):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(75, num_neurons)  # Input layer (2 + 2) -> Hidden layer (128)\n",
    "        self.fc2 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc3 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc4 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc5 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc6 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc_mu = nn.Linear(num_neurons, latent_dim)  # Hidden layer (128) -> Latent space (2)\n",
    "        self.fc_logvar = nn.Linear(num_neurons, latent_dim)  # Hidden layer (128) -> Log variance (2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # Activation function for hidden layer\n",
    "        x = torch.relu(self.fc2(x)) + x\n",
    "        x = torch.relu(self.fc3(x)) + x\n",
    "        x = torch.relu(self.fc4(x)) + x\n",
    "        x = torch.relu(self.fc5(x)) + x\n",
    "        x = torch.relu(self.fc6(x)) + x\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "# Define the decoder (MLP)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, condition_dim, num_neurons):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim + condition_dim, num_neurons)  # Input layer (2 + 2) -> Hidden layer (128)\n",
    "        self.fc2 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc3 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc4 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc5 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc6 = nn.Linear(num_neurons, num_neurons)  # Hidden layer (128) -> Hidden layer (128)\n",
    "        self.fc_output = nn.Linear(num_neurons, output_dim)  # Hidden layer (128) -> Output layer (2)\n",
    "\n",
    "    def forward(self, z, condition):\n",
    "        z = torch.cat((z, condition[:, :50]), dim=1)  # Concatenate latent vector and condition\n",
    "        z = torch.relu(self.fc1(z))  # Activation function for hidden layer\n",
    "        z = torch.relu(self.fc2(z)) + z\n",
    "        z = torch.relu(self.fc3(z)) + z\n",
    "        z = torch.relu(self.fc4(z)) + z\n",
    "        z = torch.relu(self.fc5(z)) + z\n",
    "        z = torch.relu(self.fc6(z)) + z\n",
    "        output = self.fc_output(z)\n",
    "        return output\n",
    "\n",
    "# Define the VAE model\n",
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, condition_dim, num_neurons):\n",
    "        super(ConditionalVAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim, num_neurons)\n",
    "        self.decoder = Decoder(latent_dim, output_dim, condition_dim, num_neurons)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def decode(self, z, condition):\n",
    "        return self.decoder(z, condition)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        output = self.decode(z, condition)\n",
    "        return output, mu, logvar\n",
    "\n",
    "output_dim = 75\n",
    "latent_dim = 32\n",
    "condition_dim = num_variables\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSING BY EXP FIT\n",
    "# TO-DO: Check if crps is correct\n",
    "\n",
    "from scipy.stats import linregress\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "from scipy.stats import norm\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "def normalize_transition_time(s, neuro_num, r):\n",
    "    \"\"\"\n",
    "    Normalize the transition time based on the specified num_neurons and reference value.\n",
    "\n",
    "    Args:\n",
    "        s (float): The transition time to normalize.\n",
    "        neuro_num (float): The num_neurons value for normalization.\n",
    "        r (float): The reference value for normalization.\n",
    "\n",
    "    Returns:\n",
    "        norm (float): The normalized transition time.\n",
    "    \"\"\"\n",
    "    norm = 1 - np.exp(-np.abs((s - r)) / neuro_num)\n",
    "    return norm\n",
    "\n",
    "# Code from Ira Shokar but slightly changed\n",
    "def crps_score(p, y):\n",
    "    \"\"\"\n",
    "    Calculate CRPS for given predictions and observations.\n",
    "\n",
    "    Args:\n",
    "        p (Tensor): Predictions, shape (N, D) where N = ens_num and D is the dimension of the prediction.\n",
    "        y (Tensor): Observations, shape (D) where D is the dimension of the observation.\n",
    "\n",
    "    Returns:\n",
    "        crps (float): The CRPS score.\n",
    "    \"\"\"\n",
    "    y  = y.unsqueeze(0)\n",
    "    # First term: mean distance from observations to ensemble members\n",
    "    mae     = torch.cdist(y, p, 1).mean()\n",
    "    # Second term: mean distance between ensemble members (properly normalized)\n",
    "    ens_var = torch.cdist(p, p, 1).mean()\n",
    "    \n",
    "    return mae - 0.5 * ens_var\n",
    "\n",
    "# Function to calculate transition durations\n",
    "def calculate_transition_durations(y, u, l):\n",
    "    \"\"\"\n",
    "    Calculate the return periods with user-defined upper and lower bounds.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): The time series data.\n",
    "        u (float): The upper bound for the transition.\n",
    "        l (float): The lower bound for the transition.\n",
    "\n",
    "    Returns:\n",
    "        t_times (list): The list of return periods for transitions.\n",
    "    \"\"\"\n",
    "\n",
    "    t_times = []\n",
    "    s = None\n",
    "    above_u = False\n",
    "    below_l = False\n",
    "    for i in range(1, len(y)):\n",
    "        if y[i] < l:  \n",
    "            below_l = True\n",
    "            above_u = False\n",
    "        elif y[i] > u:  \n",
    "            if below_l and s is not None:\n",
    "                t_times.append(i - s)\n",
    "                s = None  \n",
    "            above_u = True\n",
    "            below_l = False\n",
    "\n",
    "        if below_l and s is None:\n",
    "            s = i\n",
    "    return t_times\n",
    "\n",
    "def KL_coefficient(r, p, num_neurons, cycle, KL_by_dim_cycle, L1_by_dym_cycle):\n",
    "    \"\"\"\n",
    "    Calculate the KL divergence between two distributions and normalize it.\n",
    "\n",
    "    Args:\n",
    "        r (np.array): Real distribution.\n",
    "        p (np.array): Predicted distribution.\n",
    "        num_neurons (float): num_neurons value for normalization.\n",
    "        cycle (int): Cycle number for tracking.\n",
    "        KL_by_dim_cycle (dict): Dictionary to store KL divergence values by dimension and cycle.\n",
    "\n",
    "    Returns:\n",
    "        r (np.array): Processed real distribution.\n",
    "        p (np.array): Processed predicted distribution.\n",
    "        nkl (float): Normalized KL divergence.\n",
    "    \"\"\"\n",
    "    # Calculating KL divergence\n",
    "    r = r[:300000, 1, 63]\n",
    "    p = p[:300000]\n",
    "    \n",
    "    rh, b = np.histogram(r, bins=100, density=True)\n",
    "    ph, _ = np.histogram(p, bins=b, density=True)\n",
    "\n",
    "    abs_diff = np.abs(rh-ph)\n",
    "    max_diff = np.max(abs_diff)\n",
    "    norm_diff = max_diff / (np.max(rh) + np.max(ph))\n",
    "\n",
    "    e = 1e-10\n",
    "    rh += e\n",
    "    ph += e\n",
    "\n",
    "    # Calculate KL divergence between the two histograms\n",
    "    kl = np.sum(rh * np.log(rh / ph))\n",
    "    nkl = normalize_transition_time(kl, 1, 0)\n",
    "\n",
    "    KL_by_dim_cycle[num_neurons][cycle].append(nkl)\n",
    "    L1_by_dym_cycle[num_neurons][cycle].append(norm_diff)\n",
    "    \n",
    "    return r, p, nkl, norm_diff\n",
    "\n",
    "def CCDF_fit(p_times, s):\n",
    "    \"\"\"\n",
    "    Calculate the slope of the CCDF of transition times and normalize it.\n",
    "\n",
    "    Args:\n",
    "        p_times (list): Transition times from predictions.\n",
    "        s (float): Real value for normalization.\n",
    "    \n",
    "    Returns:\n",
    "        np_slope (float): Normalized slope of the CCDF.\n",
    "    \"\"\"\n",
    "    # === PREDICTIONS CCDF AND FIT ===\n",
    "    if len(p_times) > 0 and len(np.unique(p_times)) > 1:\n",
    "        sp_times = np.sort(p_times)\n",
    "        p_ccdf = 1 - np.arange(1, len(sp_times) + 1) / len(sp_times)\n",
    "\n",
    "        p_v_indices = p_ccdf > 0\n",
    "        px_fit = sp_times[p_v_indices]\n",
    "        py_fit = np.log(p_ccdf[p_v_indices])\n",
    "\n",
    "        p_slope, _, *_ = linregress(px_fit, py_fit)\n",
    "        np_slope = normalize_transition_time(p_slope, 0.005, s)\n",
    "        return np_slope\n",
    "\n",
    "    else:\n",
    "        print(\"No transitions detected in predictions for CCDF slope evaluation.\")\n",
    "\n",
    "def Mean_and_std_of_predictions(p_times, r_times, neuro_num, cc, transitions_by_dim_cycle, transitions_normalized_by_dim_cycle, transitions_normalized_std_by_dim_cycle):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of transition times from predictions and normalize them.\n",
    "\n",
    "    Args:\n",
    "        p_times (list): Transition times from predictions.\n",
    "        r_times (list): Transition times from real data.\n",
    "        neuro_num (float): num_neurons value for normalization.\n",
    "        cc (int): Cycle number for tracking.\n",
    "        transitions_by_dim_cycle (dict): Dictionary to store transition times by dimension and cycle.\n",
    "        transitions_normalized_by_dim_cycle (dict): Dictionary to store normalized transition times by dimension and cycle.\n",
    "        transitions_normalized_std_by_dim_cycle (dict): Dictionary to store normalized standard deviations by dimension and cycle.\n",
    "\n",
    "    Returns:\n",
    "        npd_mean (float): Normalized mean of transition times.\n",
    "        npd_std (float): Normalized standard deviation of transition times.\n",
    "    \"\"\"\n",
    "    p_mean = np.mean(p_times)\n",
    "    p_std = np.std(p_times)\n",
    "\n",
    "    pd_mean = abs(p_mean - np.mean(r_times))\n",
    "    pd_std = abs(p_std - np.std(r_times))\n",
    "\n",
    "    npd_mean = normalize_transition_time(pd_mean, 1000, np.mean(r_times))\n",
    "    npd_std = normalize_transition_time(pd_std, 1000, np.std(r_times))\n",
    "\n",
    "    npd_std = 1 if npd_std == 0 else npd_std\n",
    "\n",
    "    transitions_by_dim_cycle[neuro_num][cc].append(pd_mean)\n",
    "    transitions_normalized_by_dim_cycle[neuro_num][cc].append(npd_mean)\n",
    "    transitions_normalized_std_by_dim_cycle[neuro_num][cc].append(npd_std)\n",
    "\n",
    "    return npd_mean, npd_std\n",
    "\n",
    "# KL Annealing (FROM PAPER)\n",
    "def frange_cycle_linear(start, stop, n_epoch, n_cycle=4, ratio=0.5):\n",
    "    \"\"\"\n",
    "    Generate a linear schedule for KL annealing over multiple cycles.\n",
    "\n",
    "    Args:\n",
    "        start (float): Starting value of the schedule.\n",
    "        stop (float): Stopping value of the schedule.\n",
    "        n_epoch (int): Total number of epochs.\n",
    "        n_cycle (int): Number of cycles for the schedule.\n",
    "        ratio (float): Ratio of the cycle length to the total number of epochs.\n",
    "\n",
    "    Returns:\n",
    "        L (np.array): Array containing the linear schedule values for each epoch.\n",
    "    \"\"\"\n",
    "    L = np.ones(n_epoch)\n",
    "    period = n_epoch/n_cycle\n",
    "    step = (stop-start)/(period*ratio) # linear schedule\n",
    "\n",
    "    for c in range(n_cycle):\n",
    "\n",
    "        v , i = start , 0\n",
    "        while v <=stop and (int(i+c*period) < n_epoch):\n",
    "            L[int(i+c*period)] = v\n",
    "            v += step\n",
    "            i += 1\n",
    "    return L\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "def Timeseries_plot(y, p, fig):\n",
    "    \"\"\"\n",
    "    Plot the timeseries.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): Actual zonal wind values.\n",
    "        p (np.array): Predicted zonal wind values.\n",
    "        ep (int): Current epoch number.\n",
    "        ax (matplotlib.axes.Axes): Axes object to plot on.\n",
    "\n",
    "    Returns:\n",
    "        None. Just plots the timeseries on the provided axes.\n",
    "    \"\"\"\n",
    "    fig.add_trace(go.Scatter(y=y[:60000], mode='lines', name=\"Actual\", line=dict(color='blue')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(y=p[:60000], mode='lines', name=\"Predictions\", line=dict(color='red')), row=1, col=1)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Days\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Zonal Wind Value\", row=1, col=1)\n",
    "\n",
    "    # ax.legend(['Predictions', 'Actual'])\n",
    "    # ax.grid(True)\n",
    "\n",
    "    # save_path = os.path.join(folder, \"timeseries\")\n",
    "    # save_path = os.path.join(save_path, f\"timeseries_plot_{epoch+1}.png\")\n",
    "\n",
    "    # plt.savefig(save_path)\n",
    "\n",
    "    # plt.show()75\n",
    "\n",
    "def PDF_plot(yv, p, pdf_dt, fig):\n",
    "    \"\"\"\n",
    "    Plot PDFs of the zonal wind values.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): Actual zonal wind values.\n",
    "        p (np.array): Predicted zonal wind values.\n",
    "        ep (int): Current epoch number.\n",
    "        pdf_dt (float): KL diff between the PDFs of actual and predicted values.\n",
    "        ax (matplotlib.axes.Axes): Axes object to plot on.\n",
    "\n",
    "    Returns:\n",
    "        None. Just plots the PDFs on the provided axes.\n",
    "    \"\"\"\n",
    "\n",
    "    # sns.histplot(y, bins=100, kde=True, color='black', alpha=0.6, element='step', label='Real Data', ax=ax)\n",
    "    # sns.histplot(p, bins=100, kde=True, color='red', alpha=0.6, element='step', label='Predictions', ax=ax)\n",
    "\n",
    "    fig.add_trace(go.Histogram(x=yv, histnorm='probability density', name='Actual Data', opacity=0.6, marker_color='black'), row=2, col=1)\n",
    "    fig.add_trace(go.Histogram(x=p, histnorm='probability density', name='Predictions', opacity=0.6, marker_color='red'), row=2, col=1)\n",
    "\n",
    "    fig.update_layout(title_text=f\"Probability Distribution Functions (PDFs) | KL Error: {pdf_dt:.4f}\")\n",
    "    fig.update_xaxes(title_text='Zonal Wind (m/s)', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Frequency', row=2, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=[np.mean(yv), np.mean(yv)], y=[0,0.18], mode='lines', line=dict(color='black', width=2, dash='dash'), name=f'Actual Mean: {np.mean(yv):.2f}'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=[np.mean(p), np.mean(p)], y=[0,0.18], mode='lines', line=dict(color='red', width=2, dash='dash'), name=f'Pred Mean: {np.mean(p):.2f}'), row=2, col=1)\n",
    "\n",
    "    fig.update_layout(legend=dict())\n",
    "    fig.update_xaxes(showgrid=True, gridcolor='lightgray', gridwidth=1)\n",
    "\n",
    "    # save_path = os.path.join(folder, \"bi_modal_distri\")\n",
    "    # save_path = os.path.join(save_path, f\"bi_modal_distribution_plot_{epoch+1}.png\")\n",
    "    # plt.savefig(save_path)\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "def Exp_fit_plot(xlp, yvp, xlr, yvr, p_exp_fit, r_exp_fit, exp_d, range_d, fig):\n",
    "    \"\"\"\n",
    "    Plot the exponential fits of transition return periods.\n",
    "\n",
    "    Args:\n",
    "        xlp (np.array): X values for predicted exponential fit.\n",
    "        yvp (np.array): Y values for predicted exponential fit.\n",
    "        xlr (np.array): X values for real exponential fit.\n",
    "        yvr (np.array): Y values for real exponential fit.\n",
    "        p_exp_fit (float): Slope of the predicted exponential fit.\n",
    "        r_exp_fit (float): Slope of the real exponential fit.\n",
    "        ep (int): Current epoch number.\n",
    "        exp_d (float): Exponential fit error for predictions.\n",
    "        range_d (float): Range error for predictions.\n",
    "        ax (matplotlib.axes.Axes): Axes object to plot on.\n",
    "\n",
    "    Returns:\n",
    "        None. Just plots the exponential fits on the provided axes.\n",
    "    \"\"\"\n",
    "    fig.add_trace(go.Scatter(x=xlp, y=yvp, mode='lines', name='Predicted Fit', line=dict(color='blue')), row=2, col=2)\n",
    "    fig.add_trace(go.Scatter(x=xlr, y=yvr, mode='lines', name='Real Fit', line=dict(color='red')), row=2, col=2)\n",
    "\n",
    "    fig.update_xaxes(title_text='Time Duration (Steps)', row=2, col=2)\n",
    "    fig.update_yaxes(title_text='Exponential Fit', row=2, col=2)\n",
    "    fig.update_layout(title_text=f\"Exponential Fits of Transition Return Periods | Exp Error: {exp_d:.4f} | Range Error: {range_d:.4f}\", title_fontsize=16)\n",
    "\n",
    "    fig.update_yaxes(type=\"linear\", row=2, col=2)  # y-axis log scale\n",
    "    fig.update_xaxes(type=\"linear\", row=2, col=2)  # x-axis linear scale\n",
    "\n",
    "    # save_path = os.path.join(folder, \"expo_fit\")\n",
    "    # save_path = os.path.join(save_path, f\"expo_fit_plot_{epoch}.png\")\n",
    "    # plt.savefig(save_path)\n",
    "    # plt.show()\n",
    "\n",
    "def PCA_plot(fig, mu_np, labels):\n",
    "    # PCA\n",
    "    num_components = 3\n",
    "    pca = PCA(n_components=num_components)\n",
    "    print(f\"==>> pca: {pca}\")\n",
    "\n",
    "    #mu\n",
    "    latent_3d = pca.fit_transform(mu_np)\n",
    "    print(f\"==>> latent_3d: {latent_3d.shape}\")\n",
    "\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    total_explained = np.sum(explained)\n",
    "    print(f\"Explained variance by PC1: {explained[0]:.4f}\")\n",
    "    print(f\"Explained variance by PC2: {explained[1]:.4f}\")\n",
    "    print(f\"Explained variance by PC3: {explained[2]:.4f}\")\n",
    "    print(f\"Total explained variance (PC1+2+3): {total_explained:.4f}\")\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(latent_3d[:, 0:num_components], columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "    print(mu_np, labels, df)\n",
    "    df[\"Category\"] = labels\n",
    "    px_fig = px.scatter_3d(df, x=\"PC1\", y=\"PC2\", z=\"PC3\", color=\"Category\",\n",
    "                    opacity=0.75,\n",
    "                    title=\"Latent Space Projection: 4-Way Classification, mu\",\n",
    "                    width=1500, height=1400)\n",
    "    for trace in px_fig.data:\n",
    "        fig.add_trace(trace, row=1, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='PC1',\n",
    "            yaxis_title='PC2',\n",
    "            zaxis_title='PC3'\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=0),\n",
    "    )\n",
    "\n",
    "\n",
    "def Final_KL_PDF_plot(KL_by_dim_cycle, r, neuro_num, ncc, f):\n",
    "    \"\"\"\n",
    "    Plot the average transition values across all cycles.\n",
    "\n",
    "    Args:\n",
    "        KL_by_dim_cycle (dict): Dictionary containing KL PDF values by dimension and cycle.\n",
    "        r (float): Real data value for comparison.\n",
    "        neuro_num (float): num_neurons coefficient for normalization.\n",
    "        ncc (int): Number of cycles.\n",
    "        f (str): Folder path to save the plot.\n",
    "    \n",
    "    Returns:\n",
    "        None. Just plots the average transition values and saves the figure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for c in range(ncc):\n",
    "        plt.plot(KL_by_dim_cycle[neuro_num][c], 'o-', label=f'Cycle {c}')\n",
    "    \n",
    "    plt.xlabel('Epoch within Cycle')\n",
    "    plt.ylabel('KL Difference Normalized')\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(f'KL Difference Value between PDFs Normalized)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    f = os.path.join(f, f\"KL_diff_all_cycles.png\")\n",
    "    plt.savefig(f)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def Final_exp_fit_plot(exp_fit_by_dim_cycle, r_exp_fit, neuro_num, ncc, f):\n",
    "    \"\"\"\n",
    "    Plot the exponential fit values across all cycles.\n",
    "\n",
    "    Args:\n",
    "        exp_fit_by_dim_cycle (dict): Dictionary containing exponential fit values by dimension and cycle.\n",
    "        r_exp_fit (float): Real data value for comparison.\n",
    "        neuro_num (float): num_neurons coefficient for normalization.\n",
    "        ncc (int): Number of cycles.\n",
    "        f (str): Folder path to save the plot.\n",
    "\n",
    "    Returns:\n",
    "        None. Just plots the exponential fit values and saves the figure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for c in range(ncc):\n",
    "        plt.plot(exp_fit_by_dim_cycle[neuro_num][c], 'o-', label=f'Cycle {c}')\n",
    "    \n",
    "    plt.axhline(y=r_exp_fit, color='r', linestyle='--', label='Real Data')\n",
    "\n",
    "    plt.xlabel('Epoch within Cycle')\n",
    "    plt.ylabel('Exponential Fit Value')\n",
    "    plt.title(f'Exponential Fit Progress (num_neurons Coefficient={neuro_num})')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "\n",
    "    f = os.path.join(f, f\"exponential_fit_plot_all_cycles.png\")\n",
    "    plt.savefig(f)\n",
    "    plt.close()\n",
    "    \n",
    "def all_plot(y, p, xlp, yvp, xlr, yvr, \n",
    "             p_exp_fit, r_exp_fit, pdf_dt, exp_dt, range_dt, mu_np, labels, folder):\n",
    "    \"\"\"\n",
    "    Comprehensive plot with timeseries, PDF, and exponential fit.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): Actual zonal wind values.\n",
    "        p (np.array): Predicted zonal wind values.\n",
    "        xlp (np.array): X values for predicted exponential fit.\n",
    "        yvp (np.array): Y values for predicted exponential fit.\n",
    "        xlr (np.array): X values for real exponential fit.\n",
    "        yvr (np.array): Y values for real exponential fit.\n",
    "        p_exp_fit (float): Slope of the predicted exponential fit.\n",
    "        r_exp_fit (float): Slope of the real exponential fit.\n",
    "        pdf_dt (float): KL divergence between the PDFs of actual and predicted values.\n",
    "        exp_dt (float): Exponential fit error for predictions.\n",
    "        range_dt (float): Range error for predictions.\n",
    "        ep (int): Current epoch number.\n",
    "        folder (str): Folder path to save the plot.\n",
    "    \n",
    "    Returns:\n",
    "        None. Just plots the timeseries, PDF, and exponential fit and saves the figure.\n",
    "    \"\"\"\n",
    "    fig = make_subplots(rows=2, cols=2, specs=[[{}, {\"type\":\"scene\", \"rowspan\": 2}], [{}, None]],\n",
    "                        subplot_titles=[\"Timeseries of Zonal Wind U(30)\", \"3D PCA Analysis of 32-D Latent Space (mu)\",\n",
    "                                        \"Probability Distribution Functions (PDFs)\"],\n",
    "                        horizontal_spacing=0.02, vertical_spacing=0.14)\n",
    "\n",
    "    Timeseries_plot(y[:30000], p[:30000], fig)\n",
    "    PDF_plot(y, p, pdf_dt, fig)\n",
    "    # Exp_fit_plot(xlp, yvp, xlr, yvr, \n",
    "    #              p_exp_fit, r_exp_fit, exp_dt, range_dt, px)\n",
    "    PCA_plot(fig, mu_np, labels)\n",
    "    \n",
    "    dt = np.sqrt(pdf_dt**2 + exp_dt**2 + range_dt**2)\n",
    "    fig.update_layout(title_text=f\"<b>Comprehensive Analysis of Zonal Wind Predictions | Euclidean Metric Error: {dt:.4f}</b>\",\n",
    "                      title_subtitle=dict(text=f\"PDF/KL Error: {pdf_dt:.4f}, Rate of Transitions Error: {exp_dt:.4f}, Time Range of Return Periods Error: {range_dt:.4f}\",\n",
    "                                          ),\n",
    "                      title_x=0.5,\n",
    "        width=1500, height=850,\n",
    "        margin=dict(l=80, r=50, t=150, b=80),\n",
    "        margin_pad=0.05,\n",
    "        paper_bgcolor='white',\n",
    "        font=dict(family=\"Arial, sans-serif\", size=14, color=\"#444\"),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=-0.15,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5,\n",
    "            font=dict(size=12)\n",
    "        ),\n",
    "        hovermode=\"closest\",)\n",
    "    fig.show()\n",
    "\n",
    "def Loss_plot(t_loss, v_loss, cc, neuro_num, f):\n",
    "    \"\"\"\n",
    "    Plot the training and validation losses.\n",
    "\n",
    "    Args:\n",
    "        t_loss (list): Training loss values.\n",
    "        v_loss (list): Validation loss values.\n",
    "        cc (int): Cycle number for tracking.\n",
    "        neuro_num (float): num_neurons value for normalization.\n",
    "        f (str): Folder path to save the plot.\n",
    "    \n",
    "    Returns:\n",
    "        None. Just plots the training and validation losses and saves the figure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    plt.plot(t_loss, label='Training Loss')\n",
    "    plt.plot(v_loss, label='Validation Loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Losses for Cycle {cc+1} with num_neurons {neuro_num}')\n",
    "    plt.legend()\n",
    "\n",
    "    f = os.path.join(f, f\"loss_plot_cycle_{cc+1}_num_neurons_{neuro_num}.png\")\n",
    "    plt.savefig(f)\n",
    "    plt.close()\n",
    "    \n",
    "# TO-DO: Try to change KL metric to KS. Add all graphs in one figure and add the distance metric to the best model selection to it.\n",
    "\n",
    "# Training\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def model_restore(mp, model):\n",
    "    \"\"\"\n",
    "    Restore the model state from a saved checkpoint.\n",
    "\n",
    "    Args:\n",
    "        mp (str): Path to the model checkpoint.\n",
    "        model (nn.Module): The model to restore.\n",
    "\n",
    "    Returns:\n",
    "        None. The model state is loaded from the checkpoint if it exists.\n",
    "    \"\"\"\n",
    "    if os.path.exists(mp):\n",
    "        print(f\"Loading model from {mp}\")\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "def inference(model, psi, tst, vr, v, nv, ld):\n",
    "    \"\"\"\n",
    "    Perform inference using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained model.\n",
    "        psi (np.array): Input data for inference.\n",
    "        tst (int): Number of time steps.\n",
    "        vr (dict): Variable ranges for the input data.\n",
    "        v (int): Index of the variable to use for inference.\n",
    "        nv (int): Number of variables.\n",
    "        ld (int): Latent dimension of the model.\n",
    "    \n",
    "    Returns:\n",
    "        p (np.array): Predictions made by the model.\n",
    "    \"\"\"\n",
    "    s, e = vr[v][0], vr[v][1]+1\n",
    "    init_c = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
    "    p = np.zeros ([tst, 75])\n",
    "\n",
    "    for k in range (0, tst):\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "\n",
    "            with autocast(device_type='cuda'):\n",
    "\n",
    "                if (k ==0):\n",
    "\n",
    "                    init_c = init_c.float().cuda(non_blocking=True)\n",
    "                    y, _, _ = (model(init_c, init_c))\n",
    "                    y = y.detach().cpu().numpy()\n",
    "                    p[k,:] = y\n",
    "                    init_c = torch.tensor(y[:, s:e])\n",
    "\n",
    "                else:\n",
    "\n",
    "                    init_c = torch.reshape(torch.tensor(p[k-1,:]),[1,75]).float().cuda(non_blocking=True)\n",
    "                    y, _, _ = (model(init_c,init_c))\n",
    "                    y = y.detach().cpu().numpy()\n",
    "                    p[k,:] = y\n",
    "                    init_c = torch.tensor(y[:, s:e])\n",
    "    \n",
    "    return p\n",
    "\n",
    "def euclidean_distance_for_predictions(ms):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance for a list of metrics.\n",
    "\n",
    "    Args:\n",
    "        ms (list): List of computed metrics.\n",
    "\n",
    "    Returns:\n",
    "        dt (float): The Euclidean distance calculated from the given computed metrics.\n",
    "    \"\"\"\n",
    "    s = 0\n",
    "    for m in ms:\n",
    "        s += m ** 2\n",
    "    dt = np.sqrt(s)\n",
    "    return dt\n",
    "\n",
    "def save_best_cycle_epoch(models, neuro_num, cc, ep, f,\n",
    "                          exp_fit_normalized_by_dim_cycle, \n",
    "                          KL_by_dim_cycle, duration_diff_by_dim_cycle, \n",
    "                          best_models_saved, best_models):\n",
    "    \"\"\"\n",
    "    Select the best model from a cycle based on combined distance metrics and save it.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of model paths for the current cycle.\n",
    "        neuro_num (float): num_neurons coefficient for normalization.\n",
    "        cc (int): Current cycle number.\n",
    "        ep (int): Current epoch number.\n",
    "        f (str): Folder path to save the best model.\n",
    "        exp_fit_normalized_by_dim_cycle (dict): Dictionary containing normalized exponential fit values by dimension and cycle.\n",
    "        KL_by_dim_cycle (dict): Dictionary containing KL divergence values by dimension and cycle.\n",
    "        duration_diff_by_dim_cycle (dict): Dictionary containing range differences by dimension and cycle.\n",
    "        best_models_saved (list): List to store the paths of the best models saved.\n",
    "        best_models (list): List to store the best models selected.\n",
    "\n",
    "    Returns:\n",
    "        None. The best model is saved to the specified folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    b_model = None\n",
    "    b_i = -1\n",
    "    b_dt = float('inf')\n",
    "\n",
    "    for i in range(len(models)):  # models contains each epoch's model in the current cycle\n",
    "        print(exp_fit_normalized_by_dim_cycle[neuro_num][cc][i])\n",
    "        print(KL_by_dim_cycle[neuro_num][cc][i])\n",
    "        print(duration_diff_by_dim_cycle[neuro_num][cc][i])\n",
    "        ms = [exp_fit_normalized_by_dim_cycle[neuro_num][cc][i],\n",
    "                   KL_by_dim_cycle[neuro_num][cc][i], \n",
    "                   duration_diff_by_dim_cycle[neuro_num][cc][i]]\n",
    "        \n",
    "        dt = euclidean_distance_for_predictions(ms)\n",
    "        if dt < b_dt:\n",
    "            b_dt = dt\n",
    "            b_i = i\n",
    "            b_model = models[i]\n",
    "\n",
    "    if b_i != -1:\n",
    "        best_models_saved.append(b_model)\n",
    "        best_models.append((cc, b_i))\n",
    "\n",
    "    shutil.copyfile(models[b_i], f\"{f}/best_model_combined_distance_at_cycle_{cc}_and_checkpoint_{ep}.pth\")\n",
    "    print(f\"New best model saved with distance {dt:.4f} at epoch {i+1}\")\n",
    "\n",
    "def save_best_epoch(best_models, best_models_saved, exp_fit_normalized_by_dim_cycle,\n",
    "                    KL_by_dim_cycle, duration_diff_by_dim_cycle, neuro_num, mf):\n",
    "    \n",
    "    \"\"\"\n",
    "    Select the best model from the master training run based on combined distance metrics and save it.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of model paths for the current cycle.\n",
    "        neuro_num (float): num_neurons coefficient for normalization.\n",
    "        cc (int): Current cycle number.\n",
    "        ep (int): Current epoch number.\n",
    "        f (str): Folder path to save the best model.\n",
    "        exp_fit_normalized_by_dim_cycle (dict): Dictionary containing normalized exponential fit values by dimension and cycle.\n",
    "        KL_by_dim_cycle (dict): Dictionary containing KL divergence values by dimension and cycle.\n",
    "        duration_diff_by_dim_cycle (dict): Dictionary containing range differences by dimension and cycle.\n",
    "        best_models_saved (list): List to store the paths of the best models saved.\n",
    "        best_models (list): List to store the best models selected.\n",
    "\n",
    "    Returns:\n",
    "        None. The best model is saved to the specified folder.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Selecting the best model based on combined distance...\")\n",
    "\n",
    "    # Ensure best_models is not empty\n",
    "    if not best_models:\n",
    "        print(\"No best models found.\")\n",
    "        return\n",
    "    \n",
    "    # After all cycles - final best model selection\n",
    "    b_model = None\n",
    "    w_model = (-1, -1)\n",
    "    b_model_dt = float('inf')\n",
    "\n",
    "    print(f\"Number of best models saved: {len(best_models)}\")\n",
    "    for idx, (cc, ep_idx) in enumerate(best_models):\n",
    "\n",
    "        ms = [exp_fit_normalized_by_dim_cycle[neuro_num][cc][ep_idx], \n",
    "                   KL_by_dim_cycle[neuro_num][cc][ep_idx], \n",
    "                   duration_diff_by_dim_cycle[neuro_num][cc][ep_idx]]\n",
    "        \n",
    "        dt = euclidean_distance_for_predictions(ms)        \n",
    "        print(f\"Distance for model from cycle {cc+1}, epoch {ep_idx+1}: {dt:.4f}\")\n",
    "        print(f\"Current best distance: {b_model_dt:.4f}\")\n",
    "        \n",
    "        if dt < b_model_dt:\n",
    "            b_model_dt = dt\n",
    "            b_model = best_models_saved[idx]\n",
    "            w_model = (cc, ep_idx)\n",
    "\n",
    "    # Save the best model  \n",
    "    i,n = w_model\n",
    "    cc = i\n",
    "    ep = n\n",
    "\n",
    "    if cc == -1:\n",
    "        print(\"No best model found.\")\n",
    "    else:\n",
    "        shutil.copyfile(b_model, f\"{mf}/best_{neuro_num}_neurons_model_with_emr_{b_model_dt:.4f}_at_epoch_{ep+1}.pth\")\n",
    "        print(f\"Best model saved with cycle {cc+1} and epoch {ep+1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a72aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "# Inference\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "real_data       = np.load(r\"/home/danielboscu/Documents/code/AI_RES/data/actual/long_run_310k.npy\")\n",
    "real_data_1d    = real_data[:, 1, 63]\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "\n",
    "time_step = 300000\n",
    "\n",
    "latent_dim = 32\n",
    "output_dim = 75\n",
    "condition_dim = num_variables\n",
    "num_neurons = 1024\n",
    "\n",
    "model = ConditionalVAE(latent_dim, output_dim, condition_dim, num_neurons)\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "start, end = variable_range[variable][0], variable_range[variable][1]+1\n",
    "\n",
    "# MODIFY THIS LINE FOR MODEL TESTING\n",
    "past_model = True  # Set to True if you want to load past model weights\n",
    "if past_model:\n",
    "    model_weights_path = \"/home/danielboscu/Documents/code/AI_RES/training/best/checkpoint_11.pth\"\n",
    "    if os.path.exists(model_weights_path):\n",
    "        model.load_state_dict(torch.load(model_weights_path))\n",
    "        print(f\"Model weights loaded from {model_weights_path}.\")\n",
    "\n",
    "for _ in range (0,1):\n",
    "\n",
    "    pred = inference(model, psi, time_step, variable_range, variable, \n",
    "                             condition_dim, latent_dim)\n",
    "    \n",
    "    pred_mean = pred[:time_step, :] * std_psi[:, :] + mean_psi[:, :]\n",
    "    actual_values = real_data[:time_step, 1, :]\n",
    "    predictions_1d = pred_mean[:, 63]\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(pred_mean[0:30000, 63],'r')\n",
    "    plt.plot(actual_values[0:30000, 63],'b')\n",
    "    plt.grid(True)\n",
    "    plt.title(f\"Predictions vs Actual\")\n",
    "    plt.savefig(f'/home/danielboscu/Documents/code/AI_RES/training/prediction_vs_actual_{datetime.datetime.now()}.png')\n",
    "    plt.show()\n",
    "\n",
    "    # MODIFY THIS LINE FOR MODEL TESTING\n",
    "    np.save(f'/home/danielboscu/Documents/code/AI_RES/training/predictions_best_checkpoint_and_cycle_Resnet_VAE_best_epoch_no_finetune.npy', pred_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound = 53.8 / 2.8935\n",
    "lower_bound = 7.41\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(predictions_1d[1200:1400],'r')\n",
    "plt.plot(real_data_1d[1200:1400],'b')\n",
    "# plt.plot(predictions_1d[740:800],'purple')\n",
    "# plt.plot(real_data_1d[740:800],'g')\n",
    "plt.axhline(y=lower_bound)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bc4dddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 1, 75)\n",
      "(309700, 2, 75)\n",
      "Created subfolder: testing_at_2025-08-04_16-51-51.592212/timeseries\n",
      "Created subfolder: testing_at_2025-08-04_16-51-51.592212/exp_fit\n",
      "Created subfolder: testing_at_2025-08-04_16-51-51.592212/bi_modal_distribution\n",
      "Created subfolder: testing_at_2025-08-04_16-51-51.592212/single_step_profiles\n"
     ]
    }
   ],
   "source": [
    "#FLAGS to determine testing\n",
    "plot_data = 1\n",
    "CCDF = 1\n",
    "Bi_modal_distribution = 1\n",
    "single_step_profiles = 1\n",
    "all_plot_flag = 1\n",
    "\n",
    "NUM_SAMPLES = 5\n",
    "MODEL_PATH = model_weights_path\n",
    "level = 63\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Load the data; shape = (300000, 2, 75)\n",
    "real_data = np.load(r\"/home/danielboscu/Documents/code/AI_RES/data/actual/long_run_310k.npy\")\n",
    "zonal_wind = real_data[:, 1, 63]\n",
    "upper, lower = 53.8 / 2.8935, 7.41\n",
    "predictions = np.load(r\"/home/danielboscu/Documents/code/AI_RES/training/predictions_best_checkpoint_and_cycle_Resnet_VAE_best_epoch_no_finetune.npy\")\n",
    "\n",
    "#reshape the predictions so that it matches the real_data shape\n",
    "predictions = predictions.reshape(300000, 1, 75)\n",
    "print(predictions.shape)\n",
    "print(real_data.shape)\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S.%f\")\n",
    "folder = f\"testing_at_{timestamp}\"\n",
    "os.mkdir(folder)\n",
    "subfolders = ['timeseries', 'exp_fit', 'bi_modal_distribution', 'single_step_profiles']\n",
    "# Create each subdirectory inside the main folder\n",
    "for subfolder in subfolders:\n",
    "    path = os.path.join(folder, subfolder)\n",
    "    os.mkdir(path)\n",
    "    print(f\"Created subfolder: {path}\")\n",
    "SAVE_DIR = os.path.join(folder, \"single_step_profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25153a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded from /home/danielboscu/Documents/code/AI_RES/training/best/checkpoint_11.pth.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSW Transitions A to B: 199, Mean Value: 18.12\n",
      "SSW Transitions A to B: 189, Mean Value: 18.18\n",
      "SSW Transitions B to A: 199, Mean Value: 7.97\n",
      "SSW Transitions B to A: 189, Mean Value: 8.01\n",
      "Non-SSW Transitions A: 189, Mean Value: 22.89\n",
      "Non-SSW Transitions A: 189, Mean Value: 12.32\n",
      "Non-SSW Transitions B: 189, Mean Value: 1.48\n",
      "Non-SSW Transitions B: 189, Mean Value: 14.42\n",
      "Mu shape:  torch.Size([1532, 32])\n",
      "Mu values for A_ssw:  0.027890475 Mu values for B_ssw:  nan Mu values for A_noSSW:  0.0007432704 Mu values for B_noSSW:  0.012948452\n",
      "Logvar shape for A_ssw:  -1.6696459 Logvar shape for B_ssw:  nan Logvar shape for A_noSSW:  -0.584659 Logvar shape for B_noSSW:  -1.7943684\n",
      "Z values for A_ssw:  0.015481244 Z values for B_ssw:  nan Z values for A_noSSW:  0.009543033 Z values for B_noSSW:  -0.007447947\n",
      "==>> pca: PCA(n_components=3)\n",
      "==>> latent_3d: (1532, 3)\n",
      "Explained variance by PC1: 0.9961\n",
      "Explained variance by PC2: 0.0016\n",
      "Explained variance by PC3: 0.0010\n",
      "Total explained variance (PC1+2+3): 0.9987\n",
      "[[ 1.450666   -0.8015665  -0.16981171 ... -1.4286319   1.1770296\n",
      "   2.6744714 ]\n",
      " [ 3.751338   -2.4279327  -0.6629388  ... -3.5017462   3.1697524\n",
      "   7.1949196 ]\n",
      " [ 3.7221754  -2.4020624  -0.5912084  ... -3.4974952   3.0860646\n",
      "   7.1471252 ]\n",
      " ...\n",
      " [ 0.5114832  -0.25697497 -0.06507163 ... -0.5498578   0.5004694\n",
      "   1.1153196 ]\n",
      " [ 0.6419707  -0.33886227 -0.13684647 ... -0.5703032   0.54306585\n",
      "   1.2578074 ]\n",
      " [ 1.120547   -0.60763985 -0.10280674 ... -1.094312    0.9724966\n",
      "   2.150022  ]] ['AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B']            PC1       PC2       PC3\n",
      "0    -4.880244  0.442729 -0.162382\n",
      "1     5.251015  0.131566  0.161229\n",
      "2     5.027048  0.098864  0.030509\n",
      "3     5.470270  0.411199  0.019329\n",
      "4     5.358772  0.029314  0.013229\n",
      "...        ...       ...       ...\n",
      "1527 -6.496601  0.121720 -0.196922\n",
      "1528 -5.750766  0.211828  0.272254\n",
      "1529 -8.675659 -0.274173 -0.220283\n",
      "1530 -8.271805 -0.147638 -0.027592\n",
      "1531 -6.278416  0.002808 -0.292035\n",
      "\n",
      "[1532 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielboscu/Documents/code/AI_RES/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/home/danielboscu/Documents/code/AI_RES/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:144: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trace type 'scatter3d' is not compatible with subplot type 'xy'\nat grid position (1, 2)\n\nSee the docstring for the specs argument to plotly.subplots.make_subplots\nfor more information on subplot types",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 229\u001b[39m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLogvar shape for A_ssw: \u001b[39m\u001b[33m\"\u001b[39m, np.mean(logvar_np[:AB_end, :]), \n\u001b[32m    220\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mLogvar shape for B_ssw: \u001b[39m\u001b[33m\"\u001b[39m, np.mean(logvar_np[AB_end:BA_end, :]), \n\u001b[32m    221\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mLogvar shape for A_noSSW: \u001b[39m\u001b[33m\"\u001b[39m, np.mean(logvar_np[BA_end:A_end, :]), \n\u001b[32m    222\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mLogvar shape for B_noSSW: \u001b[39m\u001b[33m\"\u001b[39m, np.mean(logvar_np[A_end:B_end, :]))\n\u001b[32m    224\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mZ values for A_ssw: \u001b[39m\u001b[33m\"\u001b[39m, np.mean(z_np[:AB_end, :]), \n\u001b[32m    225\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mZ values for B_ssw: \u001b[39m\u001b[33m\"\u001b[39m, np.mean(z_np[AB_end:BA_end, :]), \n\u001b[32m    226\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mZ values for A_noSSW: \u001b[39m\u001b[33m\"\u001b[39m, np.mean(z_np[BA_end:A_end, :]), \n\u001b[32m    227\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mZ values for B_noSSW: \u001b[39m\u001b[33m\"\u001b[39m, np.mean(z_np[A_end:B_end, :]))\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     \u001b[43mall_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myvr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_fit_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_fit_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnkl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_fit_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdur_diff_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (CCDF):\n\u001b[32m    232\u001b[39m     real_data_1d = real_data[:, \u001b[32m1\u001b[39m, \u001b[32m63\u001b[39m]  \u001b[38;5;66;03m# Now shape is (309700,)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 442\u001b[39m, in \u001b[36mall_plot\u001b[39m\u001b[34m(y, p, xlp, yvp, xlr, yvr, p_exp_fit, r_exp_fit, pdf_dt, exp_dt, range_dt, mu_np, labels, folder)\u001b[39m\n\u001b[32m    439\u001b[39m PDF_plot(y, p, pdf_dt, fig)\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Exp_fit_plot(xlp, yvp, xlr, yvr, \u001b[39;00m\n\u001b[32m    441\u001b[39m \u001b[38;5;66;03m#              p_exp_fit, r_exp_fit, exp_dt, range_dt, px)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m \u001b[43mPCA_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m dt = np.sqrt(pdf_dt**\u001b[32m2\u001b[39m + exp_dt**\u001b[32m2\u001b[39m + range_dt**\u001b[32m2\u001b[39m)\n\u001b[32m    445\u001b[39m fig.update_layout(title_text=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<b>Comprehensive Analysis of Zonal Wind Predictions | Euclidean Metric Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</b>\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    446\u001b[39m                   title_subtitle=\u001b[38;5;28mdict\u001b[39m(text=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPDF/KL Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_dt\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Rate of Transitions Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_dt\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Time Range of Return Periods Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrange_dt\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    447\u001b[39m                                       ),\n\u001b[32m   (...)\u001b[39m\u001b[32m    461\u001b[39m     ),\n\u001b[32m    462\u001b[39m     hovermode=\u001b[33m\"\u001b[39m\u001b[33mclosest\u001b[39m\u001b[33m\"\u001b[39m,)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 337\u001b[39m, in \u001b[36mPCA_plot\u001b[39m\u001b[34m(fig, mu_np, labels)\u001b[39m\n\u001b[32m    332\u001b[39m px_fig = px.scatter_3d(df, x=\u001b[33m\"\u001b[39m\u001b[33mPC1\u001b[39m\u001b[33m\"\u001b[39m, y=\u001b[33m\"\u001b[39m\u001b[33mPC2\u001b[39m\u001b[33m\"\u001b[39m, z=\u001b[33m\"\u001b[39m\u001b[33mPC3\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m\"\u001b[39m\u001b[33mCategory\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    333\u001b[39m                 opacity=\u001b[32m0.75\u001b[39m,\n\u001b[32m    334\u001b[39m                 title=\u001b[33m\"\u001b[39m\u001b[33mLatent Space Projection: 4-Way Classification, mu\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    335\u001b[39m                 width=\u001b[32m1500\u001b[39m, height=\u001b[32m1400\u001b[39m)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m px_fig.data:\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m fig.update_layout(\n\u001b[32m    340\u001b[39m     scene=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    341\u001b[39m         xaxis_title=\u001b[33m'\u001b[39m\u001b[33mPC1\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    345\u001b[39m     margin=\u001b[38;5;28mdict\u001b[39m(l=\u001b[32m0\u001b[39m, r=\u001b[32m0\u001b[39m, b=\u001b[32m0\u001b[39m, t=\u001b[32m0\u001b[39m),\n\u001b[32m    346\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/AI_RES/.venv/lib/python3.12/site-packages/plotly/graph_objs/_figure.py:343\u001b[39m, in \u001b[36mFigure.add_trace\u001b[39m\u001b[34m(self, trace, row, col, secondary_y, exclude_empty_subplots)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_trace\u001b[39m(\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m, trace, row=\u001b[38;5;28;01mNone\u001b[39;00m, col=\u001b[38;5;28;01mNone\u001b[39;00m, secondary_y=\u001b[38;5;28;01mNone\u001b[39;00m, exclude_empty_subplots=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    270\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mFigure\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    271\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    272\u001b[39m \n\u001b[32m    273\u001b[39m \u001b[33;03m    Add a trace to the figure\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    341\u001b[39m \n\u001b[32m    342\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecondary_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_empty_subplots\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/AI_RES/.venv/lib/python3.12/site-packages/plotly/basedatatypes.py:2123\u001b[39m, in \u001b[36mBaseFigure.add_trace\u001b[39m\u001b[34m(self, trace, row, col, secondary_y, exclude_empty_subplots)\u001b[39m\n\u001b[32m   2114\u001b[39m         \u001b[38;5;28mself\u001b[39m.add_trace(\n\u001b[32m   2115\u001b[39m             trace,\n\u001b[32m   2116\u001b[39m             row=r,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2119\u001b[39m             exclude_empty_subplots=exclude_empty_subplots,\n\u001b[32m   2120\u001b[39m         )\n\u001b[32m   2121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_traces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2127\u001b[39m \u001b[43m    \u001b[49m\u001b[43msecondary_ys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43msecondary_y\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msecondary_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude_empty_subplots\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_empty_subplots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/AI_RES/.venv/lib/python3.12/site-packages/plotly/graph_objs/_figure.py:421\u001b[39m, in \u001b[36mFigure.add_traces\u001b[39m\u001b[34m(self, data, rows, cols, secondary_ys, exclude_empty_subplots)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_traces\u001b[39m(\n\u001b[32m    346\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    347\u001b[39m     data,\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m     exclude_empty_subplots=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    352\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mFigure\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    353\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    354\u001b[39m \n\u001b[32m    355\u001b[39m \u001b[33;03m    Add traces to the figure\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    419\u001b[39m \n\u001b[32m    420\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_traces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecondary_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_empty_subplots\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/AI_RES/.venv/lib/python3.12/site-packages/plotly/basedatatypes.py:2253\u001b[39m, in \u001b[36mBaseFigure.add_traces\u001b[39m\u001b[34m(self, data, rows, cols, secondary_ys, exclude_empty_subplots)\u001b[39m\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m trace, row, col, secondary_y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data, rows, cols, secondary_ys):\n\u001b[32m-> \u001b[39m\u001b[32m2253\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_trace_grid_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecondary_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exclude_empty_subplots:\n\u001b[32m   2256\u001b[39m     data = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   2257\u001b[39m         \u001b[38;5;28mfilter\u001b[39m(\n\u001b[32m   2258\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m trace: \u001b[38;5;28mself\u001b[39m._subplot_not_empty(\n\u001b[32m   (...)\u001b[39m\u001b[32m   2262\u001b[39m         )\n\u001b[32m   2263\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/AI_RES/.venv/lib/python3.12/site-packages/plotly/basedatatypes.py:2343\u001b[39m, in \u001b[36mBaseFigure._set_trace_grid_position\u001b[39m\u001b[34m(self, trace, row, col, secondary_y)\u001b[39m\n\u001b[32m   2340\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _set_trace_grid_reference\n\u001b[32m   2342\u001b[39m grid_ref = \u001b[38;5;28mself\u001b[39m._validate_get_grid_ref()\n\u001b[32m-> \u001b[39m\u001b[32m2343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_set_trace_grid_reference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecondary_y\u001b[49m\n\u001b[32m   2345\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/AI_RES/.venv/lib/python3.12/site-packages/plotly/_subplots.py:1403\u001b[39m, in \u001b[36m_set_trace_grid_reference\u001b[39m\u001b[34m(trace, layout, grid_ref, row, col, secondary_y)\u001b[39m\n\u001b[32m   1401\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m trace_kwargs:\n\u001b[32m   1402\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m trace:\n\u001b[32m-> \u001b[39m\u001b[32m1403\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1404\u001b[39m \u001b[38;5;250m                \u001b[39m\u001b[33;03m\"\"\"\\\u001b[39;00m\n\u001b[32m   1405\u001b[39m \u001b[33;03mTrace type '{typ}' is not compatible with subplot type '{subplot_type}'\u001b[39;00m\n\u001b[32m   1406\u001b[39m \u001b[33;03mat grid position ({row}, {col})\u001b[39;00m\n\u001b[32m   1407\u001b[39m \n\u001b[32m   1408\u001b[39m \u001b[33;03mSee the docstring for the specs argument to plotly.subplots.make_subplots\u001b[39;00m\n\u001b[32m   1409\u001b[39m \u001b[33;03mfor more information on subplot types\"\"\"\u001b[39;00m.format(\n\u001b[32m   1410\u001b[39m                     typ=trace.type,\n\u001b[32m   1411\u001b[39m                     subplot_type=subplot_refs[\u001b[32m0\u001b[39m].subplot_type,\n\u001b[32m   1412\u001b[39m                     row=row,\n\u001b[32m   1413\u001b[39m                     col=col,\n\u001b[32m   1414\u001b[39m                 )\n\u001b[32m   1415\u001b[39m             )\n\u001b[32m   1417\u001b[39m     \u001b[38;5;66;03m# Update trace reference\u001b[39;00m\n\u001b[32m   1418\u001b[39m     trace.update(trace_kwargs)\n",
      "\u001b[31mValueError\u001b[39m: Trace type 'scatter3d' is not compatible with subplot type 'xy'\nat grid position (1, 2)\n\nSee the docstring for the specs argument to plotly.subplots.make_subplots\nfor more information on subplot types"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "upper_bound = 53.8 / 2.8935\n",
    "lower_bound = 7.41\n",
    "num_neurons = 1024\n",
    "\n",
    "model = ConditionalVAE(latent_dim, output_dim, condition_dim, num_neurons)\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "if os.path.exists(model_weights_path):\n",
    "    model.load_state_dict(torch.load(model_weights_path))\n",
    "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
    "\n",
    "if (all_plot_flag):\n",
    "\n",
    "    r = real_data[:300000, 1, level]\n",
    "    p = predictions[:, 0, level]\n",
    "    # Compute transition durations for real data\n",
    "    real_durations = calculate_transition_durations(r, upper_bound, lower_bound)\n",
    "\n",
    "    # Compute transition durations for predictions data\n",
    "    pred_durations = calculate_transition_durations(p, upper_bound, lower_bound)\n",
    "\n",
    "    # === REAL DATA CCDF AND FIT ===\n",
    "    if len(real_durations) == 0:\n",
    "        print(\"No transitions detected in real data with current bounds!\")\n",
    "    else:\n",
    "        real_data_sorted = np.sort(real_durations)\n",
    "        xlr = np.linspace(min(real_data_sorted), max(real_data_sorted), 100)\n",
    "        exp_fit_r = 1/np.mean(real_data_sorted)\n",
    "        yvr = exp_fit_r*xlr\n",
    "\n",
    "    # === PREDICTIONS CCDF AND FIT ===\n",
    "    if len(pred_durations) == 0:\n",
    "        print(\"No transitions detected in predictions with current bounds!\")\n",
    "    else:\n",
    "        pred_data_sorted = np.sort(pred_durations)\n",
    "        xlp = np.linspace(min(pred_data_sorted), max(pred_data_sorted), 100)\n",
    "        exp_fit_p = 1/np.mean(pred_data_sorted)\n",
    "        yvp = exp_fit_p*xlp\n",
    "\n",
    "    # Compute CCDF\n",
    "    real_data_sorted = np.sort(real_durations)\n",
    "    ccdf_real = 1 - np.arange(1, len(real_data_sorted) + 1) / len(real_data_sorted)\n",
    "\n",
    "    # Filter valid data (exclude zero or negative CCDF values)\n",
    "    valid_indices = ccdf_real > 0  # Avoid log(0) issues\n",
    "    x_fit = real_data_sorted[valid_indices]  # Keep x in linear scale\n",
    "    y_fit = np.log(ccdf_real[valid_indices])  # Apply log transformation to y\n",
    "\n",
    "    # Perform linear regression on log-transformed data\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x_fit, y_fit)\n",
    "\n",
    "    # Convert back to exponential form (y = e^(slope*x + intercept))\n",
    "    x_line = np.linspace(min(x_fit), max(x_fit), 100)\n",
    "    y_line = np.exp(slope * x_line + intercept)  # Convert back from log scale\n",
    "\n",
    "    # Plot CCDF and best-fit line\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.step(real_data_sorted, ccdf_real, where='post', label='Real Data CCDF', linewidth=2, linestyle='--')\n",
    "    plt.plot(x_line, y_line, 'r-', label=f'Exponential Fit (slope={slope:.4f})', linewidth=2)\n",
    "\n",
    "    plt.xlabel('Time Duration (Steps)')\n",
    "    plt.ylabel('CCDF')\n",
    "    plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
    "    plt.yscale(\"log\")  # Keep y-axis in log scale\n",
    "    plt.xscale(\"linear\")  # Keep x-axis in linear scale\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    exp_fit_d = normalize_transition_time(exp_fit_p, 0.005, exp_fit_r)\n",
    "\n",
    "    max_pred = np.max(pred_durations)\n",
    "    min_pred = np.min(pred_durations)\n",
    "    difference = abs(max_pred - min_pred)\n",
    "    dur_diff_n = normalize_transition_time(difference, 10000, abs(np.max(real_durations)-np.min(real_durations)))\n",
    "\n",
    "    rh, b = np.histogram(r, bins=100, density=True)\n",
    "    ph, _ = np.histogram(p, bins=b, density=True)\n",
    "\n",
    "    e = 1e-10\n",
    "    rh += e\n",
    "    ph += e\n",
    "\n",
    "    # Calculate KL divergence between the two histograms\n",
    "    kl = np.sum(rh * np.log(rh / ph))\n",
    "    nkl = normalize_transition_time(kl, 1, 0)\n",
    "\n",
    "    save_path = os.path.join(folder, \"timeseries\")\n",
    "\n",
    "    # Plot 3D PCA\n",
    "    def detect_transitions_A_to_B(u_series, upper, lower):\n",
    "        transitions = []\n",
    "        transition_values = []\n",
    "        i = 0\n",
    "        while i < len(u_series) - 1:\n",
    "            if u_series[i-1] > upper and u_series[i] <= upper:\n",
    "                j = i + 1\n",
    "                while j < len(u_series) and u_series[j] <= upper:\n",
    "                    if u_series[j] < lower:\n",
    "                        transitions.append(i)\n",
    "                        transition_values.append(u_series[i])\n",
    "                        break\n",
    "                    j += 1\n",
    "                i = j\n",
    "            else:\n",
    "                i += 1\n",
    "        return np.array(transitions), np.array(transition_values)\n",
    "\n",
    "    def detect_transitions_B_to_A(u_series, upper, lower):\n",
    "        transitions = []\n",
    "        transition_values = []\n",
    "        i = 0\n",
    "        while i < len(u_series) - 1:\n",
    "            if u_series[i-1] < lower and u_series[i] >= lower:\n",
    "                j = i + 1\n",
    "                while j < len(u_series) and u_series[j] >= lower:\n",
    "                    if u_series[j] > upper:\n",
    "                        transitions.append(i)\n",
    "                        transition_values.append(u_series[i])\n",
    "                        break\n",
    "                    j += 1\n",
    "                i = j\n",
    "            else:\n",
    "                i += 1\n",
    "        return np.array(transitions), np.array(transition_values)\n",
    "\n",
    "    ssw_indices_A1, ssw_transition_values_A1 = detect_transitions_A_to_B(real_data[:, 1, 63], upper, lower)\n",
    "    ssw_indices_A0, ssw_transition_values_A0 = detect_transitions_A_to_B(real_data[:, 0, 63], upper, lower)\n",
    "    ssw_indices_B1, ssw_transition_values_B1 = detect_transitions_B_to_A(real_data[:, 1, 63], upper, lower)\n",
    "    ssw_indices_B0, ssw_transition_values_B0 = detect_transitions_B_to_A(real_data[:, 0, 63], upper, lower)\n",
    "\n",
    "    AB_transitions = np.union1d(ssw_indices_A1, ssw_indices_A0)\n",
    "    BA_transitions = np.union1d(ssw_indices_B1, ssw_indices_B0)\n",
    "    transition_indices = np.union1d(AB_transitions, BA_transitions)\n",
    "    total_len = len(real_data)\n",
    "    non_ssw_indices_A1 = np.where((real_data[:, 1, 63] > upper) & (~np.isin(np.arange(total_len), transition_indices)))[0]\n",
    "    non_ssw_indices_A0 = np.where((real_data[:, 0, 63] > upper) & (~np.isin(np.arange(total_len), transition_indices)))[0]\n",
    "    non_ssw_indices_B1 = np.where((real_data[:, 1, 63] < lower) & (~np.isin(np.arange(total_len), transition_indices)))[0]\n",
    "    non_ssw_indices_B0 = np.where((real_data[:, 0, 63] < lower) & (~np.isin(np.arange(total_len), transition_indices)))[0]\n",
    "\n",
    "    n_samples = min(len(ssw_indices_A1), len(ssw_indices_A0), len(non_ssw_indices_A1), len(non_ssw_indices_A0))\n",
    "    non_ssw_indices_A1 = np.random.choice(non_ssw_indices_A1, size=n_samples, replace=False)\n",
    "    non_ssw_indices_A0 = np.random.choice(non_ssw_indices_A0, size=n_samples, replace=False)\n",
    "    non_ssw_indices_B1 = np.random.choice(non_ssw_indices_B1, size=n_samples, replace=False)\n",
    "    non_ssw_indices_B0 = np.random.choice(non_ssw_indices_B0, size=n_samples, replace=False)\n",
    "    non_ssw_transition_values_A1 = zonal_wind[non_ssw_indices_A1]\n",
    "    non_ssw_transition_values_A0 = zonal_wind[non_ssw_indices_A0]\n",
    "    non_ssw_transition_values_B1 = zonal_wind[non_ssw_indices_B1]\n",
    "    non_ssw_transition_values_B0 = zonal_wind[non_ssw_indices_B0]\n",
    "\n",
    "    print(f\"SSW Transitions A to B: {len(ssw_indices_A1)}, Mean Value: {np.mean(ssw_transition_values_A1):.2f}\")\n",
    "    print(f\"SSW Transitions A to B: {len(ssw_indices_A0)}, Mean Value: {np.mean(ssw_transition_values_A0):.2f}\")\n",
    "    print(f\"SSW Transitions B to A: {len(ssw_indices_B1)}, Mean Value: {np.mean(ssw_transition_values_B1):.2f}\")\n",
    "    print(f\"SSW Transitions B to A: {len(ssw_indices_B0)}, Mean Value: {np.mean(ssw_transition_values_B0):.2f}\")\n",
    "    print(f\"Non-SSW Transitions A: {len(non_ssw_indices_A1)}, Mean Value: {np.mean(non_ssw_transition_values_A1):.2f}\")\n",
    "    print(f\"Non-SSW Transitions A: {len(non_ssw_indices_A0)}, Mean Value: {np.mean(non_ssw_transition_values_A0):.2f}\")\n",
    "    print(f\"Non-SSW Transitions B: {len(non_ssw_indices_B1)}, Mean Value: {np.mean(non_ssw_transition_values_B1):.2f}\")\n",
    "    print(f\"Non-SSW Transitions B: {len(non_ssw_indices_B0)}, Mean Value: {np.mean(non_ssw_transition_values_B0):.2f}\")\n",
    "\n",
    "    X = np.vstack([\n",
    "        real_data[ssw_indices_A1, 1],\n",
    "        real_data[ssw_indices_A0, 0],\n",
    "        real_data[ssw_indices_B1, 1],\n",
    "        real_data[ssw_indices_B0, 0],\n",
    "        real_data[non_ssw_indices_A1, 1],\n",
    "        real_data[non_ssw_indices_A0, 0],\n",
    "        real_data[non_ssw_indices_B1, 1],\n",
    "        real_data[non_ssw_indices_B0, 0]\n",
    "    ]).astype(np.float32)\n",
    "\n",
    "    labels = (\n",
    "        [\"AB\"] * len(ssw_indices_A1) +\n",
    "        [\"AB\"] * len(ssw_indices_A0) +\n",
    "        [\"BA\"] * len(ssw_indices_B1) +\n",
    "        [\"BA\"] * len(ssw_indices_B0) +\n",
    "        [\"A\"] * len(non_ssw_indices_A1) +\n",
    "        [\"A\"] * len(non_ssw_indices_A0) +\n",
    "        [\"B\"] * len(non_ssw_indices_B1) +\n",
    "        [\"B\"] * len(non_ssw_indices_B0)\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    # Encode data\n",
    "    with torch.no_grad():\n",
    "        mu, logvar = model.encode(torch.tensor(X, dtype=torch.float32).cuda())\n",
    "        z = model.reparameterize(mu, logvar)\n",
    "        mu_np = mu.cpu().numpy()\n",
    "        logvar_np = logvar.cpu().numpy()\n",
    "        z_np = z.cpu().numpy()\n",
    "\n",
    "    print(\"Mu shape: \" , mu.shape)\n",
    "\n",
    "    AB_start = 0\n",
    "    AB_end = len(ssw_indices_A1) + len(ssw_indices_A0)\n",
    "    BA_start = AB_end\n",
    "    BA_end = AB_start + len(ssw_indices_B1) + len(ssw_indices_B0)\n",
    "    A_start = BA_end\n",
    "    A_end = A_start + len(non_ssw_indices_A1) + len(non_ssw_indices_A0)\n",
    "    B_start = A_end\n",
    "    B_end = B_start + len(non_ssw_indices_B1) + len(non_ssw_indices_B0)\n",
    "\n",
    "    print(\"Mu values for A_ssw: \", np.mean(mu_np[:AB_end, :]), \n",
    "          \"Mu values for B_ssw: \", np.mean(mu_np[AB_end:BA_end, :]), \n",
    "          \"Mu values for A_noSSW: \", np.mean(mu_np[BA_end:A_end, :]), \n",
    "          \"Mu values for B_noSSW: \", np.mean(mu_np[A_end:B_end, :]))\n",
    "\n",
    "    print(\"Logvar shape for A_ssw: \", np.mean(logvar_np[:AB_end, :]), \n",
    "          \"Logvar shape for B_ssw: \", np.mean(logvar_np[AB_end:BA_end, :]), \n",
    "          \"Logvar shape for A_noSSW: \", np.mean(logvar_np[BA_end:A_end, :]), \n",
    "          \"Logvar shape for B_noSSW: \", np.mean(logvar_np[A_end:B_end, :]))\n",
    "\n",
    "    print(\"Z values for A_ssw: \", np.mean(z_np[:AB_end, :]), \n",
    "          \"Z values for B_ssw: \", np.mean(z_np[AB_end:BA_end, :]), \n",
    "          \"Z values for A_noSSW: \", np.mean(z_np[BA_end:A_end, :]), \n",
    "          \"Z values for B_noSSW: \", np.mean(z_np[A_end:B_end, :]))\n",
    "\n",
    "    all_plot(r, p, xlp, yvp, xlr, yvr, exp_fit_p, exp_fit_r, nkl, exp_fit_d, dur_diff_n, mu_np, labels, save_path)\n",
    "\n",
    "if (CCDF):\n",
    "    real_data_1d = real_data[:, 1, 63]  # Now shape is (309700,)\n",
    "    predictions_1d = predictions[:, 0, 63]  # shape (300000,)\n",
    "    \n",
    "    # Function to calculate transition durations\n",
    "    def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
    "        times_between_transitions = []\n",
    "        transition_start = None\n",
    "        above_upper = False\n",
    "        below_lower = False\n",
    "\n",
    "        for i in range(1, len(y_values)):\n",
    "            if y_values[i] < lower_bound:  \n",
    "                below_lower = True\n",
    "                above_upper = False\n",
    "            elif y_values[i] > upper_bound:  \n",
    "                if below_lower and transition_start is not None:\n",
    "                    times_between_transitions.append(i - transition_start)\n",
    "                    transition_start = None  \n",
    "                above_upper = True\n",
    "                below_lower = False\n",
    "\n",
    "            if below_lower and transition_start is None:\n",
    "                transition_start = i\n",
    "\n",
    "        return times_between_transitions\n",
    "\n",
    "    # Compute transition durations for real data\n",
    "    real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
    "\n",
    "    # Compute transition durations for predictions data\n",
    "    pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
    "\n",
    "    # Plot setup\n",
    "    CCDF_sum = 0\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    def bootstrap_ci(data, num_bootstraps=1000, confidence_level=0.95):\n",
    "        sample_size = len(data)\n",
    "        bootstrap_means = np.zeros(num_bootstraps)\n",
    "        \n",
    "        for i in range(num_bootstraps):\n",
    "            bootstrap_sample = np.random.choice(data, size=sample_size, replace=True)\n",
    "            bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "        \n",
    "        ci_lower = np.percentile(bootstrap_means, (1 - confidence_level) / 2 * 100)\n",
    "        ci_upper = np.percentile(bootstrap_means, (1 + confidence_level) / 2 * 100)\n",
    "        \n",
    "        return np.mean(data), ci_lower, ci_upper\n",
    "\n",
    "    # === REAL DATA CCDF AND FIT ===\n",
    "    if len(real_durations) == 0:\n",
    "        print(\"No transitions detected in real data with current bounds!\")\n",
    "    else:\n",
    "        real_data_sorted = np.sort(real_durations)\n",
    "        ccdf_real = 1 - np.arange(1, len(real_data_sorted) + 1) / len(real_data_sorted)\n",
    "\n",
    "        valid_indices_real = ccdf_real > 0\n",
    "        x_fit_real = real_data_sorted[valid_indices_real]\n",
    "        y_fit_real = np.log(ccdf_real[valid_indices_real])\n",
    "\n",
    "        slope_real, intercept_real, *_ = linregress(x_fit_real, y_fit_real)\n",
    "\n",
    "        x_line_real = np.linspace(min(x_fit_real), max(x_fit_real), 40)\n",
    "        y_line_real = np.exp(slope_real * x_line_real + intercept_real)\n",
    "\n",
    "        # Create a grid of x values (time steps / durations)\n",
    "\n",
    "        bootstrap_mean = []\n",
    "        ci_lower_vals = []\n",
    "        ci_upper_vals = []\n",
    "\n",
    "        for x in x_line_real:\n",
    "            valid_indices = (real_durations > x).astype(float)\n",
    "            mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
    "            bootstrap_mean.append(mean_val)\n",
    "            ci_lower_vals.append(lower)\n",
    "            ci_upper_vals.append(upper)\n",
    "\n",
    "        bootstrap_mean = np.array(bootstrap_mean)\n",
    "        ci_lower_vals = np.array(ci_lower_vals)\n",
    "        ci_upper_vals = np.array(ci_upper_vals)\n",
    "\n",
    "        # Calculate error bars (difference from the bootstrap mean)\n",
    "        error_lower = bootstrap_mean - ci_lower_vals\n",
    "        error_upper = ci_upper_vals - bootstrap_mean\n",
    "\n",
    "        plt.step(real_data_sorted, ccdf_real, where='post', label='Real Data CCDF', linewidth=2, linestyle='--')\n",
    "        plt.errorbar(x_line_real, bootstrap_mean, yerr=[error_lower, error_upper],\n",
    "                fmt='o', color='blue', capsize=3, ecolor='blue', label='Real Bootstrap 95% CI')\n",
    "        plt.plot(x_line_real, y_line_real, 'b-', label=f'Real Exp Fit (slope={slope_real:.4f})', linewidth=2)\n",
    "\n",
    "    # === PREDICTIONS CCDF AND FIT ===\n",
    "    if len(pred_durations) == 0:\n",
    "        print(\"No transitions detected in predictions with current bounds!\")\n",
    "    else:\n",
    "        pred_data_sorted = np.sort(pred_durations)\n",
    "        ccdf_pred = 1 - np.arange(1, len(pred_data_sorted) + 1) / len(pred_data_sorted)\n",
    "\n",
    "        valid_indices_pred = ccdf_pred > 0\n",
    "        x_fit_pred = pred_data_sorted[valid_indices_pred]\n",
    "        y_fit_pred = np.log(ccdf_pred[valid_indices_pred])\n",
    "\n",
    "        slope_pred, intercept_pred, *_ = linregress(x_fit_pred, y_fit_pred)\n",
    "\n",
    "        x_line_pred = np.linspace(min(x_fit_pred), max(x_fit_pred), 40)\n",
    "        y_line_pred = np.exp(slope_pred * x_line_pred + intercept_pred)\n",
    "\n",
    "        # Create a grid of x values (time steps / durations)\n",
    "\n",
    "        bootstrap_mean = []\n",
    "        ci_lower_vals = []\n",
    "        ci_upper_vals = []\n",
    "\n",
    "        for x in x_line_pred:\n",
    "            valid_indices = (pred_durations > x).astype(float)\n",
    "            mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
    "            bootstrap_mean.append(mean_val)\n",
    "            ci_lower_vals.append(lower)\n",
    "            ci_upper_vals.append(upper)\n",
    "\n",
    "        bootstrap_mean = np.array(bootstrap_mean)\n",
    "        ci_lower_vals = np.array(ci_lower_vals)\n",
    "        ci_upper_vals = np.array(ci_upper_vals)\n",
    "\n",
    "        # Calculate error bars (difference from the bootstrap mean)\n",
    "        error_lower = bootstrap_mean - ci_lower_vals\n",
    "        error_upper = ci_upper_vals - bootstrap_mean\n",
    "\n",
    "        plt.step(pred_data_sorted, ccdf_pred, where='post', label='Predictions CCDF', linewidth=2, linestyle='-.', color='red')\n",
    "        plt.errorbar(x_line_pred, bootstrap_mean, yerr=[error_lower, error_upper],\n",
    "                fmt='o', color='red', capsize=3, ecolor='red', label='Pred Bootstrap 95% CI')\n",
    "        plt.plot(x_line_pred, y_line_pred, 'r-', label=f'Pred Exp Fit (slope={slope_pred:.4f})', linewidth=2)\n",
    "\n",
    "        CCDF_sum += slope_pred\n",
    "\n",
    "    # Plot labels and formatting\n",
    "    plt.xlabel('Time Duration (Steps)')\n",
    "    plt.ylabel('CCDF')\n",
    "    plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
    "    plt.yscale(\"log\")  # y-axis log scale\n",
    "    plt.xscale(\"linear\")  # x-axis linear scale\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder, f\"CCDF_plot\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "if (Bi_modal_distribution):\n",
    "    zonal_wind_data_real = real_data[:, 1, 63]  # variable index 1 (e.g., zonal wind), level 60\n",
    "    zonal_wind_data_predictions = predictions[:, 0, 63]  # variable index 0 (predictions), level 60\n",
    "\n",
    "    print(f\"Shape of zonal_wind_data_real: {zonal_wind_data_real.shape}\")\n",
    "    print(f\"Shape of zonal_wind_data_predictions: {zonal_wind_data_predictions.shape}\")\n",
    "\n",
    "    # Plot the bimodal histogram\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create histograms (overlaid)\n",
    "    sns.histplot(zonal_wind_data_real, bins=50, kde=True, color='black', alpha=0.6, element='step', label='Real Data')\n",
    "    sns.histplot(zonal_wind_data_predictions, bins=50, kde=True, color='red', alpha=0.6, element='step', label='Predictions')\n",
    "\n",
    "    # Customize plot labels and title\n",
    "    plt.title('Distribution of Zonal Winds For Real Data and Predictions', fontsize=16)\n",
    "    plt.xlabel('Zonal Wind (m/s)', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "    # Add vertical lines at means\n",
    "    plt.axvline(np.mean(zonal_wind_data_real), color='black', linestyle='--', label=f'Real Mean: {np.mean(zonal_wind_data_real):.2f}')\n",
    "    plt.axvline(np.mean(zonal_wind_data_predictions), color='red', linestyle='--', label=f'Pred Mean: {np.mean(zonal_wind_data_predictions):.2f}')\n",
    "\n",
    "    # Final plot settings\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder, \"bi_modal_distribution\")\n",
    "    save_path = os.path.join(save_path, \"bi_modal_distribution_plot\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "if (single_step_profiles):\n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    # === Load model weights ===\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.eval()\n",
    "\n",
    "    # === Randomly sample time points from real data ===\n",
    "    time_indices = random.sample(range(0, real_data.shape[0] - 2), NUM_SAMPLES)\n",
    "    print(f\"Randomly sampled time steps: {time_indices}\")\n",
    "\n",
    "    # === Time series visualization ===\n",
    "    real_data_timeseries = real_data[:, 1, level]\n",
    "    time_steps_all = np.arange(len(real_data_timeseries))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(time_steps_all, real_data_timeseries, label=\"Real Data at Level 61\", color='blue')\n",
    "\n",
    "    # Mark sample points\n",
    "    for idx_num, idx in enumerate(time_indices):\n",
    "        plt.axvline(x=idx, color='green', linestyle='--', linewidth=2)\n",
    "    if len(time_indices) > 0:\n",
    "        plt.axvline(x=time_indices[0], color='green', linestyle='--', linewidth=2, label='Sampled Points')\n",
    "\n",
    "    plt.title(\"Real Data Time Series with Sampled Points Highlighted\")\n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.ylabel(\"U (m/s) at Level 61\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(SAVE_DIR, \"real_data_timeseries_with_samples.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "    # === Iterate over each sampled time point ===\n",
    "    for i, time_step in enumerate(time_indices):\n",
    "        next_time_step = time_step + 1\n",
    "\n",
    "        # === Real data: current and next ===\n",
    "        real_current = real_data[time_step, 1, :]       \n",
    "        real_next = real_data[next_time_step, 1, :]      \n",
    "\n",
    "        # === Normalize real_current and make prediction for next step ===\n",
    "        initial_cond = torch.reshape(torch.tensor(psi[time_step,start:end]), [1, num_variables])\n",
    "        z = torch.zeros([1,latent_dim])\n",
    "        num_ens = 1\n",
    "        pred = np.zeros ([time_step, num_variables, num_ens])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn_like(z)\n",
    "            print(z.shape, initial_cond.shape)\n",
    "            y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
    "\n",
    "        # === Denormalize predicted next ===\n",
    "        pred_next_denorm = y.squeeze() * std_psi.squeeze() + mean_psi.squeeze()\n",
    "\n",
    "        # === Extract U, Re(Psi), Im(Psi) components ===\n",
    "        # U profiles\n",
    "        U_current_real = real_current[51:74]\n",
    "        U_next_real = real_next[51:74]\n",
    "        U_next_pred = pred_next_denorm[51:74]\n",
    "\n",
    "        # Re(Psi) profiles\n",
    "        RePsi_current_real = real_current[0:24]\n",
    "        RePsi_next_real = real_next[0:24]\n",
    "        RePsi_next_pred = pred_next_denorm[0:24]\n",
    "\n",
    "        # Im(Psi) profiles\n",
    "        ImPsi_current_real = real_current[25:50]\n",
    "        ImPsi_next_real = real_next[25:50]\n",
    "        ImPsi_next_pred = pred_next_denorm[25:50]\n",
    "\n",
    "        # === Differences ===\n",
    "        U_diff_real = U_next_real - U_current_real\n",
    "        U_diff_pred = U_next_pred - U_current_real\n",
    "\n",
    "        RePsi_diff_real = RePsi_next_real - RePsi_current_real\n",
    "        RePsi_diff_pred = RePsi_next_pred - RePsi_current_real\n",
    "\n",
    "        ImPsi_diff_real = ImPsi_next_real - ImPsi_current_real\n",
    "        ImPsi_diff_pred = ImPsi_next_pred - ImPsi_current_real\n",
    "\n",
    "        # === Create a single figure with 3 rows (U, Re(Psi), Im(Psi)) ===\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(16, 18))  # 3 rows, 2 columns (Profile and Difference)\n",
    "\n",
    "        z_levels_U = np.linspace(0, 70, 23)\n",
    "        z_levels_RePsi = np.linspace(0, 70, 24)\n",
    "        z_levels_ImPsi = np.linspace(0, 70, 25)\n",
    "\n",
    "        # --- U ---\n",
    "        axes[0, 0].plot(U_current_real, z_levels_U, 'x-', label=\"Real Current\")\n",
    "        axes[0, 0].plot(U_next_real, z_levels_U, 'd-', label=\"Real Next\")\n",
    "        axes[0, 0].plot(U_next_pred, z_levels_U, 's--', label=\"Predicted Next\")\n",
    "        axes[0, 0].set_title(f\"U Profiles @ Step {time_step}\")\n",
    "        axes[0, 0].set_xlabel(\"U (m/s)\")\n",
    "        axes[0, 0].set_ylabel(\"Vertical Levels (km)\")\n",
    "        axes[0, 0].legend()\n",
    "\n",
    "        axes[0, 1].plot(U_diff_real, z_levels_U, 'xb', label=\"Real Δ (Next - Current)\")\n",
    "        axes[0, 1].plot(U_diff_pred, z_levels_U, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
    "        axes[0, 1].set_title(\"U Difference (Next - Current)\")\n",
    "        axes[0, 1].set_xlabel(\"ΔU (m/s)\")\n",
    "        axes[0, 1].legend()\n",
    "\n",
    "        # --- Re(Psi) ---\n",
    "        axes[1, 0].plot(RePsi_current_real, z_levels_RePsi, 'x-', label=\"Real Current\")\n",
    "        axes[1, 0].plot(RePsi_next_real, z_levels_RePsi, 'd-', label=\"Real Next\")\n",
    "        axes[1, 0].plot(RePsi_next_pred, z_levels_RePsi, 's--', label=\"Predicted Next\")\n",
    "        axes[1, 0].set_title(f\"Re(Psi) Profiles @ Step {time_step}\")\n",
    "        axes[1, 0].set_xlabel(\"Re(Psi)\")\n",
    "        axes[1, 0].set_ylabel(\"Vertical Levels (km)\")\n",
    "        axes[1, 0].legend()\n",
    "\n",
    "        axes[1, 1].plot(RePsi_diff_real, z_levels_RePsi, 'xb', label=\"Real Δ (Next - Current)\")\n",
    "        axes[1, 1].plot(RePsi_diff_pred, z_levels_RePsi, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
    "        axes[1, 1].set_title(\"Re(Psi) Difference (Next - Current)\")\n",
    "        axes[1, 1].set_xlabel(\"ΔRe(Psi)\")\n",
    "        axes[1, 1].legend()\n",
    "\n",
    "        # --- Im(Psi) ---\n",
    "        axes[2, 0].plot(ImPsi_current_real, z_levels_ImPsi, 'x-', label=\"Real Current\")\n",
    "        axes[2, 0].plot(ImPsi_next_real, z_levels_ImPsi, 'd-', label=\"Real Next\")\n",
    "        axes[2, 0].plot(ImPsi_next_pred, z_levels_ImPsi, 's--', label=\"Predicted Next\")\n",
    "        axes[2, 0].set_title(f\"Im(Psi) Profiles @ Step {time_step}\")\n",
    "        axes[2, 0].set_xlabel(\"Im(Psi)\")\n",
    "        axes[2, 0].set_ylabel(\"Vertical Levels (km)\")\n",
    "        axes[2, 0].legend()\n",
    "\n",
    "        axes[2, 1].plot(ImPsi_diff_real, z_levels_ImPsi, 'xb', label=\"Real Δ (Next - Current)\")\n",
    "        axes[2, 1].plot(ImPsi_diff_pred, z_levels_ImPsi, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
    "        axes[2, 1].set_title(\"Im(Psi) Difference (Next - Current)\")\n",
    "        axes[2, 1].set_xlabel(\"ΔIm(Psi)\")\n",
    "        axes[2, 1].legend()\n",
    "\n",
    "        # === Finalize and Save ===\n",
    "        plt.suptitle(f\"Single Step Profile Comparisons at Time Step {time_step}\", fontsize=18)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "\n",
    "        save_path = os.path.join(SAVE_DIR, f\"Profile_Summary_point_{time_step}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Combined plot saved for sampled point {time_step}\")\n",
    "\n",
    "    # Final debug\n",
    "    print(\"Finished processing all sampled points.\")\n",
    "        # Debugging prints\n",
    "    print(predictions.shape) \n",
    "    print(real_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722d39c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
