{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWi0w8G07_2G",
        "outputId": "d7b6c2e4-6c31-4122-be65-e9bef0352d76"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import numpy as np\n",
        "from scipy.integrate import solve_ivp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8jD34tx8HAT"
      },
      "outputs": [],
      "source": [
        "psi = np.load('/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vKXlQjvFavj"
      },
      "outputs": [],
      "source": [
        "# Pre-processing\n",
        "\n",
        "lead = 1\n",
        "\n",
        "trainN = 200000\n",
        "valN = 50000\n",
        "index = 63\n",
        "\n",
        "psi = psi[:,1,:]\n",
        "\n",
        "print(psi.shape)\n",
        "mean_psi = np.mean(psi, axis=0, keepdims=True)\n",
        "std_psi = np.std(psi, axis=0, keepdims=True)\n",
        "psi = (psi - mean_psi) / std_psi\n",
        "\n",
        "psi_train_input = torch.tensor(psi[0:trainN,:])\n",
        "psi_train_label =  torch.tensor(psi[lead:trainN+lead,:])\n",
        "\n",
        "psi_val_input = torch.tensor(psi[trainN:trainN+valN,:])\n",
        "psi_val_label =  torch.tensor(psi[trainN+lead:trainN+valN+lead,:])\n",
        "\n",
        "print(psi_train_input.shape)\n",
        "print(psi_train_label.shape)\n",
        "print(psi_val_input.shape)\n",
        "print(psi_val_label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2cRLYTu-nIH",
        "outputId": "8ac8610e-7b7b-405b-de49-fccb2d3d1217"
      },
      "outputs": [],
      "source": [
        "print(np.shape(psi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(psi_train_input[0:200000,63])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "0j0V94c6-wQG",
        "outputId": "fdff92c7-9c06-49bb-f924-3e1edf25d048"
      },
      "outputs": [],
      "source": [
        "plt.plot(psi_val_input[0:200000,63])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the encoder (MLP)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(75, 512)  # Input layer (2 + 2) -> Hidden layer (128)\n",
        "        self.fc2 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc3 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc4 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc5 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc6 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc_mu = nn.Linear(512, latent_dim)  # Hidden layer (128) -> Latent space (2)\n",
        "        self.fc_logvar = nn.Linear(512, latent_dim)  # Hidden layer (128) -> Log variance (2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))  # Activation function for hidden layer\n",
        "        x = torch.relu(self.fc2(x)) + x\n",
        "        x = torch.relu(self.fc3(x)) + x\n",
        "        x = torch.relu(self.fc4(x)) + x\n",
        "        mu = self.fc_mu(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mu, logvar\n",
        "\n",
        "# Define the decoder (MLP)\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, output_dim, condition_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim + condition_dim, 512)  # Input layer (2 + 2) -> Hidden layer (128)\n",
        "        self.fc2 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc3 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc4 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc5 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc6 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc_output = nn.Linear(512, output_dim)  # Hidden layer (128) -> Output layer (2)\n",
        "\n",
        "    def forward(self, z, condition):\n",
        "        z = torch.cat((z, condition), dim=1)  # Concatenate latent vector and condition\n",
        "        z = torch.relu(self.fc1(z))  # Activation function for hidden layer\n",
        "        z = torch.relu(self.fc2(z)) + z\n",
        "        z = torch.relu(self.fc3(z)) + z\n",
        "        z = torch.relu(self.fc4(z)) + z\n",
        "        output = self.fc_output(z)\n",
        "        return output\n",
        "\n",
        "# Define the VAE model\n",
        "class ConditionalVAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim, output_dim, condition_dim):\n",
        "        super(ConditionalVAE, self).__init__()\n",
        "        self.encoder = Encoder(input_dim, latent_dim)\n",
        "        self.decoder = Decoder(latent_dim, output_dim, condition_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def decode(self, z, condition):\n",
        "        return self.decoder(z, condition)\n",
        "\n",
        "    def forward(self, x, condition):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        output = self.decode(z, condition)\n",
        "        return output, mu, logvar\n",
        "\n",
        "input_dim = 1\n",
        "output_dim = 75\n",
        "latent_dim = 1024\n",
        "condition_dim = 75\n",
        "batch_size = 1024\n",
        "num_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVG1Hn1z-4br"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = ConditionalVAE(input_dim, latent_dim, output_dim, condition_dim)\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "folder = f\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_at_{datetime.datetime.now()}\"\n",
        "model_weights_path = f'{folder}/model_weights_pytorch.pth'\n",
        "os.makedirs(folder)\n",
        "\n",
        "# from torchsummary import summary\n",
        "\n",
        "# summary(model, input_size = [(128, 1, 75), (128, 75)])\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in range (0, trainN, batch_size):\n",
        "\n",
        "        input_batch = psi_train_input[batch:batch + batch_size,:]\n",
        "        label_batch = psi_train_label[batch:batch + batch_size,:]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output, mu, logvar = model(label_batch.float().cuda(), input_batch.float().cuda())\n",
        "\n",
        "        # Reconstruction loss\n",
        "        reconstruction_loss = F.mse_loss(output, label_batch.float().cuda(), reduction=\"sum\")\n",
        "        # KL divergence loss\n",
        "        kl_loss = 0.5 * (mu ** 2 + torch.exp(logvar) - 1 - logvar).sum()\n",
        "        \n",
        "        # Total loss\n",
        "        loss = reconstruction_loss + 10 * kl_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'''Epoch {epoch+1}, \n",
        "          Reconstrunction Loss: {reconstruction_loss},\n",
        "          KL Divergence Loss: {kl_loss}''')\n",
        "\n",
        "    # Validation Loss\n",
        "    for batch in range (0, valN, batch_size):\n",
        "\n",
        "        input_batch = psi_val_input[batch:batch + batch_size,:]\n",
        "        label_batch = psi_val_label[batch:batch + batch_size,:]\n",
        "        \n",
        "        output, mu, logvar = model(label_batch.float().cuda(), input_batch.float().cuda())\n",
        "        reconstruction_loss = F.mse_loss(output, label_batch.float().cuda(), reduction=\"sum\")\n",
        "        kl_loss = 0.5 * (mu ** 2 + torch.exp(logvar) - 1 - logvar).sum()\n",
        "        val_loss = reconstruction_loss + 10 * kl_loss # Experiment HIGHER coefficients\n",
        "        # Print both reconstruction_loss and kl_loss\n",
        "\n",
        "    print(f'''\n",
        "          Validation Reconstrunction Loss: {reconstruction_loss},\n",
        "          Validation KL Divergence Loss: {kl_loss}''')\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{folder}/checkpoint_{epoch+1}\")\n",
        "    print(f\"Model weights saved to {folder} with point {epoch+1}.\")\n",
        "    \n",
        "    # Inference\n",
        "\n",
        "    initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "    time_step = 30000\n",
        "    z = torch.zeros([1,latent_dim])\n",
        "    num_ens = 1\n",
        "    pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "\n",
        "    for k in range (0, time_step):\n",
        "\n",
        "        for ens in range (0, num_ens):\n",
        "            if (k ==0):\n",
        "\n",
        "                z = torch.randn_like(z)\n",
        "                print(z.shape, initial_cond.shape)\n",
        "                y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:,ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            else:\n",
        "                select_ens = np.random.randint(0,num_ens,1)\n",
        "                z = torch.randn_like(z)\n",
        "                y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:, ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "    # Denormalize final preds\n",
        "    print(std_psi[:, 63])\n",
        "    pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "    # Denormalize test labels\n",
        "    actual_values = psi_train_label[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "    print(actual_values)\n",
        "\n",
        "    plt.plot(pred_mean[0:30000,63],'r')\n",
        "    plt.plot(actual_values[0:30000],'b')\n",
        "    plt.title(f\"Predictions vs Actual | Batch size of {batch_size}\")\n",
        "    plt.savefig(f'{folder}/prediction_epoch_{epoch+1}.png')\n",
        "    plt.show()\n",
        "    plt.cla()\n",
        "\n",
        "torch.save(model.state_dict(), f\"{model_weights_path}\")\n",
        "print(f\"Model weights saved to {folder} with point {epoch+1}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inference\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = ConditionalVAE(input_dim, latent_dim, output_dim, condition_dim)\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# MODIFY THIS LINE FOR MODEL TESTING\n",
        "model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Finetuned_Resnet_VAE_model_at_2025-03-29 16:48:56.932248/checkpoint_5\"\n",
        "\n",
        "if os.path.exists(model_weights_path):\n",
        "    model.load_state_dict(torch.load(model_weights_path))\n",
        "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
        "\n",
        "initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "time_step = 300000\n",
        "z = torch.zeros([1,latent_dim])\n",
        "num_ens = 1\n",
        "pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "for k in range (0, time_step):\n",
        "\n",
        "    for ens in range (0, num_ens):\n",
        "        if (k ==0):\n",
        "\n",
        "            z = torch.randn_like(z)\n",
        "            print(z.shape, initial_cond.shape)\n",
        "            y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "            pred[k,:,ens] = y\n",
        "            y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "            initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "        else:\n",
        "            select_ens = np.random.randint(0,num_ens,1)\n",
        "            z = torch.randn_like(z)\n",
        "            y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "            pred[k,:, ens] = y\n",
        "            y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "            initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "# Denormalize final preds\n",
        "print(std_psi[:, 63])\n",
        "pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "# Denormalize test labels\n",
        "actual_values = psi[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "print(actual_values)\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(pred_mean[0:300000,63],'r')\n",
        "plt.plot(actual_values[0:300000],'b')\n",
        "plt.grid(True)\n",
        "plt.title(f\"Predictions vs Actual | Checkpoint 4(best)\")\n",
        "plt.savefig(f'/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/plots/temp_preds/prediction_vs_actual_{datetime.datetime.now()}.png')\n",
        "plt.show()\n",
        "plt.cla()\n",
        "\n",
        "# MODIFY THIS LINE FOR MODEL TESTING\n",
        "np.save(f'/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Finetuned_Resnet_VAE_model_at_2025-03-29 16:48:56.932248/predictions_best_checkpoint_Finetuned_Resnet_VAE_1.npy', pred_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Denormalize final preds\n",
        "print(std_psi[:, 63])\n",
        "pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "# Denormalize test labels\n",
        "actual_values = psi[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "print(actual_values)\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(pred_mean[0:300000,63],'r')\n",
        "plt.plot(actual_values[0:300000],'b')\n",
        "plt.grid(True)\n",
        "plt.title(f\"Predictions vs Actual | Checkpoint 5\")\n",
        "plt.savefig(f'{folder}/prediction_vs_actual.png')\n",
        "plt.show()\n",
        "plt.cla()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing the Predictive Model\n",
        "\n",
        "## Overview\n",
        "This section outlines our testing strategy to validate the accuracy, robustness, and reliability of our predictive model. Rigorous testing is critical to ensure that our model performs well under various tests.\n",
        "Set flags to 1 based on which metric(s) you would like to test.\n",
        "\n",
        "In the next cell are the flags and some basic parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#FLAGS to determine testing\n",
        "plot_data = 1\n",
        "#what level do you want to plot\n",
        "level = 63\n",
        "CCDF = 1\n",
        "Bi_modal_distribution = 1\n",
        "single_step_profiles = 1\n",
        "#for the single_step_profiles\n",
        "NUM_SAMPLES = 5\n",
        "#what weights do you want to use?\n",
        "MODEL_PATH = r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_at_2025-03-25 16:07:01.635719/checkpoint_4_promising\"\n",
        "LEVEL = 63"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are two paths here that you will manually set. One to the physical data and the other to the predictions. \n",
        "# WARNING\n",
        "Unless you're running new tests...\n",
        "Do not run this cell multiple times after testing as it will create a new folder based on your current time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Initialize Data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Load the data; shape = (300000, 2, 75)\n",
        "real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "predictions = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Finetuned_Resnet_VAE_model_at_2025-03-29 16:48:56.932248/predictions_best_checkpoint_Finetuned_Resnet_VAE_1.npy\")\n",
        "\n",
        "#reshape the predictions so that it matches the real_data shape\n",
        "predictions = predictions.reshape(300000, 1, 75)\n",
        "print(predictions.shape)\n",
        "print(real_data.shape)\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S.%f\")\n",
        "folder = f\"testing_at_{timestamp}\"\n",
        "os.mkdir(folder)\n",
        "subfolders = ['timeseries', 'CCDF', 'bi_modal_distribution', 'single_step_profiles']\n",
        "# Create each subdirectory inside the main folder\n",
        "for subfolder in subfolders:\n",
        "    path = os.path.join(folder, subfolder)\n",
        "    os.mkdir(path)\n",
        "    print(f\"Created subfolder: {path}\")\n",
        "SAVE_DIR = os.path.join(folder, \"single_step_profiles\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CCDF Error bars\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "import seaborn as sns\n",
        "\n",
        "CCDF_sum = 0\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = ConditionalVAE(input_dim, latent_dim, output_dim, condition_dim)\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# MODIFY THIS LINE FOR MODEL TESTING\n",
        "model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_at_2025-03-25 16:07:01.635719/checkpoint_4_promising\"\n",
        "\n",
        "if os.path.exists(model_weights_path):\n",
        "    model.load_state_dict(torch.load(model_weights_path))\n",
        "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
        "    \n",
        "for i in range(0, 10):\n",
        "    # Inference\n",
        "    initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "    time_step = 300000\n",
        "    z = torch.zeros([1,latent_dim])\n",
        "    num_ens = 1\n",
        "    pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "    for k in range (0, time_step):\n",
        "\n",
        "        for ens in range (0, num_ens):\n",
        "            if (k ==0):\n",
        "\n",
        "                z = torch.randn_like(z)\n",
        "                print(z.shape, initial_cond.shape)\n",
        "                y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:,ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            else:\n",
        "                select_ens = np.random.randint(0,num_ens,1)\n",
        "                z = torch.randn_like(z)\n",
        "                y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:, ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "    # Denormalize final preds\n",
        "    print(std_psi[:, 63])\n",
        "    pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "    # Denormalize test labels\n",
        "    actual_values = psi[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "    print(actual_values)\n",
        "\n",
        "    # Load the data; shape = (300000, 2, 75)\n",
        "    real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "    predictions = pred_mean.reshape(300000, 1, 75)\n",
        "\n",
        "    if (CCDF):\n",
        "        real_data_1d = real_data[:, 1, 63]  # Now shape is (309700,)\n",
        "        predictions_1d = predictions[:, 0, 63]  # shape (300000,)\n",
        "\n",
        "        # Define bounds (assuming they apply to both datasets)\n",
        "        upper_bound = 53.8 / 2.8935\n",
        "        lower_bound = 1.75 / 2.8935\n",
        "\n",
        "        # Function to calculate transition durations\n",
        "        def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "            times_between_transitions = []\n",
        "            transition_start = None\n",
        "            above_upper = False\n",
        "            below_lower = False\n",
        "\n",
        "            for i in range(1, len(y_values)):\n",
        "                if y_values[i] < lower_bound:  \n",
        "                    below_lower = True\n",
        "                    above_upper = False\n",
        "                elif y_values[i] > upper_bound:  \n",
        "                    if below_lower and transition_start is not None:\n",
        "                        times_between_transitions.append(i - transition_start)\n",
        "                        transition_start = None  \n",
        "                    above_upper = True\n",
        "                    below_lower = False\n",
        "\n",
        "                if below_lower and transition_start is None:\n",
        "                    transition_start = i\n",
        "\n",
        "            return times_between_transitions\n",
        "\n",
        "        # Compute transition durations for real data\n",
        "        real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "\n",
        "        # Compute transition durations for predictions data\n",
        "        pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "\n",
        "        # Plot setup\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        def bootstrap_ci(data, num_bootstraps=1000, confidence_level=0.95):\n",
        "            sample_size = len(data)\n",
        "            bootstrap_means = np.zeros(num_bootstraps)\n",
        "            \n",
        "            for i in range(num_bootstraps):\n",
        "                bootstrap_sample = np.random.choice(data, size=sample_size, replace=True)\n",
        "                bootstrap_means[i] = np.mean(bootstrap_sample)\n",
        "            \n",
        "            ci_lower = np.percentile(bootstrap_means, (1 - confidence_level) / 2 * 100)\n",
        "            ci_upper = np.percentile(bootstrap_means, (1 + confidence_level) / 2 * 100)\n",
        "            \n",
        "            return np.mean(data), ci_lower, ci_upper\n",
        "\n",
        "        # === REAL DATA CCDF AND FIT ===\n",
        "        if len(real_durations) == 0:\n",
        "            print(\"No transitions detected in real data with current bounds!\")\n",
        "        else:\n",
        "            real_data_sorted = np.sort(real_durations)\n",
        "            ccdf_real = 1 - np.arange(1, len(real_data_sorted) + 1) / len(real_data_sorted)\n",
        "\n",
        "            valid_indices_real = ccdf_real > 0\n",
        "            x_fit_real = real_data_sorted[valid_indices_real]\n",
        "            y_fit_real = np.log(ccdf_real[valid_indices_real])\n",
        "\n",
        "            slope_real, intercept_real, *_ = linregress(x_fit_real, y_fit_real)\n",
        "\n",
        "            x_line_real = np.linspace(min(x_fit_real), max(x_fit_real), 40)\n",
        "            y_line_real = np.exp(slope_real * x_line_real + intercept_real)\n",
        "\n",
        "            # Create a grid of x values (time steps / durations)\n",
        "\n",
        "            bootstrap_mean = []\n",
        "            ci_lower_vals = []\n",
        "            ci_upper_vals = []\n",
        "\n",
        "            for x in x_line_real:\n",
        "                valid_indices = (real_durations > x).astype(float)\n",
        "                mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
        "                bootstrap_mean.append(mean_val)\n",
        "                ci_lower_vals.append(lower)\n",
        "                ci_upper_vals.append(upper)\n",
        "\n",
        "            bootstrap_mean = np.array(bootstrap_mean)\n",
        "            ci_lower_vals = np.array(ci_lower_vals)\n",
        "            ci_upper_vals = np.array(ci_upper_vals)\n",
        "\n",
        "            # Calculate error bars (difference from the bootstrap mean)\n",
        "            error_lower = bootstrap_mean - ci_lower_vals\n",
        "            error_upper = ci_upper_vals - bootstrap_mean\n",
        "\n",
        "            plt.step(real_data_sorted, ccdf_real, where='post', label='Real Data CCDF', linewidth=2, linestyle='--')\n",
        "            plt.errorbar(x_line_real, bootstrap_mean, yerr=[error_lower, error_upper],\n",
        "                    fmt='o', color='blue', capsize=3, ecolor='blue', label='Real Bootstrap 95% CI')\n",
        "            plt.plot(x_line_real, y_line_real, 'b-', label=f'Real Exp Fit (slope={slope_real:.4f})', linewidth=2)\n",
        "\n",
        "        # === PREDICTIONS CCDF AND FIT ===\n",
        "        if len(pred_durations) == 0:\n",
        "            print(\"No transitions detected in predictions with current bounds!\")\n",
        "        else:\n",
        "            pred_data_sorted = np.sort(pred_durations)\n",
        "            ccdf_pred = 1 - np.arange(1, len(pred_data_sorted) + 1) / len(pred_data_sorted)\n",
        "\n",
        "            valid_indices_pred = ccdf_pred > 0\n",
        "            x_fit_pred = pred_data_sorted[valid_indices_pred]\n",
        "            y_fit_pred = np.log(ccdf_pred[valid_indices_pred])\n",
        "\n",
        "            slope_pred, intercept_pred, *_ = linregress(x_fit_pred, y_fit_pred)\n",
        "\n",
        "            x_line_pred = np.linspace(min(x_fit_pred), max(x_fit_pred), 40)\n",
        "            y_line_pred = np.exp(slope_pred * x_line_pred + intercept_pred)\n",
        "\n",
        "            # Create a grid of x values (time steps / durations)\n",
        "\n",
        "            bootstrap_mean = []\n",
        "            ci_lower_vals = []\n",
        "            ci_upper_vals = []\n",
        "\n",
        "            for x in x_line_pred:\n",
        "                valid_indices = (pred_durations > x).astype(float)\n",
        "                mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
        "                bootstrap_mean.append(mean_val)\n",
        "                ci_lower_vals.append(lower)\n",
        "                ci_upper_vals.append(upper)\n",
        "\n",
        "            bootstrap_mean = np.array(bootstrap_mean)\n",
        "            ci_lower_vals = np.array(ci_lower_vals)\n",
        "            ci_upper_vals = np.array(ci_upper_vals)\n",
        "\n",
        "            # Calculate error bars (difference from the bootstrap mean)\n",
        "            error_lower = bootstrap_mean - ci_lower_vals\n",
        "            error_upper = ci_upper_vals - bootstrap_mean\n",
        "\n",
        "            plt.step(pred_data_sorted, ccdf_pred, where='post', label='Predictions CCDF', linewidth=2, linestyle='-.', color='red')\n",
        "            plt.errorbar(x_line_pred, bootstrap_mean, yerr=[error_lower, error_upper],\n",
        "                    fmt='o', color='red', capsize=3, ecolor='red', label='Pred Bootstrap 95% CI')\n",
        "            plt.plot(x_line_pred, y_line_pred, 'r-', label=f'Pred Exp Fit (slope={slope_pred:.4f})', linewidth=2)\n",
        "\n",
        "            CCDF_sum += slope_pred\n",
        "\n",
        "        # Plot labels and formatting\n",
        "        plt.xlabel('Time Duration (Steps)')\n",
        "        plt.ylabel('CCDF')\n",
        "        plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "        plt.yscale(\"log\")  # y-axis log scale\n",
        "        plt.xscale(\"linear\")  # x-axis linear scale\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(folder, \"CCDF\")\n",
        "        save_path = os.path.join(save_path, f\"CCDF_plot{i}\")\n",
        "        plt.savefig(save_path)\n",
        "        plt.show()\n",
        "\n",
        "CCDF_avg = CCDF_sum/10\n",
        "print(CCDF_avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tests package\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "import seaborn as sns\n",
        "import random\n",
        "if (plot_data):\n",
        "    #note that the value 300000 will have to change depending on the real and predictions data length\n",
        "    u_profile_real = real_data[:300000, 1, level]  # Match time length with predictions\n",
        "    u_profile_pred = predictions[:, 0, level]\n",
        "    time_steps = np.arange(len(u_profile_pred))\n",
        "\n",
        "    # === Plot ===\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    plt.plot(time_steps, u_profile_real, label='Real Data', alpha=0.7)\n",
        "    plt.plot(time_steps, u_profile_pred, label='Predictions', linestyle='--')\n",
        "\n",
        "\n",
        "    # Labels, legend, and formatting\n",
        "    plt.xlabel('Time step')\n",
        "    plt.ylabel('U (m/s)')\n",
        "    plt.title(f'Time Series of U at Vertical Level {level}')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(folder, \"timeseries\")\n",
        "    save_path = os.path.join(save_path, \"real_prediction_plot\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "\n",
        "if (CCDF):\n",
        "    real_data_1d = real_data[:, 1, 61]  # Now shape is (309700,)\n",
        "    predictions_1d = predictions[:, 0, 61]  # shape (300000,)\n",
        "\n",
        "    # Define bounds (assuming they apply to both datasets)\n",
        "    upper_bound = 53.8 / 2.8935\n",
        "    lower_bound = 1.75 / 2.8935\n",
        "\n",
        "    # Function to calculate transition durations\n",
        "    def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "        times_between_transitions = []\n",
        "        transition_start = None\n",
        "        above_upper = False\n",
        "        below_lower = False\n",
        "\n",
        "        for i in range(1, len(y_values)):\n",
        "            if y_values[i] < lower_bound:  \n",
        "                below_lower = True\n",
        "                above_upper = False\n",
        "            elif y_values[i] > upper_bound:  \n",
        "                if below_lower and transition_start is not None:\n",
        "                    times_between_transitions.append(i - transition_start)\n",
        "                    transition_start = None  \n",
        "                above_upper = True\n",
        "                below_lower = False\n",
        "\n",
        "            if below_lower and transition_start is None:\n",
        "                transition_start = i\n",
        "\n",
        "        return times_between_transitions\n",
        "\n",
        "    # Compute transition durations for real data\n",
        "    real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "\n",
        "    # Compute transition durations for predictions data\n",
        "    pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "\n",
        "    # Plot setup\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # === REAL DATA CCDF AND FIT ===\n",
        "    if len(real_durations) == 0:\n",
        "        print(\"No transitions detected in real data with current bounds!\")\n",
        "    else:\n",
        "        real_data_sorted = np.sort(real_durations)\n",
        "        ccdf_real = 1 - np.arange(1, len(real_data_sorted) + 1) / len(real_data_sorted)\n",
        "\n",
        "        valid_indices_real = ccdf_real > 0\n",
        "        x_fit_real = real_data_sorted[valid_indices_real]\n",
        "        y_fit_real = np.log(ccdf_real[valid_indices_real])\n",
        "\n",
        "        slope_real, intercept_real, *_ = linregress(x_fit_real, y_fit_real)\n",
        "\n",
        "        x_line_real = np.linspace(min(x_fit_real), max(x_fit_real), 100)\n",
        "        y_line_real = np.exp(slope_real * x_line_real + intercept_real)\n",
        "\n",
        "        plt.step(real_data_sorted, ccdf_real, where='post', label='Real Data CCDF', linewidth=2, linestyle='--')\n",
        "        plt.plot(x_line_real, y_line_real, 'b-', label=f'Real Exp Fit (slope={slope_real:.4f})', linewidth=2)\n",
        "\n",
        "    # === PREDICTIONS CCDF AND FIT ===\n",
        "    if len(pred_durations) == 0:\n",
        "        print(\"No transitions detected in predictions with current bounds!\")\n",
        "    else:\n",
        "        pred_data_sorted = np.sort(pred_durations)\n",
        "        ccdf_pred = 1 - np.arange(1, len(pred_data_sorted) + 1) / len(pred_data_sorted)\n",
        "\n",
        "        valid_indices_pred = ccdf_pred > 0\n",
        "        x_fit_pred = pred_data_sorted[valid_indices_pred]\n",
        "        y_fit_pred = np.log(ccdf_pred[valid_indices_pred])\n",
        "\n",
        "        slope_pred, intercept_pred, *_ = linregress(x_fit_pred, y_fit_pred)\n",
        "\n",
        "        x_line_pred = np.linspace(min(x_fit_pred), max(x_fit_pred), 100)\n",
        "        y_line_pred = np.exp(slope_pred * x_line_pred + intercept_pred)\n",
        "\n",
        "        plt.step(pred_data_sorted, ccdf_pred, where='post', label='Predictions CCDF', linewidth=2, linestyle='-.', color='red')\n",
        "        plt.plot(x_line_pred, y_line_pred, 'r-', label=f'Pred Exp Fit (slope={slope_pred:.4f})', linewidth=2)\n",
        "\n",
        "    # Plot labels and formatting\n",
        "    plt.xlabel('Time Duration (Steps)')\n",
        "    plt.ylabel('CCDF')\n",
        "    plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "    plt.yscale(\"log\")  # y-axis log scale\n",
        "    plt.xscale(\"linear\")  # x-axis linear scale\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(folder, \"CCDF\")\n",
        "    save_path = os.path.join(save_path, \"CCDF_plot\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "if (Bi_modal_distribution):\n",
        "    zonal_wind_data_real = real_data[:, 1, 63]  # variable index 1 (e.g., zonal wind), level 60\n",
        "    zonal_wind_data_predictions = predictions[:, 0, 63]  # variable index 0 (predictions), level 60\n",
        "\n",
        "    print(f\"Shape of zonal_wind_data_real: {zonal_wind_data_real.shape}\")\n",
        "    print(f\"Shape of zonal_wind_data_predictions: {zonal_wind_data_predictions.shape}\")\n",
        "\n",
        "    # Plot the bimodal histogram\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Create histograms (overlaid)\n",
        "    sns.histplot(zonal_wind_data_real, bins=50, kde=True, color='black', alpha=0.6, element='step', label='Real Data')\n",
        "    sns.histplot(zonal_wind_data_predictions, bins=50, kde=True, color='red', alpha=0.6, element='step', label='Predictions')\n",
        "\n",
        "    # Customize plot labels and title\n",
        "    plt.title('Distribution of Zonal Winds For Real Data and Predictions', fontsize=16)\n",
        "    plt.xlabel('Zonal Wind (m/s)', fontsize=14)\n",
        "    plt.ylabel('Frequency', fontsize=14)\n",
        "\n",
        "    # Add vertical lines at means\n",
        "    plt.axvline(np.mean(zonal_wind_data_real), color='black', linestyle='--', label=f'Real Mean: {np.mean(zonal_wind_data_real):.2f}')\n",
        "    plt.axvline(np.mean(zonal_wind_data_predictions), color='red', linestyle='--', label=f'Pred Mean: {np.mean(zonal_wind_data_predictions):.2f}')\n",
        "\n",
        "    # Final plot settings\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(folder, \"bi_modal_distribution\")\n",
        "    save_path = os.path.join(save_path, \"bi_modal_distribution_plot\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "if (single_step_profiles):\n",
        "    # Ensure save directory exists\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    # === Load model weights ===\n",
        "    model.load_state_dict(torch.load(MODEL_PATH))\n",
        "    model.eval()\n",
        "\n",
        "    # === Randomly sample time points from real data ===\n",
        "    time_indices = random.sample(range(0, real_data.shape[0] - 2), NUM_SAMPLES)\n",
        "    print(f\"Randomly sampled time steps: {time_indices}\")\n",
        "\n",
        "    # === Time series visualization ===\n",
        "    real_data_timeseries = real_data[:, 1, LEVEL]\n",
        "    time_steps_all = np.arange(len(real_data_timeseries))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(time_steps_all, real_data_timeseries, label=\"Real Data at Level 61\", color='blue')\n",
        "\n",
        "    # Mark sample points\n",
        "    for idx_num, idx in enumerate(time_indices):\n",
        "        plt.axvline(x=idx, color='green', linestyle='--', linewidth=2)\n",
        "    if len(time_indices) > 0:\n",
        "        plt.axvline(x=time_indices[0], color='green', linestyle='--', linewidth=2, label='Sampled Points')\n",
        "\n",
        "    plt.title(\"Real Data Time Series with Sampled Points Highlighted\")\n",
        "    plt.xlabel(\"Time Step\")\n",
        "    plt.ylabel(\"U (m/s) at Level 61\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_path = os.path.join(SAVE_DIR, \"real_data_timeseries_with_samples.png\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    # === Iterate over each sampled time point ===\n",
        "    for i, time_step in enumerate(time_indices):\n",
        "        next_time_step = time_step + 1\n",
        "\n",
        "        # === Real data: current and next ===\n",
        "        real_current = real_data[time_step, 1, :]       \n",
        "        real_next = real_data[next_time_step, 1, :]      \n",
        "\n",
        "        # === Normalize real_current and make prediction for next step ===\n",
        "        initial_condition_normalized = (real_current.reshape(1, 75, 1) - mean_psi.reshape(1, -1, 1)) / std_psi.reshape(1, -1, 1)\n",
        "        current_input = torch.tensor(initial_condition_normalized, dtype=torch.float32).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn_like(z)\n",
        "            print(z.shape, initial_cond.shape)\n",
        "            y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "\n",
        "        # === Denormalize predicted next ===\n",
        "        pred_next_denorm = y.squeeze() * std_psi.squeeze() + mean_psi.squeeze()\n",
        "\n",
        "        # === Extract U, Re(Psi), Im(Psi) components ===\n",
        "        # U profiles\n",
        "        U_current_real = real_current[51:74]\n",
        "        U_next_real = real_next[51:74]\n",
        "        U_next_pred = pred_next_denorm[51:74]\n",
        "\n",
        "        # Re(Psi) profiles\n",
        "        RePsi_current_real = real_current[0:24]\n",
        "        RePsi_next_real = real_next[0:24]\n",
        "        RePsi_next_pred = pred_next_denorm[0:24]\n",
        "\n",
        "        # Im(Psi) profiles\n",
        "        ImPsi_current_real = real_current[25:50]\n",
        "        ImPsi_next_real = real_next[25:50]\n",
        "        ImPsi_next_pred = pred_next_denorm[25:50]\n",
        "\n",
        "        # === Differences ===\n",
        "        U_diff_real = U_next_real - U_current_real\n",
        "        U_diff_pred = U_next_pred - U_current_real\n",
        "\n",
        "        RePsi_diff_real = RePsi_next_real - RePsi_current_real\n",
        "        RePsi_diff_pred = RePsi_next_pred - RePsi_current_real\n",
        "\n",
        "        ImPsi_diff_real = ImPsi_next_real - ImPsi_current_real\n",
        "        ImPsi_diff_pred = ImPsi_next_pred - ImPsi_current_real\n",
        "\n",
        "        # === Create a single figure with 3 rows (U, Re(Psi), Im(Psi)) ===\n",
        "        fig, axes = plt.subplots(3, 2, figsize=(16, 18))  # 3 rows, 2 columns (Profile and Difference)\n",
        "\n",
        "        z_levels_U = np.linspace(0, 70, 23)\n",
        "        z_levels_RePsi = np.linspace(0, 70, 24)\n",
        "        z_levels_ImPsi = np.linspace(0, 70, 25)\n",
        "\n",
        "        # --- U ---\n",
        "        axes[0, 0].plot(U_current_real, z_levels_U, 'x-', label=\"Real Current\")\n",
        "        axes[0, 0].plot(U_next_real, z_levels_U, 'd-', label=\"Real Next\")\n",
        "        axes[0, 0].plot(U_next_pred, z_levels_U, 's--', label=\"Predicted Next\")\n",
        "        axes[0, 0].set_title(f\"U Profiles @ Step {time_step}\")\n",
        "        axes[0, 0].set_xlabel(\"U (m/s)\")\n",
        "        axes[0, 0].set_ylabel(\"Vertical Levels (km)\")\n",
        "        axes[0, 0].legend()\n",
        "\n",
        "        axes[0, 1].plot(U_diff_real, z_levels_U, 'xb', label=\"Real Δ (Next - Current)\")\n",
        "        axes[0, 1].plot(U_diff_pred, z_levels_U, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
        "        axes[0, 1].set_title(\"U Difference (Next - Current)\")\n",
        "        axes[0, 1].set_xlabel(\"ΔU (m/s)\")\n",
        "        axes[0, 1].legend()\n",
        "\n",
        "        # --- Re(Psi) ---\n",
        "        axes[1, 0].plot(RePsi_current_real, z_levels_RePsi, 'x-', label=\"Real Current\")\n",
        "        axes[1, 0].plot(RePsi_next_real, z_levels_RePsi, 'd-', label=\"Real Next\")\n",
        "        axes[1, 0].plot(RePsi_next_pred, z_levels_RePsi, 's--', label=\"Predicted Next\")\n",
        "        axes[1, 0].set_title(f\"Re(Psi) Profiles @ Step {time_step}\")\n",
        "        axes[1, 0].set_xlabel(\"Re(Psi)\")\n",
        "        axes[1, 0].set_ylabel(\"Vertical Levels (km)\")\n",
        "        axes[1, 0].legend()\n",
        "\n",
        "        axes[1, 1].plot(RePsi_diff_real, z_levels_RePsi, 'xb', label=\"Real Δ (Next - Current)\")\n",
        "        axes[1, 1].plot(RePsi_diff_pred, z_levels_RePsi, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
        "        axes[1, 1].set_title(\"Re(Psi) Difference (Next - Current)\")\n",
        "        axes[1, 1].set_xlabel(\"ΔRe(Psi)\")\n",
        "        axes[1, 1].legend()\n",
        "\n",
        "        # --- Im(Psi) ---\n",
        "        axes[2, 0].plot(ImPsi_current_real, z_levels_ImPsi, 'x-', label=\"Real Current\")\n",
        "        axes[2, 0].plot(ImPsi_next_real, z_levels_ImPsi, 'd-', label=\"Real Next\")\n",
        "        axes[2, 0].plot(ImPsi_next_pred, z_levels_ImPsi, 's--', label=\"Predicted Next\")\n",
        "        axes[2, 0].set_title(f\"Im(Psi) Profiles @ Step {time_step}\")\n",
        "        axes[2, 0].set_xlabel(\"Im(Psi)\")\n",
        "        axes[2, 0].set_ylabel(\"Vertical Levels (km)\")\n",
        "        axes[2, 0].legend()\n",
        "\n",
        "        axes[2, 1].plot(ImPsi_diff_real, z_levels_ImPsi, 'xb', label=\"Real Δ (Next - Current)\")\n",
        "        axes[2, 1].plot(ImPsi_diff_pred, z_levels_ImPsi, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
        "        axes[2, 1].set_title(\"Im(Psi) Difference (Next - Current)\")\n",
        "        axes[2, 1].set_xlabel(\"ΔIm(Psi)\")\n",
        "        axes[2, 1].legend()\n",
        "\n",
        "        # === Finalize and Save ===\n",
        "        plt.suptitle(f\"Single Step Profile Comparisons at Time Step {time_step}\", fontsize=18)\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "\n",
        "        save_path = os.path.join(SAVE_DIR, f\"Profile_Summary_point_{time_step}.png\")\n",
        "        plt.savefig(save_path)\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Combined plot saved for sampled point {time_step}\")\n",
        "\n",
        "    # Final debug\n",
        "    print(\"Finished processing all sampled points.\")\n",
        "        # Debugging prints\n",
        "    print(predictions.shape) \n",
        "    print(real_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Climate Loss Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Total Variation Distance\n",
        "def total_variation_distance(p,q):\n",
        "\tp = np.array(p)\n",
        "\tq = np.array(q)\n",
        "\treturn 0.5 * np.sum(np.abs(p-q))\n",
        "\n",
        "predictions = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/meetings/March_28th/ResNet/Inferences/predictions_best_checkpoint_Resnet_VAE_4.npy\")\n",
        "real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "print(predictions.shape)\n",
        "#actual implementation\n",
        "pred_hist, _ = np.histogram(predictions, bins=50, density=True)\n",
        "actual_hist, _ = np.histogram(real_data,bins=50,density=True)\n",
        "\n",
        "tvd = total_variation_distance(pred_hist,actual_hist)\n",
        "print(f\"TVD: {tvd}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import linregress\n",
        "import os\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = ConditionalVAE(input_dim, latent_dim, output_dim, condition_dim)\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_at_2025-03-25 16:07:01.635719/checkpoint_4_promising\"\n",
        "\n",
        "if os.path.exists(model_weights_path):\n",
        "    model.load_state_dict(torch.load(model_weights_path))\n",
        "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
        "\n",
        "def climate_loss_function(psi, model, latent_dim=1024, time_step=batch_size, num_ens=1):\n",
        "    if (CCDF):\n",
        "            # Inference\n",
        "            initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "            z = torch.zeros([1,latent_dim])\n",
        "            num_ens = 1\n",
        "            pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "            for k in range (0, time_step):\n",
        "\n",
        "                for ens in range (0, num_ens):\n",
        "                    if (k ==0):\n",
        "\n",
        "                        z = torch.randn_like(z)\n",
        "                        print(z.shape, initial_cond.shape)\n",
        "                        y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                        pred[k,:,ens] = y\n",
        "                        y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                        initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "                    else:\n",
        "                        select_ens = np.random.randint(0,num_ens,1)\n",
        "                        z = torch.randn_like(z)\n",
        "                        y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                        pred[k,:, ens] = y\n",
        "                        y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                        initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            # Denormalize final preds\n",
        "            print(std_psi[:, 63])\n",
        "            pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "            # Denormalize test labels\n",
        "            actual_values = psi[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "            print(actual_values)\n",
        "\n",
        "            # Load the data; shape = (300000, 2, 75)\n",
        "            real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "            predictions = pred_mean.reshape(time_step, 1, 75)\n",
        "\n",
        "            real_data_1d = real_data[:, 0, 63]  # Now shape is (309700,)\n",
        "            predictions_1d = predictions[:, 0, 63]  # shape (300000,)\n",
        "\n",
        "            # Define bounds (assuming they apply to both datasets)\n",
        "            upper_bound = 53.8 / 2.8935\n",
        "            lower_bound = 1.75 / 2.8935\n",
        "\n",
        "            # Function to calculate transition durations\n",
        "            def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "                times_between_transitions = []\n",
        "                transition_start = None\n",
        "                above_upper = False\n",
        "                below_lower = False\n",
        "\n",
        "                for i in range(1, len(y_values)):\n",
        "                    if y_values[i] < lower_bound:  \n",
        "                        below_lower = True\n",
        "                        above_upper = False\n",
        "                    elif y_values[i] > upper_bound:  \n",
        "                        if below_lower and transition_start is not None:\n",
        "                            times_between_transitions.append(i - transition_start)\n",
        "                            transition_start = None  \n",
        "                        above_upper = True\n",
        "                        below_lower = False\n",
        "\n",
        "                    if below_lower and transition_start is None:\n",
        "                        transition_start = i\n",
        "\n",
        "                return times_between_transitions\n",
        "\n",
        "            # Compute transition durations for real data\n",
        "            real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "\n",
        "            # Compute transition durations for predictions data\n",
        "            pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "\n",
        "            def bootstrap_ci(data, num_bootstraps=1000, confidence_level=0.95):\n",
        "                sample_size = len(data)\n",
        "                bootstrap_means = np.zeros(num_bootstraps)\n",
        "                \n",
        "                for i in range(num_bootstraps):\n",
        "                    bootstrap_sample = np.random.choice(data, size=sample_size, replace=True)\n",
        "                    bootstrap_means[i] = np.mean(bootstrap_sample)\n",
        "                \n",
        "                ci_lower = np.percentile(bootstrap_means, (1 - confidence_level) / 2 * 100)\n",
        "                ci_upper = np.percentile(bootstrap_means, (1 + confidence_level) / 2 * 100)\n",
        "                \n",
        "                return np.mean(data), ci_lower, ci_upper\n",
        "\n",
        "            # === REAL DATA CCDF AND FIT ===\n",
        "            if len(real_durations) == 0:\n",
        "                print(\"No transitions detected in real data with current bounds!\")\n",
        "            else:\n",
        "                real_data_sorted = np.sort(real_durations)\n",
        "                ccdf_real = 1 - np.arange(1, len(real_data_sorted) + 1) / len(real_data_sorted)\n",
        "\n",
        "                valid_indices_real = ccdf_real > 0\n",
        "                x_fit_real = real_data_sorted[valid_indices_real]\n",
        "                y_fit_real = np.log(ccdf_real[valid_indices_real])\n",
        "\n",
        "                slope_real, intercept_real, *_ = linregress(x_fit_real, y_fit_real)\n",
        "\n",
        "                x_line_real = np.linspace(min(x_fit_real), max(x_fit_real), 40)\n",
        "                y_line_real = np.exp(slope_real * x_line_real + intercept_real)\n",
        "\n",
        "                # Create a grid of x values (time steps / durations)\n",
        "\n",
        "                bootstrap_mean = []\n",
        "                ci_lower_vals = []\n",
        "                ci_upper_vals = []\n",
        "\n",
        "                for x in x_line_real:\n",
        "                    valid_indices = (real_durations > x).astype(float)\n",
        "                    mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
        "                    bootstrap_mean.append(mean_val)\n",
        "                    ci_lower_vals.append(lower)\n",
        "                    ci_upper_vals.append(upper)\n",
        "\n",
        "                bootstrap_mean = np.array(bootstrap_mean)\n",
        "                ci_lower_vals = np.array(ci_lower_vals)\n",
        "                ci_upper_vals = np.array(ci_upper_vals)\n",
        "\n",
        "                # Calculate error bars (difference from the bootstrap mean)\n",
        "                error_lower = bootstrap_mean - ci_lower_vals\n",
        "                error_upper = ci_upper_vals - bootstrap_mean\n",
        "\n",
        "                plt.step(real_data_sorted, ccdf_real, where='post', label='Real Data CCDF', linewidth=2, linestyle='--')\n",
        "                plt.errorbar(x_line_real, bootstrap_mean, yerr=[error_lower, error_upper],\n",
        "                        fmt='o', color='blue', capsize=3, ecolor='blue', label='Real Bootstrap 95% CI')\n",
        "                plt.plot(x_line_real, y_line_real, 'b-', label=f'Real Exp Fit (slope={slope_real:.4f})', linewidth=2)\n",
        "\n",
        "            # === PREDICTIONS CCDF AND FIT ===\n",
        "            if len(pred_durations) == 0:\n",
        "                print(\"No transitions detected in predictions with current bounds!\")\n",
        "            else:\n",
        "                pred_data_sorted = np.sort(pred_durations)\n",
        "                ccdf_pred = 1 - np.arange(1, len(pred_data_sorted) + 1) / len(pred_data_sorted)\n",
        "\n",
        "                valid_indices_pred = ccdf_pred > 0\n",
        "                x_fit_pred = pred_data_sorted[valid_indices_pred]\n",
        "                y_fit_pred = np.log(ccdf_pred[valid_indices_pred])\n",
        "\n",
        "                slope_pred, intercept_pred, *_ = linregress(x_fit_pred, y_fit_pred)\n",
        "\n",
        "                x_line_pred = np.linspace(min(x_fit_pred), max(x_fit_pred), 40)\n",
        "                y_line_pred = np.exp(slope_pred * x_line_pred + intercept_pred)\n",
        "\n",
        "                # Create a grid of x values (time steps / durations)\n",
        "\n",
        "                bootstrap_mean = []\n",
        "                ci_lower_vals = []\n",
        "                ci_upper_vals = []\n",
        "\n",
        "                for x in x_line_pred:\n",
        "                    valid_indices = (pred_durations > x).astype(float)\n",
        "                    mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
        "                    bootstrap_mean.append(mean_val)\n",
        "                    ci_lower_vals.append(lower)\n",
        "                    ci_upper_vals.append(upper)\n",
        "\n",
        "                bootstrap_mean = np.array(bootstrap_mean)\n",
        "                ci_lower_vals = np.array(ci_lower_vals)\n",
        "                ci_upper_vals = np.array(ci_upper_vals)\n",
        "\n",
        "                # Calculate error bars (difference from the bootstrap mean)\n",
        "                error_lower = bootstrap_mean - ci_lower_vals\n",
        "                error_upper = ci_upper_vals - bootstrap_mean\n",
        "\n",
        "                plt.step(pred_data_sorted, ccdf_pred, where='post', label='Predictions CCDF', linewidth=2, linestyle='-.', color='red')\n",
        "                plt.errorbar(x_line_pred, bootstrap_mean, yerr=[error_lower, error_upper],\n",
        "                        fmt='o', color='red', capsize=3, ecolor='red', label='Pred Bootstrap 95% CI')\n",
        "                plt.plot(x_line_pred, y_line_pred, 'r-', label=f'Pred Exp Fit (slope={slope_pred:.4f})', linewidth=2)\n",
        "\n",
        "                CCDF_loss = abs(slope_real-slope_pred)\n",
        "            \n",
        "            # Plot labels and formatting\n",
        "            plt.xlabel('Time Duration (Steps)')\n",
        "            plt.ylabel('CCDF')\n",
        "            plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "            plt.yscale(\"log\")  # y-axis log scale\n",
        "            plt.xscale(\"linear\")  # x-axis linear scale\n",
        "            plt.grid()\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            pred_hist, _ = np.histogram(predictions, bins=100, density=True)\n",
        "            actual_hist, _ = np.histogram(real_data,bins=100,density=True)\n",
        "\n",
        "            tvd = total_variation_distance(pred_hist,actual_hist)\n",
        "\n",
        "            return CCDF_loss, tvd\n",
        "\n",
        "CCDF_loss, tvd = climate_loss_function(psi, model, 1024, 300000, 1)\n",
        "climate_loss = tvd * 0.5 + CCDF_loss * 500\n",
        "print(climate_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from scipy.stats import linregress\n",
        "\n",
        "class ClimateModelLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ClimateModelLoss, self).__init__()\n",
        "\n",
        "    def calculate_transition_durations(self, y_values):\n",
        "        upper_bound=53.8 / 2.8935 \n",
        "        lower_bound=1.75 / 2.8935\n",
        "        times_between_transitions = []\n",
        "        transition_start = None\n",
        "        above_upper = False\n",
        "        below_lower = False\n",
        "\n",
        "        for i in range(1, len(y_values)):\n",
        "            if y_values[i] < lower_bound:  \n",
        "                below_lower = True\n",
        "                above_upper = False\n",
        "            elif y_values[i] > upper_bound:  \n",
        "                if below_lower and transition_start is not None:\n",
        "                    times_between_transitions.append(i - transition_start)\n",
        "                    transition_start = None  \n",
        "                above_upper = True\n",
        "                below_lower = False\n",
        "\n",
        "            if below_lower and transition_start is None:\n",
        "                transition_start = i\n",
        "\n",
        "        return times_between_transitions\n",
        "    \n",
        "    def compute_ccdf_slope(self, durations):\n",
        "        if len(durations) == 0:\n",
        "            return 0  # Return 0 if no transitions detected\n",
        "        \n",
        "        # Sort durations and compute CCDF\n",
        "        data_sorted = np.sort(durations)\n",
        "        ccdf = 1 - np.arange(1, len(data_sorted) + 1) / len(data_sorted)\n",
        "        \n",
        "        # Prepare data for linear regression\n",
        "        valid_indices = ccdf > 0\n",
        "        x_fit = data_sorted[valid_indices]\n",
        "        \n",
        "        # Check if we have enough valid data points\n",
        "        if len(x_fit) < 2:\n",
        "            return 0  # Not enough points for regression\n",
        "        \n",
        "        # Check if all x values are identical\n",
        "        if np.allclose(x_fit, x_fit[0], rtol=1e-10, atol=1e-10):\n",
        "            # If all x values are the same, we can't compute a meaningful slope\n",
        "            # Return a default value or handle the edge case appropriately\n",
        "            return 0\n",
        "    \n",
        "        y_fit = np.log(ccdf[valid_indices])\n",
        "        \n",
        "        # Compute slope using linear regression\n",
        "        slope, intercept, r_value, p_value, std_err = linregress(x_fit, y_fit)\n",
        "        \n",
        "        return slope\n",
        "    \n",
        "    def forward(self, predictions):\n",
        "        \n",
        "        # Select the specific column for analysis (column 63 in original code)\n",
        "        # and denormalize data\n",
        "        pred_denorm = predictions * std_psi[:, 63] + mean_psi[:, 63]\n",
        "        pred_1d = pred_denorm[:, 0, 63]\n",
        "        \n",
        "        # Compute real data transition durations (from loaded reference data)\n",
        "        real_data_1d = real_data[:, 0, 63]\n",
        "        \n",
        "        # Compute transition durations\n",
        "        real_durations = self.calculate_transition_durations(real_data_1d)\n",
        "        pred_durations = self.calculate_transition_durations(pred_1d)\n",
        "        \n",
        "        # Compute CCDF slopes\n",
        "        real_slope = self.compute_ccdf_slope(real_durations)\n",
        "        pred_slope = self.compute_ccdf_slope(pred_durations)\n",
        "        \n",
        "        # CCDF loss (difference in slopes)\n",
        "        ccdf_loss = abs(real_slope - pred_slope)\n",
        "        \n",
        "        # Total Variation Distance\n",
        "        pred_hist, _ = np.histogram(pred_1d, bins=100, density=True)\n",
        "        real_hist, _ = np.histogram(real_data_1d, bins=100, density=True)\n",
        "        tvd = np.sum(np.abs(pred_hist - real_hist)) / 2\n",
        "        \n",
        "        # Combine losses with weights\n",
        "        total_loss = 0 * ccdf_loss + 20 * tvd\n",
        "        \n",
        "        return torch.tensor(total_loss, dtype=torch.float32, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = ConditionalVAE(input_dim, latent_dim, output_dim, condition_dim)\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "folder = f\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Finetuned_Resnet_VAE_model_at_{datetime.datetime.now()}\"\n",
        "os.makedirs(folder)\n",
        "\n",
        "# MODIFY THIS LINE FOR MODEL TESTING\n",
        "model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_at_2025-03-25 16:07:01.635719/checkpoint_4_promising\"\n",
        "\n",
        "if os.path.exists(model_weights_path):\n",
        "    model.load_state_dict(torch.load(model_weights_path))\n",
        "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
        "\n",
        "num_epochs = 5\n",
        "climate_loss_fn = ClimateModelLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "    time_step = 0\n",
        "    z = torch.zeros([1, latent_dim])\n",
        "    num_ens = 1\n",
        "    pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "    for k in range (0, time_step):\n",
        "\n",
        "        for ens in range (0, num_ens):\n",
        "            if (k ==0):\n",
        "\n",
        "                z = torch.randn_like(z)\n",
        "                print(z.shape, initial_cond.shape)\n",
        "                y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:,ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            else:\n",
        "                select_ens = np.random.randint(0,num_ens,1)\n",
        "                z = torch.randn_like(z)\n",
        "                y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:, ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "    # Denormalize final preds\n",
        "    print(std_psi[:, 63])\n",
        "    pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "    # Denormalize test labels\n",
        "    actual_values = psi[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "    print(actual_values)\n",
        "\n",
        "    plt.figure(figsize=(20,8))\n",
        "    plt.plot(pred_mean[0:300000,63],'r')\n",
        "    plt.plot(actual_values[0:300000],'b')\n",
        "    plt.grid(True)\n",
        "    plt.title(f\"Predictions vs Actual | Checkpoint 4(best)\")\n",
        "    plt.savefig(f'/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/plots/temp_preds/prediction_vs_actual_{datetime.datetime.now()}.png')\n",
        "    plt.show()\n",
        "    plt.cla()\n",
        "\n",
        "    loss = climate_loss_fn(predictions)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'''Epoch {epoch+1}, \n",
        "          Climate Loss: {loss}''')\n",
        "\n",
        "    # Validation Loss\n",
        "    initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "    time_step = 300000\n",
        "    z = torch.zeros([1, latent_dim])\n",
        "    num_ens = 1\n",
        "    pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "    for k in range (0, time_step):\n",
        "\n",
        "        for ens in range (0, num_ens):\n",
        "            if (k ==0):\n",
        "\n",
        "                z = torch.randn_like(z)\n",
        "                print(z.shape, initial_cond.shape)\n",
        "                y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:,ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            else:\n",
        "                select_ens = np.random.randint(0,num_ens,1)\n",
        "                z = torch.randn_like(z)\n",
        "                y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:, ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "    # Denormalize final preds\n",
        "    print(std_psi[:, 63])\n",
        "    pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "    # Denormalize test labels\n",
        "    actual_values = psi[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "    print(actual_values)\n",
        "\n",
        "    plt.figure(figsize=(20,8))\n",
        "    plt.plot(pred_mean[0:300000,63],'r')\n",
        "    plt.plot(actual_values[0:300000],'b')\n",
        "    plt.grid(True)\n",
        "    plt.title(f\"Predictions vs Actual | Checkpoint 4(best)\")\n",
        "    plt.savefig(f'/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/plots/temp_preds/prediction_vs_actual_{datetime.datetime.now()}.png')\n",
        "    plt.show()\n",
        "    plt.cla()\n",
        "\n",
        "    val_loss = climate_loss_fn(predictions)\n",
        "\n",
        "    print(f'''Epoch {epoch+1}, \n",
        "          Validation Climate Loss: {val_loss}''')\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{folder}/checkpoint_{epoch+1}\")\n",
        "    print(f\"Model weights saved to {folder} with point {epoch+1}.\")\n",
        "\n",
        "# Inference\n",
        "\n",
        "initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "time_step = 30000\n",
        "z = torch.zeros([1,latent_dim])\n",
        "num_ens = 1\n",
        "pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "for k in range (0, time_step):\n",
        "\n",
        "    for ens in range (0, num_ens):\n",
        "        if (k ==0):\n",
        "\n",
        "            z = torch.randn_like(z)\n",
        "            print(z.shape, initial_cond.shape)\n",
        "            y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "            pred[k,:,ens] = y\n",
        "            y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "            initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "        else:\n",
        "            select_ens = np.random.randint(0,num_ens,1)\n",
        "            z = torch.randn_like(z)\n",
        "            y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "            pred[k,:, ens] = y\n",
        "            y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "            initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "# Denormalize final preds\n",
        "print(std_psi[:, 63])\n",
        "pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "# Denormalize test labels\n",
        "actual_values = psi_train_label[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "print(actual_values)\n",
        "\n",
        "plt.plot(pred_mean[0:30000,63],'r')\n",
        "plt.plot(actual_values[0:30000],'b')\n",
        "plt.title(f\"Predictions vs Actual | Batch size of {batch_size}\")\n",
        "plt.savefig(f'{folder}/prediction_epoch_{epoch+1}.png')\n",
        "plt.show()\n",
        "plt.cla()\n",
        "\n",
        "torch.save(model.state_dict(), f\"{model_weights_path}\")\n",
        "print(f\"Model weights saved to {folder} with point {epoch+1}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CCDF Error bars\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "import seaborn as sns\n",
        "\n",
        "CCDF_sum = 0\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = ConditionalVAE(input_dim, latent_dim, output_dim, condition_dim)\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# MODIFY THIS LINE FOR MODEL TESTING\n",
        "model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Finetuned_Resnet_VAE_model_at_2025-03-29 16:09:38.411062/checkpoint_5\"\n",
        "\n",
        "if os.path.exists(model_weights_path):\n",
        "    model.load_state_dict(torch.load(model_weights_path))\n",
        "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
        "    \n",
        "for i in range(0, 1):\n",
        "    # Inference\n",
        "    initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "    time_step = 300000\n",
        "    z = torch.zeros([1,latent_dim])\n",
        "    num_ens = 1\n",
        "    pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "    for k in range (0, time_step):\n",
        "\n",
        "        for ens in range (0, num_ens):\n",
        "            if (k == 0):\n",
        "\n",
        "                z = torch.randn_like(z)\n",
        "                print(z.shape, initial_cond.shape)\n",
        "                y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:,ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            else:\n",
        "                select_ens = np.random.randint(0,num_ens,1)\n",
        "                z = torch.randn_like(z)\n",
        "                y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:, ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "    # Denormalize final preds\n",
        "    print(std_psi[:, 63])\n",
        "    pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "    # Denormalize test labels\n",
        "    actual_values = psi[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "    print(actual_values)\n",
        "\n",
        "    # Load the data; shape = (300000, 2, 75)\n",
        "    real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "    predictions = pred_mean.reshape(300000, 1, 75)\n",
        "\n",
        "    if (CCDF):\n",
        "        real_data_1d = real_data[:, 1, 63]  # Now shape is (309700,)\n",
        "        predictions_1d = predictions[:, 0, 63]  # shape (300000,)\n",
        "\n",
        "        # Define bounds (assuming they apply to both datasets)\n",
        "        upper_bound = 53.8 / 2.8935\n",
        "        lower_bound = 1.75 / 2.8935\n",
        "\n",
        "        # Function to calculate transition durations\n",
        "        def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "            times_between_transitions = []\n",
        "            transition_start = None\n",
        "            above_upper = False\n",
        "            below_lower = False\n",
        "\n",
        "            for i in range(1, len(y_values)):\n",
        "                if y_values[i] < lower_bound:  \n",
        "                    below_lower = True\n",
        "                    above_upper = False\n",
        "                elif y_values[i] > upper_bound:  \n",
        "                    if below_lower and transition_start is not None:\n",
        "                        times_between_transitions.append(i - transition_start)\n",
        "                        transition_start = None  \n",
        "                    above_upper = True\n",
        "                    below_lower = False\n",
        "\n",
        "                if below_lower and transition_start is None:\n",
        "                    transition_start = i\n",
        "\n",
        "            return times_between_transitions\n",
        "\n",
        "        # Compute transition durations for real data\n",
        "        real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "\n",
        "        # Compute transition durations for predictions data\n",
        "        pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "\n",
        "        # Plot setup\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        def bootstrap_ci(data, num_bootstraps=1000, confidence_level=0.95):\n",
        "            sample_size = len(data)\n",
        "            bootstrap_means = np.zeros(num_bootstraps)\n",
        "            \n",
        "            for i in range(num_bootstraps):\n",
        "                bootstrap_sample = np.random.choice(data, size=sample_size, replace=True)\n",
        "                bootstrap_means[i] = np.mean(bootstrap_sample)\n",
        "            \n",
        "            ci_lower = np.percentile(bootstrap_means, (1 - confidence_level) / 2 * 100)\n",
        "            ci_upper = np.percentile(bootstrap_means, (1 + confidence_level) / 2 * 100)\n",
        "            \n",
        "            return np.mean(data), ci_lower, ci_upper\n",
        "\n",
        "        # === REAL DATA CCDF AND FIT ===\n",
        "        if len(real_durations) == 0:\n",
        "            print(\"No transitions detected in real data with current bounds!\")\n",
        "        else:\n",
        "            real_data_sorted = np.sort(real_durations)\n",
        "            ccdf_real = 1 - np.arange(1, len(real_data_sorted) + 1) / len(real_data_sorted)\n",
        "\n",
        "            valid_indices_real = ccdf_real > 0\n",
        "            x_fit_real = real_data_sorted[valid_indices_real]\n",
        "            y_fit_real = np.log(ccdf_real[valid_indices_real])\n",
        "\n",
        "            slope_real, intercept_real, *_ = linregress(x_fit_real, y_fit_real)\n",
        "\n",
        "            x_line_real = np.linspace(min(x_fit_real), max(x_fit_real), 40)\n",
        "            y_line_real = np.exp(slope_real * x_line_real + intercept_real)\n",
        "\n",
        "            # Create a grid of x values (time steps / durations)\n",
        "\n",
        "            bootstrap_mean = []\n",
        "            ci_lower_vals = []\n",
        "            ci_upper_vals = []\n",
        "\n",
        "            for x in x_line_real:\n",
        "                valid_indices = (real_durations > x).astype(float)\n",
        "                mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
        "                bootstrap_mean.append(mean_val)\n",
        "                ci_lower_vals.append(lower)\n",
        "                ci_upper_vals.append(upper)\n",
        "\n",
        "            bootstrap_mean = np.array(bootstrap_mean)\n",
        "            ci_lower_vals = np.array(ci_lower_vals)\n",
        "            ci_upper_vals = np.array(ci_upper_vals)\n",
        "\n",
        "            # Calculate error bars (difference from the bootstrap mean)\n",
        "            error_lower = bootstrap_mean - ci_lower_vals\n",
        "            error_upper = ci_upper_vals - bootstrap_mean\n",
        "\n",
        "            plt.step(real_data_sorted, ccdf_real, where='post', label='Real Data CCDF', linewidth=2, linestyle='--')\n",
        "            plt.errorbar(x_line_real, bootstrap_mean, yerr=[error_lower, error_upper],\n",
        "                    fmt='o', color='blue', capsize=3, ecolor='blue', label='Real Bootstrap 95% CI')\n",
        "            plt.plot(x_line_real, y_line_real, 'b-', label=f'Real Exp Fit (slope={slope_real:.4f})', linewidth=2)\n",
        "\n",
        "        # === PREDICTIONS CCDF AND FIT ===\n",
        "        if len(pred_durations) == 0:\n",
        "            print(\"No transitions detected in predictions with current bounds!\")\n",
        "        else:\n",
        "            pred_data_sorted = np.sort(pred_durations)\n",
        "            ccdf_pred = 1 - np.arange(1, len(pred_data_sorted) + 1) / len(pred_data_sorted)\n",
        "\n",
        "            valid_indices_pred = ccdf_pred > 0\n",
        "            x_fit_pred = pred_data_sorted[valid_indices_pred]\n",
        "            y_fit_pred = np.log(ccdf_pred[valid_indices_pred])\n",
        "\n",
        "            slope_pred, intercept_pred, *_ = linregress(x_fit_pred, y_fit_pred)\n",
        "\n",
        "            x_line_pred = np.linspace(min(x_fit_pred), max(x_fit_pred), 40)\n",
        "            y_line_pred = np.exp(slope_pred * x_line_pred + intercept_pred)\n",
        "\n",
        "            # Create a grid of x values (time steps / durations)\n",
        "\n",
        "            bootstrap_mean = []\n",
        "            ci_lower_vals = []\n",
        "            ci_upper_vals = []\n",
        "\n",
        "            for x in x_line_pred:\n",
        "                valid_indices = (pred_durations > x).astype(float)\n",
        "                mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
        "                bootstrap_mean.append(mean_val)\n",
        "                ci_lower_vals.append(lower)\n",
        "                ci_upper_vals.append(upper)\n",
        "\n",
        "            bootstrap_mean = np.array(bootstrap_mean)\n",
        "            ci_lower_vals = np.array(ci_lower_vals)\n",
        "            ci_upper_vals = np.array(ci_upper_vals)\n",
        "\n",
        "            # Calculate error bars (difference from the bootstrap mean)\n",
        "            error_lower = bootstrap_mean - ci_lower_vals\n",
        "            error_upper = ci_upper_vals - bootstrap_mean\n",
        "\n",
        "            plt.step(pred_data_sorted, ccdf_pred, where='post', label='Predictions CCDF', linewidth=2, linestyle='-.', color='red')\n",
        "            plt.errorbar(x_line_pred, bootstrap_mean, yerr=[error_lower, error_upper],\n",
        "                    fmt='o', color='red', capsize=3, ecolor='red', label='Pred Bootstrap 95% CI')\n",
        "            plt.plot(x_line_pred, y_line_pred, 'r-', label=f'Pred Exp Fit (slope={slope_pred:.4f})', linewidth=2)\n",
        "\n",
        "            CCDF_sum += slope_pred\n",
        "\n",
        "        # Plot labels and formatting\n",
        "        plt.xlabel('Time Duration (Steps)')\n",
        "        plt.ylabel('CCDF')\n",
        "        plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "        plt.yscale(\"log\")  # y-axis log scale\n",
        "        plt.xscale(\"linear\")  # x-axis linear scale\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(folder, \"CCDF\")\n",
        "        plt.savefig(save_path)\n",
        "        plt.show()\n",
        "\n",
        "CCDF_avg = CCDF_sum/10\n",
        "print(CCDF_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EXPERIMENTAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from scipy.stats import linregress\n",
        "\n",
        "class ClimateModelLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ClimateModelLoss, self).__init__()\n",
        "    \n",
        "    def forward(self, predictions, real_data):\n",
        "        \n",
        "        # Select the specific column for analysis (column 63 in original code)\n",
        "        # and denormalize data\n",
        "        pred_denorm = predictions.detach().cpu().numpy() * std_psi[:, 63] + mean_psi[:, 63]\n",
        "        pred_1d = pred_denorm[:, 63]\n",
        "        \n",
        "        # Compute real data transition durations (from loaded reference data)\n",
        "        real_data_1d = real_data[:, 63]\n",
        "        \n",
        "        # Total Variation Distance\n",
        "        pred_hist, _ = np.histogram(pred_1d, bins=10, density=True)\n",
        "        real_hist, _ = np.histogram(real_data_1d.detach().cpu().numpy(), bins=10, density=True)\n",
        "        tvd = np.sum(np.abs(pred_hist - real_hist)) / 2\n",
        "        \n",
        "        # Combine losses with weights\n",
        "        total_loss = tvd\n",
        "        \n",
        "        return torch.tensor(total_loss, dtype=torch.float32, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = ConditionalVAE(input_dim, latent_dim, output_dim, condition_dim)\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "folder = f\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Finetuned_Resnet_VAE_model_at_{datetime.datetime.now()}\"\n",
        "os.makedirs(folder)\n",
        "\n",
        "# MODIFY THIS LINE FOR MODEL TESTING\n",
        "model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_at_2025-03-25 16:07:01.635719/checkpoint_4_promising\"\n",
        "\n",
        "if os.path.exists(model_weights_path):\n",
        "    model.load_state_dict(torch.load(model_weights_path))\n",
        "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
        "\n",
        "num_epochs = 50\n",
        "climate_loss_fn = ClimateModelLoss()\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in range (0, trainN, batch_size):\n",
        "\n",
        "        input_batch = psi_train_input[batch:batch + batch_size,:]\n",
        "        label_batch = psi_train_label[batch:batch + batch_size,:]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output, mu, logvar = model(label_batch.float().cuda(), input_batch.float().cuda())\n",
        "\n",
        "        loss = climate_loss_fn(output, label_batch.float().cuda())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'''Epoch {epoch+1}, \n",
        "          TVD Loss: {loss}''')\n",
        "\n",
        "    # Validation Loss\n",
        "    for batch in range (0, valN, batch_size):\n",
        "\n",
        "        input_batch = psi_val_input[batch:batch + batch_size,:]\n",
        "        label_batch = psi_val_label[batch:batch + batch_size,:]\n",
        "        \n",
        "        output, mu, logvar = model(label_batch.float().cuda(), input_batch.float().cuda())\n",
        "        val_loss = climate_loss_fn(output, label_batch.float().cuda())\n",
        "\n",
        "    print(f'''\n",
        "          Validation TVD Loss: {val_loss}''')\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{folder}/checkpoint_{epoch+1}\")\n",
        "    print(f\"Model weights saved to {folder} with point {epoch+1}.\")\n",
        "    \n",
        "    # Inference\n",
        "\n",
        "    initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "    time_step = 30000\n",
        "    z = torch.zeros([1,latent_dim])\n",
        "    num_ens = 1\n",
        "    pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "\n",
        "    for k in range (0, time_step):\n",
        "\n",
        "        for ens in range (0, num_ens):\n",
        "            if (k ==0):\n",
        "\n",
        "                z = torch.randn_like(z)\n",
        "                print(z.shape, initial_cond.shape)\n",
        "                y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:,ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            else:\n",
        "                select_ens = np.random.randint(0,num_ens,1)\n",
        "                z = torch.randn_like(z)\n",
        "                y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:, ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "    # Denormalize final preds\n",
        "    print(std_psi[:, 63])\n",
        "    pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "    # Denormalize test labels\n",
        "    actual_values = psi_train_label[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "    print(actual_values)\n",
        "\n",
        "    plt.plot(pred_mean[0:30000,63],'r')\n",
        "    plt.plot(actual_values[0:30000],'b')\n",
        "    plt.title(f\"Predictions vs Actual | Batch size of {batch_size}\")\n",
        "    plt.savefig(f'{folder}/prediction_epoch_{epoch+1}.png')\n",
        "    plt.show()\n",
        "    plt.cla()\n",
        "\n",
        "torch.save(model.state_dict(), f\"{model_weights_path}\")\n",
        "print(f\"Model weights saved to {folder} with point {epoch+1}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CCDF Error bars\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "import seaborn as sns\n",
        "\n",
        "CCDF_sum = 0\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "num_ccdfs = 10\n",
        "\n",
        "for i in range(0, num_ccdfs):\n",
        "    # Inference\n",
        "    initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "    time_step = 300000\n",
        "    z = torch.zeros([1,latent_dim])\n",
        "    num_ens = 1\n",
        "    pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "    for k in range (0, time_step):\n",
        "\n",
        "        for ens in range (0, num_ens):\n",
        "            if (k ==0):\n",
        "\n",
        "                z = torch.randn_like(z)\n",
        "                print(z.shape, initial_cond.shape)\n",
        "                y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:,ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            else:\n",
        "                select_ens = np.random.randint(0,num_ens,1)\n",
        "                z = torch.randn_like(z)\n",
        "                y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:, ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "    # Denormalize final preds\n",
        "    print(std_psi[:, 63])\n",
        "    pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "    # Denormalize test labels\n",
        "    actual_values = psi[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "    print(actual_values)\n",
        "\n",
        "    # Load the data; shape = (300000, 2, 75)\n",
        "    real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "    predictions = pred_mean.reshape(300000, 1, 75)\n",
        "\n",
        "    if (CCDF):\n",
        "        real_data_1d = real_data[:, 1, 63]  # Now shape is (309700,)\n",
        "        predictions_1d = predictions[:, 0, 63]  # shape (300000,)\n",
        "\n",
        "        # Define bounds (assuming they apply to both datasets)\n",
        "        upper_bound = 53.8 / 2.8935\n",
        "        lower_bound = 1.75 / 2.8935\n",
        "\n",
        "        # Function to calculate transition durations\n",
        "        def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "            times_between_transitions = []\n",
        "            transition_start = None\n",
        "            above_upper = False\n",
        "            below_lower = False\n",
        "\n",
        "            for i in range(1, len(y_values)):\n",
        "                if y_values[i] < lower_bound:  \n",
        "                    below_lower = True\n",
        "                    above_upper = False\n",
        "                elif y_values[i] > upper_bound:  \n",
        "                    if below_lower and transition_start is not None:\n",
        "                        times_between_transitions.append(i - transition_start)\n",
        "                        transition_start = None  \n",
        "                    above_upper = True\n",
        "                    below_lower = False\n",
        "\n",
        "                if below_lower and transition_start is None:\n",
        "                    transition_start = i\n",
        "\n",
        "            return times_between_transitions\n",
        "\n",
        "        # Compute transition durations for real data\n",
        "        real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "\n",
        "        # Compute transition durations for predictions data\n",
        "        pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "\n",
        "        # Plot setup\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        def bootstrap_ci(data, num_bootstraps=1000, confidence_level=0.95):\n",
        "            sample_size = len(data)\n",
        "            bootstrap_means = np.zeros(num_bootstraps)\n",
        "            \n",
        "            for i in range(num_bootstraps):\n",
        "                bootstrap_sample = np.random.choice(data, size=sample_size, replace=True)\n",
        "                bootstrap_means[i] = np.mean(bootstrap_sample)\n",
        "            \n",
        "            ci_lower = np.percentile(bootstrap_means, (1 - confidence_level) / 2 * 100)\n",
        "            ci_upper = np.percentile(bootstrap_means, (1 + confidence_level) / 2 * 100)\n",
        "            \n",
        "            return np.mean(data), ci_lower, ci_upper\n",
        "\n",
        "        # === REAL DATA CCDF AND FIT ===\n",
        "        if len(real_durations) == 0:\n",
        "            print(\"No transitions detected in real data with current bounds!\")\n",
        "        else:\n",
        "            real_data_sorted = np.sort(real_durations)\n",
        "            ccdf_real = 1 - np.arange(1, len(real_data_sorted) + 1) / len(real_data_sorted)\n",
        "\n",
        "            valid_indices_real = ccdf_real > 0\n",
        "            x_fit_real = real_data_sorted[valid_indices_real]\n",
        "            y_fit_real = np.log(ccdf_real[valid_indices_real])\n",
        "\n",
        "            slope_real, intercept_real, *_ = linregress(x_fit_real, y_fit_real)\n",
        "\n",
        "            x_line_real = np.linspace(min(x_fit_real), max(x_fit_real), 40)\n",
        "            y_line_real = np.exp(slope_real * x_line_real + intercept_real)\n",
        "\n",
        "            # Create a grid of x values (time steps / durations)\n",
        "\n",
        "            bootstrap_mean = []\n",
        "            ci_lower_vals = []\n",
        "            ci_upper_vals = []\n",
        "\n",
        "            for x in x_line_real:\n",
        "                valid_indices = (real_durations > x).astype(float)\n",
        "                mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
        "                bootstrap_mean.append(mean_val)\n",
        "                ci_lower_vals.append(lower)\n",
        "                ci_upper_vals.append(upper)\n",
        "\n",
        "            bootstrap_mean = np.array(bootstrap_mean)\n",
        "            ci_lower_vals = np.array(ci_lower_vals)\n",
        "            ci_upper_vals = np.array(ci_upper_vals)\n",
        "\n",
        "            # Calculate error bars (difference from the bootstrap mean)\n",
        "            error_lower = bootstrap_mean - ci_lower_vals\n",
        "            error_upper = ci_upper_vals - bootstrap_mean\n",
        "\n",
        "            plt.step(real_data_sorted, ccdf_real, where='post', label='Real Data CCDF', linewidth=2, linestyle='--')\n",
        "            plt.errorbar(x_line_real, bootstrap_mean, yerr=[error_lower, error_upper],\n",
        "                    fmt='o', color='blue', capsize=3, ecolor='blue', label='Real Bootstrap 95% CI')\n",
        "            plt.plot(x_line_real, y_line_real, 'b-', label=f'Real Exp Fit (slope={slope_real:.4f})', linewidth=2)\n",
        "\n",
        "        # === PREDICTIONS CCDF AND FIT ===\n",
        "        if len(pred_durations) == 0:\n",
        "            print(\"No transitions detected in predictions with current bounds!\")\n",
        "        else:\n",
        "            pred_data_sorted = np.sort(pred_durations)\n",
        "            ccdf_pred = 1 - np.arange(1, len(pred_data_sorted) + 1) / len(pred_data_sorted)\n",
        "\n",
        "            valid_indices_pred = ccdf_pred > 0\n",
        "            x_fit_pred = pred_data_sorted[valid_indices_pred]\n",
        "            y_fit_pred = np.log(ccdf_pred[valid_indices_pred])\n",
        "\n",
        "            slope_pred, intercept_pred, *_ = linregress(x_fit_pred, y_fit_pred)\n",
        "\n",
        "            x_line_pred = np.linspace(min(x_fit_pred), max(x_fit_pred), 40)\n",
        "            y_line_pred = np.exp(slope_pred * x_line_pred + intercept_pred)\n",
        "\n",
        "            # Create a grid of x values (time steps / durations)\n",
        "\n",
        "            bootstrap_mean = []\n",
        "            ci_lower_vals = []\n",
        "            ci_upper_vals = []\n",
        "\n",
        "            for x in x_line_pred:\n",
        "                valid_indices = (pred_durations > x).astype(float)\n",
        "                mean_val, lower, upper = bootstrap_ci(valid_indices)\n",
        "                bootstrap_mean.append(mean_val)\n",
        "                ci_lower_vals.append(lower)\n",
        "                ci_upper_vals.append(upper)\n",
        "\n",
        "            bootstrap_mean = np.array(bootstrap_mean)\n",
        "            ci_lower_vals = np.array(ci_lower_vals)\n",
        "            ci_upper_vals = np.array(ci_upper_vals)\n",
        "\n",
        "            # Calculate error bars (difference from the bootstrap mean)\n",
        "            error_lower = bootstrap_mean - ci_lower_vals\n",
        "            error_upper = ci_upper_vals - bootstrap_mean\n",
        "\n",
        "            plt.step(pred_data_sorted, ccdf_pred, where='post', label='Predictions CCDF', linewidth=2, linestyle='-.', color='red')\n",
        "            plt.errorbar(x_line_pred, bootstrap_mean, yerr=[error_lower, error_upper],\n",
        "                    fmt='o', color='red', capsize=3, ecolor='red', label='Pred Bootstrap 95% CI')\n",
        "            plt.plot(x_line_pred, y_line_pred, 'r-', label=f'Pred Exp Fit (slope={slope_pred:.4f})', linewidth=2)\n",
        "\n",
        "            CCDF_sum += slope_pred\n",
        "\n",
        "        # Plot labels and formatting\n",
        "        plt.xlabel('Time Duration (Steps)')\n",
        "        plt.ylabel('CCDF')\n",
        "        plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "        plt.yscale(\"log\")  # y-axis log scale\n",
        "        plt.xscale(\"linear\")  # x-axis linear scale\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(folder, \"CCDF\")\n",
        "        plt.savefig(save_path)\n",
        "        plt.show()\n",
        "\n",
        "        print(1/np.mean(real_data_sorted))\n",
        "\n",
        "CCDF_avg = CCDF_sum/num_ccdfs\n",
        "print(CCDF_avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tests package\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "import seaborn as sns\n",
        "import random\n",
        "if (plot_data):\n",
        "    #note that the value 300000 will have to change depending on the real and predictions data length\n",
        "    u_profile_real = real_data[:300000, 1, level]  # Match time length with predictions\n",
        "    u_profile_pred = predictions[:, 0, level]\n",
        "    time_steps = np.arange(len(u_profile_pred))\n",
        "\n",
        "    # === Plot ===\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    plt.plot(time_steps, u_profile_real, label='Real Data', alpha=0.7)\n",
        "    plt.plot(time_steps, u_profile_pred, label='Predictions', linestyle='--')\n",
        "\n",
        "\n",
        "    # Labels, legend, and formatting\n",
        "    plt.xlabel('Time step')\n",
        "    plt.ylabel('U (m/s)')\n",
        "    plt.title(f'Time Series of U at Vertical Level {level}')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(folder, \"timeseries\")\n",
        "    save_path = os.path.join(save_path, \"real_prediction_plot\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "\n",
        "if (CCDF):\n",
        "    real_data_1d = real_data[:, 1, 61]  # Now shape is (309700,)\n",
        "    predictions_1d = predictions[:, 0, 61]  # shape (300000,)\n",
        "\n",
        "    # Define bounds (assuming they apply to both datasets)\n",
        "    upper_bound = 53.8 / 2.8935\n",
        "    lower_bound = 1.75 / 2.8935\n",
        "\n",
        "    # Function to calculate transition durations\n",
        "    def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "        times_between_transitions = []\n",
        "        transition_start = None\n",
        "        above_upper = False\n",
        "        below_lower = False\n",
        "\n",
        "        for i in range(1, len(y_values)):\n",
        "            if y_values[i] < lower_bound:  \n",
        "                below_lower = True\n",
        "                above_upper = False\n",
        "            elif y_values[i] > upper_bound:  \n",
        "                if below_lower and transition_start is not None:\n",
        "                    times_between_transitions.append(i - transition_start)\n",
        "                    transition_start = None  \n",
        "                above_upper = True\n",
        "                below_lower = False\n",
        "\n",
        "            if below_lower and transition_start is None:\n",
        "                transition_start = i\n",
        "\n",
        "        return times_between_transitions\n",
        "\n",
        "    # Compute transition durations for real data\n",
        "    real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "\n",
        "    # Compute transition durations for predictions data\n",
        "    pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "\n",
        "    # Plot setup\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # === REAL DATA CCDF AND FIT ===\n",
        "    if len(real_durations) == 0:\n",
        "        print(\"No transitions detected in real data with current bounds!\")\n",
        "    else:\n",
        "        real_data_sorted = np.sort(real_durations)\n",
        "        ccdf_real = 1 - np.arange(1, len(real_data_sorted) + 1) / len(real_data_sorted)\n",
        "\n",
        "        valid_indices_real = ccdf_real > 0\n",
        "        x_fit_real = real_data_sorted[valid_indices_real]\n",
        "        y_fit_real = np.log(ccdf_real[valid_indices_real])\n",
        "\n",
        "        slope_real, intercept_real, *_ = linregress(x_fit_real, y_fit_real)\n",
        "\n",
        "        x_line_real = np.linspace(min(x_fit_real), max(x_fit_real), 100)\n",
        "        y_line_real = np.exp(slope_real * x_line_real + intercept_real)\n",
        "\n",
        "        plt.step(real_data_sorted, ccdf_real, where='post', label='Real Data CCDF', linewidth=2, linestyle='--')\n",
        "        plt.plot(x_line_real, y_line_real, 'b-', label=f'Real Exp Fit (slope={slope_real:.4f})', linewidth=2)\n",
        "\n",
        "    # === PREDICTIONS CCDF AND FIT ===\n",
        "    if len(pred_durations) == 0:\n",
        "        print(\"No transitions detected in predictions with current bounds!\")\n",
        "    else:\n",
        "        pred_data_sorted = np.sort(pred_durations)\n",
        "        ccdf_pred = 1 - np.arange(1, len(pred_data_sorted) + 1) / len(pred_data_sorted)\n",
        "\n",
        "        valid_indices_pred = ccdf_pred > 0\n",
        "        x_fit_pred = pred_data_sorted[valid_indices_pred]\n",
        "        y_fit_pred = np.log(ccdf_pred[valid_indices_pred])\n",
        "\n",
        "        slope_pred, intercept_pred, *_ = linregress(x_fit_pred, y_fit_pred)\n",
        "\n",
        "        x_line_pred = np.linspace(min(x_fit_pred), max(x_fit_pred), 100)\n",
        "        y_line_pred = np.exp(slope_pred * x_line_pred + intercept_pred)\n",
        "\n",
        "        plt.step(pred_data_sorted, ccdf_pred, where='post', label='Predictions CCDF', linewidth=2, linestyle='-.', color='red')\n",
        "        plt.plot(x_line_pred, y_line_pred, 'r-', label=f'Pred Exp Fit (slope={slope_pred:.4f})', linewidth=2)\n",
        "\n",
        "    # Plot labels and formatting\n",
        "    plt.xlabel('Time Duration (Steps)')\n",
        "    plt.ylabel('CCDF')\n",
        "    plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "    plt.yscale(\"log\")  # y-axis log scale\n",
        "    plt.xscale(\"linear\")  # x-axis linear scale\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(folder, \"CCDF\")\n",
        "    save_path = os.path.join(save_path, \"CCDF_plot\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "if (Bi_modal_distribution):\n",
        "    zonal_wind_data_real = real_data[:, 1, 63]  # variable index 1 (e.g., zonal wind), level 60\n",
        "    zonal_wind_data_predictions = predictions[:, 0, 63]  # variable index 0 (predictions), level 60\n",
        "\n",
        "    print(f\"Shape of zonal_wind_data_real: {zonal_wind_data_real.shape}\")\n",
        "    print(f\"Shape of zonal_wind_data_predictions: {zonal_wind_data_predictions.shape}\")\n",
        "\n",
        "    # Plot the bimodal histogram\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Create histograms (overlaid)\n",
        "    sns.histplot(zonal_wind_data_real, bins=50, kde=True, color='black', alpha=0.6, element='step', label='Real Data')\n",
        "    sns.histplot(zonal_wind_data_predictions, bins=50, kde=True, color='red', alpha=0.6, element='step', label='Predictions')\n",
        "\n",
        "    # Customize plot labels and title\n",
        "    plt.title('Distribution of Zonal Winds For Real Data and Predictions', fontsize=16)\n",
        "    plt.xlabel('Zonal Wind (m/s)', fontsize=14)\n",
        "    plt.ylabel('Frequency', fontsize=14)\n",
        "\n",
        "    # Add vertical lines at means\n",
        "    plt.axvline(np.mean(zonal_wind_data_real), color='black', linestyle='--', label=f'Real Mean: {np.mean(zonal_wind_data_real):.2f}')\n",
        "    plt.axvline(np.mean(zonal_wind_data_predictions), color='red', linestyle='--', label=f'Pred Mean: {np.mean(zonal_wind_data_predictions):.2f}')\n",
        "\n",
        "    # Final plot settings\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(folder, \"bi_modal_distribution\")\n",
        "    save_path = os.path.join(save_path, \"bi_modal_distribution_plot\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "if (single_step_profiles):\n",
        "    # Ensure save directory exists\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    # === Load model weights ===\n",
        "    model.load_state_dict(torch.load(MODEL_PATH))\n",
        "    model.eval()\n",
        "\n",
        "    # === Randomly sample time points from real data ===\n",
        "    time_indices = random.sample(range(0, real_data.shape[0] - 2), NUM_SAMPLES)\n",
        "    print(f\"Randomly sampled time steps: {time_indices}\")\n",
        "\n",
        "    # === Time series visualization ===\n",
        "    real_data_timeseries = real_data[:, 1, LEVEL]\n",
        "    time_steps_all = np.arange(len(real_data_timeseries))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(time_steps_all, real_data_timeseries, label=\"Real Data at Level 61\", color='blue')\n",
        "\n",
        "    # Mark sample points\n",
        "    for idx_num, idx in enumerate(time_indices):\n",
        "        plt.axvline(x=idx, color='green', linestyle='--', linewidth=2)\n",
        "    if len(time_indices) > 0:\n",
        "        plt.axvline(x=time_indices[0], color='green', linestyle='--', linewidth=2, label='Sampled Points')\n",
        "\n",
        "    plt.title(\"Real Data Time Series with Sampled Points Highlighted\")\n",
        "    plt.xlabel(\"Time Step\")\n",
        "    plt.ylabel(\"U (m/s) at Level 61\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_path = os.path.join(SAVE_DIR, \"real_data_timeseries_with_samples.png\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    # === Iterate over each sampled time point ===\n",
        "    for i, time_step in enumerate(time_indices):\n",
        "        next_time_step = time_step + 1\n",
        "\n",
        "        # === Real data: current and next ===\n",
        "        real_current = real_data[time_step, 1, :]       \n",
        "        real_next = real_data[next_time_step, 1, :]      \n",
        "\n",
        "        # === Normalize real_current and make prediction for next step ===\n",
        "        initial_condition_normalized = (real_current.reshape(1, 75, 1) - mean_psi.reshape(1, -1, 1)) / std_psi.reshape(1, -1, 1)\n",
        "        current_input = torch.tensor(initial_condition_normalized, dtype=torch.float32).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn_like(z)\n",
        "            print(z.shape, initial_cond.shape)\n",
        "            y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "\n",
        "        # === Denormalize predicted next ===\n",
        "        pred_next_denorm = y.squeeze() * std_psi.squeeze() + mean_psi.squeeze()\n",
        "\n",
        "        # === Extract U, Re(Psi), Im(Psi) components ===\n",
        "        # U profiles\n",
        "        U_current_real = real_current[51:74]\n",
        "        U_next_real = real_next[51:74]\n",
        "        U_next_pred = pred_next_denorm[51:74]\n",
        "\n",
        "        # Re(Psi) profiles\n",
        "        RePsi_current_real = real_current[0:24]\n",
        "        RePsi_next_real = real_next[0:24]\n",
        "        RePsi_next_pred = pred_next_denorm[0:24]\n",
        "\n",
        "        # Im(Psi) profiles\n",
        "        ImPsi_current_real = real_current[25:50]\n",
        "        ImPsi_next_real = real_next[25:50]\n",
        "        ImPsi_next_pred = pred_next_denorm[25:50]\n",
        "\n",
        "        # === Differences ===\n",
        "        U_diff_real = U_next_real - U_current_real\n",
        "        U_diff_pred = U_next_pred - U_current_real\n",
        "\n",
        "        RePsi_diff_real = RePsi_next_real - RePsi_current_real\n",
        "        RePsi_diff_pred = RePsi_next_pred - RePsi_current_real\n",
        "\n",
        "        ImPsi_diff_real = ImPsi_next_real - ImPsi_current_real\n",
        "        ImPsi_diff_pred = ImPsi_next_pred - ImPsi_current_real\n",
        "\n",
        "        # === Create a single figure with 3 rows (U, Re(Psi), Im(Psi)) ===\n",
        "        fig, axes = plt.subplots(3, 2, figsize=(16, 18))  # 3 rows, 2 columns (Profile and Difference)\n",
        "\n",
        "        z_levels_U = np.linspace(0, 70, 23)\n",
        "        z_levels_RePsi = np.linspace(0, 70, 24)\n",
        "        z_levels_ImPsi = np.linspace(0, 70, 25)\n",
        "\n",
        "        # --- U ---\n",
        "        axes[0, 0].plot(U_current_real, z_levels_U, 'x-', label=\"Real Current\")\n",
        "        axes[0, 0].plot(U_next_real, z_levels_U, 'd-', label=\"Real Next\")\n",
        "        axes[0, 0].plot(U_next_pred, z_levels_U, 's--', label=\"Predicted Next\")\n",
        "        axes[0, 0].set_title(f\"U Profiles @ Step {time_step}\")\n",
        "        axes[0, 0].set_xlabel(\"U (m/s)\")\n",
        "        axes[0, 0].set_ylabel(\"Vertical Levels (km)\")\n",
        "        axes[0, 0].legend()\n",
        "\n",
        "        axes[0, 1].plot(U_diff_real, z_levels_U, 'xb', label=\"Real Δ (Next - Current)\")\n",
        "        axes[0, 1].plot(U_diff_pred, z_levels_U, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
        "        axes[0, 1].set_title(\"U Difference (Next - Current)\")\n",
        "        axes[0, 1].set_xlabel(\"ΔU (m/s)\")\n",
        "        axes[0, 1].legend()\n",
        "\n",
        "        # --- Re(Psi) ---\n",
        "        axes[1, 0].plot(RePsi_current_real, z_levels_RePsi, 'x-', label=\"Real Current\")\n",
        "        axes[1, 0].plot(RePsi_next_real, z_levels_RePsi, 'd-', label=\"Real Next\")\n",
        "        axes[1, 0].plot(RePsi_next_pred, z_levels_RePsi, 's--', label=\"Predicted Next\")\n",
        "        axes[1, 0].set_title(f\"Re(Psi) Profiles @ Step {time_step}\")\n",
        "        axes[1, 0].set_xlabel(\"Re(Psi)\")\n",
        "        axes[1, 0].set_ylabel(\"Vertical Levels (km)\")\n",
        "        axes[1, 0].legend()\n",
        "\n",
        "        axes[1, 1].plot(RePsi_diff_real, z_levels_RePsi, 'xb', label=\"Real Δ (Next - Current)\")\n",
        "        axes[1, 1].plot(RePsi_diff_pred, z_levels_RePsi, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
        "        axes[1, 1].set_title(\"Re(Psi) Difference (Next - Current)\")\n",
        "        axes[1, 1].set_xlabel(\"ΔRe(Psi)\")\n",
        "        axes[1, 1].legend()\n",
        "\n",
        "        # --- Im(Psi) ---\n",
        "        axes[2, 0].plot(ImPsi_current_real, z_levels_ImPsi, 'x-', label=\"Real Current\")\n",
        "        axes[2, 0].plot(ImPsi_next_real, z_levels_ImPsi, 'd-', label=\"Real Next\")\n",
        "        axes[2, 0].plot(ImPsi_next_pred, z_levels_ImPsi, 's--', label=\"Predicted Next\")\n",
        "        axes[2, 0].set_title(f\"Im(Psi) Profiles @ Step {time_step}\")\n",
        "        axes[2, 0].set_xlabel(\"Im(Psi)\")\n",
        "        axes[2, 0].set_ylabel(\"Vertical Levels (km)\")\n",
        "        axes[2, 0].legend()\n",
        "\n",
        "        axes[2, 1].plot(ImPsi_diff_real, z_levels_ImPsi, 'xb', label=\"Real Δ (Next - Current)\")\n",
        "        axes[2, 1].plot(ImPsi_diff_pred, z_levels_ImPsi, 'o--r', label=\"Pred Δ (Next - Current)\")\n",
        "        axes[2, 1].set_title(\"Im(Psi) Difference (Next - Current)\")\n",
        "        axes[2, 1].set_xlabel(\"ΔIm(Psi)\")\n",
        "        axes[2, 1].legend()\n",
        "\n",
        "        # === Finalize and Save ===\n",
        "        plt.suptitle(f\"Single Step Profile Comparisons at Time Step {time_step}\", fontsize=18)\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "\n",
        "        save_path = os.path.join(SAVE_DIR, f\"Profile_Summary_point_{time_step}.png\")\n",
        "        plt.savefig(save_path)\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Combined plot saved for sampled point {time_step}\")\n",
        "\n",
        "    # Final debug\n",
        "    print(\"Finished processing all sampled points.\")\n",
        "        # Debugging prints\n",
        "    print(predictions.shape) \n",
        "    print(real_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
