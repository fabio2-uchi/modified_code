{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWi0w8G07_2G",
        "outputId": "d7b6c2e4-6c31-4122-be65-e9bef0352d76"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import numpy as np\n",
        "from scipy.integrate import solve_ivp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vKXlQjvFavj"
      },
      "outputs": [],
      "source": [
        "# Init pack\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "import numpy as np\n",
        "from scipy.integrate import solve_ivp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "psi = np.load('/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy')\n",
        "\n",
        "# Pre-processing\n",
        "\n",
        "lead = 1\n",
        "\n",
        "trainN = 200000\n",
        "valN = 50000\n",
        "index = 63\n",
        "\n",
        "psi = psi[:,1,:]\n",
        "\n",
        "print(psi.shape)\n",
        "mean_psi = np.mean(psi, axis=0, keepdims=True)\n",
        "std_psi = np.std(psi, axis=0, keepdims=True)\n",
        "psi = (psi - mean_psi) / std_psi\n",
        "\n",
        "psi_train_input = torch.tensor(psi[0:trainN,:])\n",
        "psi_train_label =  torch.tensor(psi[lead:trainN+lead,:])\n",
        "\n",
        "\n",
        "# # Make sure input and label lengths match\n",
        "# assert psi_train_input.shape[0] == psi_train_label.shape[0], \"Input and label length mismatch\"\n",
        "\n",
        "# #shuffle and map indices\\\n",
        "# valid_indices = np.arange(0, trainN - lead)\n",
        "# np.random.seed(42)  # Optional for reproducibility\n",
        "# shuffled_indices = np.random.permutation(valid_indices)\n",
        "# psi_train_input = torch.tensor(psi[shuffled_indices, :])\n",
        "# psi_train_label = torch.tensor(psi[shuffled_indices + lead, :])\n",
        "\n",
        "\n",
        "# t = shuffled_indices[0]\n",
        "# print(torch.allclose(psi_train_input[0], torch.tensor(psi[t])))\n",
        "# print(torch.allclose(psi_train_label[0], torch.tensor(psi[t + 1])))\n",
        "\n",
        "psi_val_input = torch.tensor(psi[trainN:trainN+valN,:])\n",
        "psi_val_label =  torch.tensor(psi[trainN+lead:trainN+valN+lead,:])\n",
        "\n",
        "print(psi_train_input.shape)\n",
        "print(psi_train_label.shape)\n",
        "print(psi_val_input.shape)\n",
        "print(psi_val_label.shape)\n",
        "plt.plot(psi_train_input[0:200000,63])\n",
        "plt.plot(psi_val_input[0:50000,63])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the encoder (MLP)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(75, 512)  # Input layer (2 + 2) -> Hidden layer (128)\n",
        "        self.fc2 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc3 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc4 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc5 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc6 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc_mu = nn.Linear(512, latent_dim)  # Hidden layer (128) -> Latent space (2)\n",
        "        self.fc_logvar = nn.Linear(512, latent_dim)  # Hidden layer (128) -> Log variance (2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))  # Activation function for hidden layer\n",
        "        x = torch.relu(self.fc2(x)) + x\n",
        "        x = torch.relu(self.fc3(x)) + x\n",
        "        x = torch.relu(self.fc4(x)) + x\n",
        "        # x = torch.relu(self.fc5(x)) + x\n",
        "        # x = torch.relu(self.fc6(x)) + x\n",
        "        mu = self.fc_mu(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mu, logvar\n",
        "\n",
        "# Define the decoder (MLP)\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, output_dim, condition_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim + condition_dim, 512)  # Input layer (2 + 2) -> Hidden layer (128)\n",
        "        self.fc2 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc3 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc4 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc5 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc6 = nn.Linear(512, 512)  # Hidden layer (128) -> Hidden layer (128)\n",
        "        self.fc_output = nn.Linear(512, output_dim)  # Hidden layer (128) -> Output layer (2)\n",
        "\n",
        "    def forward(self, z, condition):\n",
        "        z = torch.cat((z, condition), dim=1)  # Concatenate latent vector and condition\n",
        "        z = torch.relu(self.fc1(z))  # Activation function for hidden layer\n",
        "        z = torch.relu(self.fc2(z)) + z\n",
        "        z = torch.relu(self.fc3(z)) + z\n",
        "        z = torch.relu(self.fc4(z)) + z\n",
        "        # z = torch.relu(self.fc5(z)) + z\n",
        "        # z = torch.relu(self.fc6(z)) + z\n",
        "        output = self.fc_output(z)\n",
        "        return output\n",
        "\n",
        "# Define the VAE model\n",
        "class ConditionalVAE(nn.Module):\n",
        "    def __init__(self, latent_dim, output_dim, condition_dim):\n",
        "        super(ConditionalVAE, self).__init__()\n",
        "        self.encoder = Encoder(latent_dim)\n",
        "        self.decoder = Decoder(latent_dim, output_dim, condition_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def decode(self, z, condition):\n",
        "        return self.decoder(z, condition)\n",
        "\n",
        "    def forward(self, x, condition):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        output = self.decode(z, condition)\n",
        "        return output, mu, logvar\n",
        "\n",
        "output_dim = 75\n",
        "latent_dim = 1024\n",
        "condition_dim = 75\n",
        "batch_size = 1024\n",
        "num_epochs = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ORIGINAL TRAINING + INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVG1Hn1z-4br"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "import math\n",
        "\n",
        "def normalize_transition_time(slope_value, delta, transition_real):\n",
        "    normalized = 1 - np.exp(-np.abs((slope_value - transition_real)) / delta)\n",
        "    return normalized\n",
        "\n",
        "def total_variation_distance(p, q):\n",
        "    p = np.array(p)\n",
        "    q = np.array(q)\n",
        "    return 0.5 * np.sum(np.abs(p - q))\n",
        "\n",
        "def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "    times_between_transitions = []\n",
        "    transition_start = None\n",
        "    above_upper = False\n",
        "    below_lower = False\n",
        "    for i in range(1, len(y_values)):\n",
        "        if y_values[i] < lower_bound:\n",
        "            below_lower = True\n",
        "            above_upper = False\n",
        "        elif y_values[i] > upper_bound:\n",
        "            if below_lower and transition_start is not None:\n",
        "                times_between_transitions.append(i - transition_start)\n",
        "                transition_start = None\n",
        "            above_upper = True\n",
        "            below_lower = False\n",
        "        if below_lower and transition_start is None:\n",
        "            transition_start = i\n",
        "    return times_between_transitions\n",
        "\n",
        "latent_dims = [1024]\n",
        "latent_dim = 1024\n",
        "kl_coefficients = [10]\n",
        "num_cycles = 5\n",
        "upper_bound = 53.8 / 2.8935\n",
        "lower_bound = 7.41\n",
        "level = 63\n",
        "\n",
        "best_distance = float('inf')\n",
        "tvd_list = []\n",
        "transition_list = []\n",
        "transition_list_unormalized = []\n",
        "\n",
        "real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "real_data_1d = real_data[:, 1, level]\n",
        "real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "real_data_sorted = np.sort(real_durations)\n",
        "transition_real = np.mean(real_data_sorted)\n",
        "actual_hist, bin_edges = np.histogram(real_data[:, 1, level], bins=50, density=True)\n",
        "print(f\"Reference Real Data average_transition_time: {transition_real}\")\n",
        "\n",
        "tvds_by_dim_cycle = {kl: {cycle: [] for cycle in range(num_cycles)} for kl in kl_coefficients}\n",
        "transitions_by_dim_cycle = {kl: {cycle: [] for cycle in range(num_cycles)} for kl in kl_coefficients}\n",
        "transitions_normalized_by_dim_cycle = {kl: {cycle: [] for cycle in range(num_cycles)} for kl in kl_coefficients}\n",
        "exp_by_dim_cycle = {kl: {cycle: [] for cycle in range(num_cycles)} for kl in kl_coefficients}\n",
        "\n",
        "lat_folder = f\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_KL_TEST_at_{datetime.datetime.now()}\"\n",
        "os.makedirs(lat_folder)\n",
        "\n",
        "for kl_coef in kl_coefficients:\n",
        "    print(f\"USING KL COEF OF {kl_coef}\")\n",
        "    best_models = []\n",
        "    best_models_saved = []\n",
        "    for cycle in range(0,num_cycles):\n",
        "        tvd_cycle_list = []\n",
        "        transition_cycle_list = []\n",
        "        transition_cycle_list_unormalized = []\n",
        "        \n",
        "        # Initialize the model, optimizer, and loss function\n",
        "        model = ConditionalVAE(latent_dim, output_dim, condition_dim)\n",
        "        model = model.cuda()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "        num_epochs = 5\n",
        "\n",
        "        folder = f\"{lat_folder}/model_at_{cycle}_with_kl_{kl_coef}\"\n",
        "        os.makedirs(folder)\n",
        "        subfolders = ['timeseries', 'expo_fit', '2D', 'summary']\n",
        "\n",
        "        # Create each subdirectory inside the main folder\n",
        "        for subfolder in subfolders:\n",
        "            path = os.path.join(folder, subfolder)\n",
        "            os.mkdir(path)\n",
        "            print(f\"Created subfolder: {path}\")\n",
        "\n",
        "        # from torchsummary import summary\n",
        "\n",
        "        # summary(model, input_size = [(128, 1, 75), (128, 75)])\n",
        "        # Train the model\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            for batch in range (0, trainN, batch_size):\n",
        "\n",
        "                input_batch = psi_train_input[batch:batch + batch_size,:]\n",
        "                label_batch = psi_train_label[batch:batch + batch_size,:]\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                output, mu, logvar = model(label_batch.float().cuda(), input_batch.float().cuda())\n",
        "\n",
        "                # Reconstruction loss\n",
        "                reconstruction_loss = F.mse_loss(output, label_batch.float().cuda(), reduction=\"sum\")\n",
        "                # KL divergence loss\n",
        "                kl_loss = 0.5 * (mu ** 2 + torch.exp(logvar) - 1 - logvar).sum()\n",
        "                \n",
        "                # Total loss\n",
        "                loss = reconstruction_loss + kl_coef * kl_loss\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            print(f'''Epoch {epoch+1}, \n",
        "                Reconstrunction Loss: {reconstruction_loss},\n",
        "                KL Divergence Loss: {kl_loss}''')\n",
        "\n",
        "            # Validation Loss\n",
        "            for batch in range (0, valN, batch_size):\n",
        "\n",
        "                input_batch = psi_val_input[batch:batch + batch_size,:]\n",
        "                label_batch = psi_val_label[batch:batch + batch_size,:]\n",
        "                \n",
        "                output, mu, logvar = model(label_batch.float().cuda(), input_batch.float().cuda())\n",
        "                reconstruction_loss = F.mse_loss(output, label_batch.float().cuda(), reduction=\"sum\")\n",
        "                kl_loss = 0.5 * (mu ** 2 + torch.exp(logvar) - 1 - logvar).sum()\n",
        "                val_loss = reconstruction_loss + kl_coef * kl_loss # Experiment HIGHER coefficients\n",
        "                # Print both reconstruction_loss and kl_loss\n",
        "\n",
        "            print(f'''\n",
        "                Validation Reconstrunction Loss: {reconstruction_loss},\n",
        "                Validation KL Divergence Loss: {kl_loss}''')\n",
        "            \n",
        "            # Inference\n",
        "\n",
        "            initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "            time_step = 300000\n",
        "            z = torch.zeros([1,latent_dim])\n",
        "            num_ens = 1\n",
        "            pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "            for k in range (0, time_step):\n",
        "\n",
        "                for ens in range (0, num_ens):\n",
        "                    if (k ==0):\n",
        "\n",
        "                        z = torch.randn_like(z)\n",
        "                        print(z.shape, initial_cond.shape)\n",
        "                        y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                        pred[k,:,ens] = y\n",
        "                        y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                        initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "                    else:\n",
        "                        select_ens = np.random.randint(0,num_ens,1)\n",
        "                        z = torch.randn_like(z)\n",
        "                        y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                        pred[k,:, ens] = y\n",
        "                        y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                        initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            # Denormalize final preds\n",
        "            print(std_psi[:, 63])\n",
        "            pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "            # Denormalize test labels\n",
        "            actual_values = psi_train_label[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "            print(actual_values)\n",
        "            \n",
        "            real_data_1d = real_data[:30000, 0, 63]  # Now shape is (309700,)\n",
        "            predictions_1d = pred_mean[:, 63]  # shape (300000,)\n",
        "\n",
        "            plt.figure(figsize=(20,8))\n",
        "            plt.plot(pred_mean[0:30000,63],'r')\n",
        "            plt.plot(real_data[0:30000, 0, 63])\n",
        "            plt.grid(True)\n",
        "            plt.title(f\"Predictions vs Actual | Epoch {epoch}\")\n",
        "            save_path = os.path.join(folder, \"timeseries\")\n",
        "            save_path = os.path.join(save_path, f\"timeseries_plot_{epoch}.png\")\n",
        "            plt.savefig(save_path)\n",
        "            plt.xlabel('Time Step')\n",
        "            plt.ylabel('Zonal Wind Value')\n",
        "            plt.legend(['Predictions', 'Actual'])\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            # Function to calculate transition durations\n",
        "            def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "                times_between_transitions = []\n",
        "                transition_start = None\n",
        "                above_upper = False\n",
        "                below_lower = False\n",
        "\n",
        "                for i in range(1, len(y_values)):\n",
        "                    if y_values[i] < lower_bound:  \n",
        "                        below_lower = True\n",
        "                        above_upper = False\n",
        "                    elif y_values[i] > upper_bound:  \n",
        "                        if below_lower and transition_start is not None:\n",
        "                            times_between_transitions.append(i - transition_start)\n",
        "                            transition_start = None  \n",
        "                        above_upper = True\n",
        "                        below_lower = False\n",
        "\n",
        "                    if below_lower and transition_start is None:\n",
        "                        transition_start = i\n",
        "\n",
        "                return times_between_transitions\n",
        "            \n",
        "            predictions_1d = pred_mean[:, level, 0]\n",
        "            pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "            print(pred_durations)\n",
        "            pred_hist, _ = np.histogram(predictions_1d, bins=bin_edges, density=True)\n",
        "\n",
        "            # === PREDICTIONS CCDF AND FIT ===\n",
        "            exponential_fit_pred = 0\n",
        "\n",
        "            # if len(pred_durations) > 0:\n",
        "            transition_pred = np.mean(pred_durations)\n",
        "            transition_cycle_list.append(normalize_transition_time(transition_pred, 1000, transition_real))\n",
        "            transition_cycle_list_unormalized.append(transition_pred)\n",
        "            transitions_by_dim_cycle[kl_coef][cycle].append(transition_pred)\n",
        "            transitions_normalized_by_dim_cycle[kl_coef][cycle].append(normalize_transition_time(transition_pred, 1000, transition_real))\n",
        "\n",
        "            tvd = total_variation_distance(pred_hist, actual_hist)\n",
        "            tvd_cycle_list.append(tvd)\n",
        "            tvds_by_dim_cycle[kl_coef][cycle].append(tvd)\n",
        "\n",
        "            distance = np.sqrt(tvd ** 2 + (normalize_transition_time(transition_pred, 1000, transition_real)) ** 2)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}: TVD = {tvd:.6f}, Transition_Difference = {transition_pred-transition_real:.6f}, Combined Distance = {distance:.6f}\")\n",
        "            torch.save(model.state_dict(), f\"{folder}/model_at_epoch{epoch}\")\n",
        "\n",
        "            if distance < best_distance:\n",
        "                best_distance = distance\n",
        "                torch.save(model.state_dict(), f\"{folder}/best_model_combined_distance.pth\")\n",
        "                print(\"New best model saved based on TVD + transition difference distance.\")\n",
        "            # else:\n",
        "            #     print(\"No transitions detected in predictions.\")\n",
        "            #     transitions_by_dim_cycle[kl_coef][cycle].append(np.nan)\n",
        "            #     tvds_by_dim_cycle[kl_coef][cycle].append(np.nan)\n",
        "            #     tvd_cycle_list.append(np.nan)\n",
        "            #     transition_cycle_list.append(np.nan)\n",
        "            #     transition_cycle_list_unormalized.append(np.nan)\n",
        "\n",
        "\n",
        "            # Plot labels and formatting\n",
        "\n",
        "            x_line_real = np.linspace(min(real_data_sorted), max(real_data_sorted), 100)\n",
        "            exponential_fit_real = 1/np.mean(real_data_sorted)\n",
        "            y_values_real = exponential_fit_real*x_line_real\n",
        "            plt.plot(x_line_real, y_values_real, 'b-', label=f'Real Exp Fit (slope={exponential_fit_real:.4f})', linewidth=2)\n",
        "\n",
        "            if len(pred_durations) > 0:\n",
        "                x_line_pred = np.linspace(min(pred_durations), max(pred_durations), 100)\n",
        "                exponential_fit_pred = 1/np.mean(pred_durations)\n",
        "                y_values_pred = exponential_fit_pred*x_line_pred\n",
        "                plt.plot(x_line_pred, y_values_pred, 'r-', label=f'Pred Exp Fit (slope={exponential_fit_pred:.4f})', linewidth=2)\n",
        "                exp_by_dim_cycle[kl_coef][cycle].append(exponential_fit_pred)\n",
        "\n",
        "            plt.xlabel('Time Duration (Steps)')\n",
        "            plt.ylabel('Exponential Fit')\n",
        "            plt.title('Exponential Fit of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "            plt.yscale(\"linear\")  # y-axis log scale\n",
        "            plt.xscale(\"linear\")  # x-axis linear scale\n",
        "            plt.grid()\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            save_path = os.path.join(folder, \"expo_fit\")\n",
        "            save_path = os.path.join(save_path, f\"expo_fit_plot_{epoch}.png\")\n",
        "            plt.savefig(save_path)\n",
        "            plt.show()\n",
        "\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(tvd, transition_pred, 'o-', label=f'Cycle {cycle}')\n",
        "            plt.xlabel(\"Total Variation Distance\")\n",
        "            plt.ylabel(\"Average Transition Time\")\n",
        "            plt.axhline(y=transition_real, color='r', linestyle='--', label='Real Data')\n",
        "            plt.ylim(0.1,2000)\n",
        "            plt.xlim(0, 1)\n",
        "            plt.title(\"TVD vs. Avg Transition Time per Epoch\")\n",
        "            plt.grid(True)\n",
        "            save_path = os.path.join(folder, \"2D\")\n",
        "            save_path = os.path.join(save_path, f\"2D_plot_{epoch}.png\")\n",
        "            plt.savefig(save_path)\n",
        "            plt.show()\n",
        "            \n",
        "            if epoch == num_epochs - 1:  # Last epoch of last cycle for this dimension\n",
        "                # Plot TVDs with cycles overlapped\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                for c in range(num_cycles):\n",
        "                    plt.plot(tvds_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                \n",
        "                plt.xlabel('Epoch within Cycle')\n",
        "                plt.ylabel('Total Variation Distance')\n",
        "                plt.title(f'TVD Progress (KL Coefficient={kl_coef})')\n",
        "                plt.grid(True)\n",
        "                plt.legend()\n",
        "                save_path = os.path.join(folder, \"summary\")\n",
        "                save_path = os.path.join(save_path, f\"tvd_plot_all_cycles.png\")\n",
        "                plt.savefig(save_path)\n",
        "                plt.show()\n",
        "                \n",
        "                # Plot Exponential Fits with cycles overlapped\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                for c in range(num_cycles):\n",
        "                    plt.plot(transitions_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                \n",
        "                plt.axhline(y=transition_real, color='r', linestyle='--', label='Real Data')\n",
        "                plt.xlabel('Epoch within Cycle')\n",
        "                plt.ylabel('Average Transition Value')\n",
        "                plt.ylim(0.1,2000)\n",
        "                plt.title(f'Average Transition Progress (KL Coefficient={kl_coef})')\n",
        "                plt.grid(True)\n",
        "                plt.legend()\n",
        "                save_path = os.path.join(folder, \"summary\")\n",
        "                save_path = os.path.join(save_path, f\"transition_plot_all_cycles.png\")\n",
        "                plt.savefig(save_path)\n",
        "                plt.show()\n",
        "\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                for c in range(num_cycles):\n",
        "                    plt.plot(exp_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                \n",
        "                plt.axhline(y=exponential_fit_real, color='r', linestyle='--', label='Real Data')\n",
        "                plt.xlabel('Epoch within Cycle')\n",
        "                plt.ylabel('Exponential Fit Value')\n",
        "                plt.title(f'Exponential Fit Progress (KL Coefficient={kl_coef})')\n",
        "                plt.grid(True)\n",
        "                plt.legend()\n",
        "                save_path = os.path.join(folder, \"summary\")\n",
        "                save_path = os.path.join(save_path, f\"exponential_fit_plot_all_cycles.png\")\n",
        "                plt.savefig(save_path)\n",
        "                plt.show()\n",
        "                \n",
        "                # Plot TVD and 1/average transition time per epoch\n",
        "                plt.figure(figsize=(12, 6))\n",
        "                plt.scatter(tvd_cycle_list, transition_cycle_list, c=range(len(tvd_cycle_list)), cmap='viridis')\n",
        "                plt.colorbar(label='Epoch')\n",
        "                plt.xlabel(\"Total Variation Distance\")\n",
        "                plt.ylabel(\"Average Transition Time\")\n",
        "                plt.title(\"TVD vs. Avg Transition Time per Epoch\")\n",
        "                plt.grid(True)\n",
        "                save_path = os.path.join(folder, \"summary\")\n",
        "                save_path = os.path.join(save_path, f\"tvd_vs_transition_plot_all_cycles.png\")\n",
        "                plt.savefig(save_path)\n",
        "                plt.show()\n",
        "                \n",
        "                # If this is the last latent dimension, create master graphs with all dimensions\n",
        "                if kl_coef == kl_coefficients[-1] and cycle == num_cycles - 1:\n",
        "                    # Create a master folder for overlapping graphs\n",
        "                        \n",
        "                        # Plot TVDs with cycles overlapped\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    for c in range(num_cycles):\n",
        "                        plt.plot(tvds_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                    \n",
        "                    plt.xlabel('Epoch within Cycle')\n",
        "                    plt.ylabel('Total Variation Distance')\n",
        "                    plt.title(f'TVD Progress (KL Coefficient={kl_coef})')\n",
        "                    plt.grid(True)\n",
        "                    plt.legend()\n",
        "                    save_path = os.path.join(lat_folder, f\"tvd_plot_all_cycles.png\")\n",
        "                    plt.savefig(save_path)\n",
        "                    plt.show()\n",
        "                    \n",
        "                    # Plot Exponential Fits with cycles overlapped\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    for c in range(num_cycles):\n",
        "                        plt.plot(transitions_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                    \n",
        "                    plt.axhline(y=transition_real, color='r', linestyle='--', label='Real Data')\n",
        "                    plt.xlabel('Epoch within Cycle')\n",
        "                    plt.ylabel('Average Transition Value')\n",
        "                    plt.ylim(0.1,2000)\n",
        "                    plt.title(f'Average Transition Progress (KL Coefficient={kl_coef})')\n",
        "                    plt.grid(True)\n",
        "                    plt.legend()\n",
        "                    save_path = os.path.join(lat_folder, f\"transition_plot_all_cycles.png\")\n",
        "                    plt.savefig(save_path)\n",
        "                    plt.show()\n",
        "\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    for c in range(num_cycles):\n",
        "                        plt.plot(exp_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                    \n",
        "                    plt.axhline(y=exponential_fit_real, color='r', linestyle='--', label='Real Data')\n",
        "                    plt.xlabel('Epoch within Cycle')\n",
        "                    plt.ylabel('Exponential Fit Value')\n",
        "                    plt.title(f'Exponential Fit Progress (KL Coefficient={kl_coef})')\n",
        "                    plt.grid(True)\n",
        "                    plt.legend()\n",
        "                    save_path = os.path.join(lat_folder, f\"exponential_fit_plot_all_cycles.png\")\n",
        "                    plt.savefig(save_path)\n",
        "                    plt.show()\n",
        "                    \n",
        "                    # Plot TVD and 1/average transition time per epoch\n",
        "                    plt.figure(figsize=(12, 6))\n",
        "                    plt.scatter(tvd_cycle_list, transition_cycle_list, c=range(len(tvd_cycle_list)), cmap='viridis')\n",
        "                    plt.colorbar(label='Epoch')\n",
        "                    plt.xlabel(\"Total Variation Distance\")\n",
        "                    plt.ylabel(\"Average Transition Time\")\n",
        "                    plt.title(\"TVD vs. Avg Transition Time per Epoch\")\n",
        "                    plt.grid(True)\n",
        "                    save_path = os.path.join(lat_folder, f\"tvd_vs_transition_plot_all_cycles.png\")\n",
        "                    plt.savefig(save_path)\n",
        "                    plt.show()\n",
        "\n",
        "            torch.save(model.state_dict(), f\"{folder}/checkpoint_{epoch+1}\")\n",
        "            print(f\"Model weights saved to {folder} with point {epoch+1}.\")\n",
        "        \n",
        "            tvd_list.append(tvd_cycle_list)\n",
        "            transition_list.append(transition_cycle_list)\n",
        "            transition_list_unormalized.append(transition_cycle_list_unormalized)\n",
        "\n",
        "        # Save the model after each cycle\n",
        "        index = -1\n",
        "        best_distance = float('inf')\n",
        "        for i in range(0, num_cycles):\n",
        "            distance = np.sqrt(tvds_by_dim_cycle[kl_coef][cycle][i] ** 2 + transitions_normalized_by_dim_cycle[kl_coef][cycle][i] ** 2)\n",
        "            if distance < best_distance:\n",
        "                best_distance = distance\n",
        "                torch.save(model.state_dict(), f\"{folder}/best_model_combined_distance.pth\")\n",
        "                print(\"New best model saved based on TVD + normalized average transition value.\")\n",
        "                index = i\n",
        "                best_models_saved.append(model.state_dict())\n",
        "        best_models.append(index)\n",
        "\n",
        "\n",
        "    best_model_distance = float('inf')\n",
        "    for i,n in enumerate(best_models):\n",
        "        distance = np.sqrt(tvds_by_dim_cycle[kl_coef][i][n] ** 2 + transitions_normalized_by_dim_cycle[kl_coef][i][n] ** 2)\n",
        "        if distance < best_model_distance:\n",
        "            best_model_distance = distance\n",
        "            best_model = best_models_saved[i]\n",
        "            where_model = (i,n)\n",
        "    # Save the best model  \n",
        "    coordinates = where_model\n",
        "    cycle = i\n",
        "    epoch = n\n",
        "    torch.save(best_model, f\"{lat_folder}/best_model_combined_distance.pth\")\n",
        "    print(f\"Best model saved based on TVD + normalized average transition value with cycle {i+1} and epoch {n+1}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inference\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = ConditionalVAE(latent_dim, output_dim, condition_dim)\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# MODIFY THIS LINE FOR MODEL TESTING\n",
        "model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_KL_TEST_at_2025-04-24 15:43:51.612862/model_at_1_with_kl_10/checkpoint_2\"\n",
        "\n",
        "if os.path.exists(model_weights_path):\n",
        "    model.load_state_dict(torch.load(model_weights_path))\n",
        "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
        "\n",
        "for _ in range (0,5):\n",
        "    initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "    time_step = 300000\n",
        "    z = torch.zeros([1,latent_dim])\n",
        "    num_ens = 1\n",
        "    pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "    for k in range (0, time_step):\n",
        "\n",
        "        for ens in range (0, num_ens):\n",
        "            if (k==0):\n",
        "\n",
        "                z = torch.randn_like(z)\n",
        "                print(z.shape, initial_cond.shape)\n",
        "                y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:,ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            else:\n",
        "                select_ens = np.random.randint(0,num_ens,1)\n",
        "                z = torch.randn_like(z)\n",
        "                y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:, ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "    # Denormalize final preds\n",
        "    print(std_psi[:, 63])\n",
        "    pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "    # Denormalize test labels\n",
        "    actual_values = psi[:300000, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "    print(actual_values)\n",
        "\n",
        "    plt.figure(figsize=(20,8))\n",
        "    plt.plot(pred_mean[0:300000,63],'r')\n",
        "    plt.plot(actual_values[0:300000],'b')\n",
        "    plt.grid(True)\n",
        "    plt.title(f\"Predictions vs Actual | Checkpoint 4(best)\")\n",
        "    plt.savefig(f'/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_KL_TEST_at_2025-04-24 15:43:51.612862/model_at_1_with_kl_10/prediction_vs_actual_{datetime.datetime.now()}.png')\n",
        "    plt.show()\n",
        "\n",
        "    # MODIFY THIS LINE FOR MODEL TESTING\n",
        "    np.save(f'/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_KL_TEST_at_2025-04-24 15:43:51.612862/model_at_1_with_kl_10/predictions_best_checkpoint_and_cycle_Resnet_VAE_1.npy', pred_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NEW DATASET FOR FINETUNING + FINETUNING SCRIPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CCDF Error bars\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "import seaborn as sns\n",
        "\n",
        "CCDF_sum = 0\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "num_ccdfs = 10\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = ConditionalVAE(input_dim, latent_dim, output_dim, condition_dim)\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# MODIFY THIS LINE FOR MODEL TESTING\n",
        "model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_at_2025-03-25 16:07:01.635719/checkpoint_4_promising\"\n",
        "\n",
        "if os.path.exists(model_weights_path):\n",
        "    model.load_state_dict(torch.load(model_weights_path))\n",
        "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
        "    \n",
        "for i in range(0, num_ccdfs):\n",
        "    # Inference\n",
        "    initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "    time_step = 300000\n",
        "    z = torch.zeros([1,latent_dim])\n",
        "    num_ens = 1\n",
        "    pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "    for k in range (0, time_step):\n",
        "\n",
        "        for ens in range (0, num_ens):\n",
        "            if (k ==0):\n",
        "\n",
        "                z = torch.randn_like(z)\n",
        "                print(z.shape, initial_cond.shape)\n",
        "                y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:,ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            else:\n",
        "                select_ens = np.random.randint(0,num_ens,1)\n",
        "                z = torch.randn_like(z)\n",
        "                y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:, ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "    # Denormalize final preds\n",
        "    print(std_psi[:, 63])\n",
        "    pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "    # Denormalize test labels\n",
        "    actual_values = psi[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "    print(actual_values)\n",
        "\n",
        "    # Load the data; shape = (300000, 2, 75)\n",
        "    real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "    predictions = pred_mean.reshape(300000, 1, 75)\n",
        "\n",
        "    if (CCDF):\n",
        "        real_data_1d = real_data[:, 1, 61]  # Now shape is (309700,)\n",
        "        predictions_1d = predictions[:, 0, 61]  # shape (300000,)\n",
        "\n",
        "        # Define bounds (assuming they apply to both datasets)\n",
        "        upper_bound = 53.8 / 2.8935\n",
        "        lower_bound = 1.75 / 2.8935\n",
        "\n",
        "        # Function to calculate transition durations\n",
        "        def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "            times_between_transitions = []\n",
        "            transition_start = None\n",
        "            above_upper = False\n",
        "            below_lower = False\n",
        "\n",
        "            for i in range(1, len(y_values)):\n",
        "                if y_values[i] < lower_bound:  \n",
        "                    below_lower = True\n",
        "                    above_upper = False\n",
        "                elif y_values[i] > upper_bound:  \n",
        "                    if below_lower and transition_start is not None:\n",
        "                        times_between_transitions.append(i - transition_start)\n",
        "                        transition_start = None  \n",
        "                    above_upper = True\n",
        "                    below_lower = False\n",
        "\n",
        "                if below_lower and transition_start is None:\n",
        "                    transition_start = i\n",
        "\n",
        "            return times_between_transitions\n",
        "\n",
        "        # Compute transition durations for real data\n",
        "        real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "\n",
        "        # Compute transition durations for predictions data\n",
        "        pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "\n",
        "        # Plot setup\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        # === REAL DATA CCDF AND FIT ===\n",
        "        if len(real_durations) == 0:\n",
        "            print(\"No transitions detected in real data with current bounds!\")\n",
        "        else:\n",
        "            real_data_sorted = np.sort(real_durations)\n",
        "            x_line_real = np.linspace(min(real_data_sorted), max(real_data_sorted), 100)\n",
        "            exponential_fit_real = 1/np.mean(real_data_sorted)\n",
        "            y_values_real = exponential_fit_real*x_line_real\n",
        "            plt.plot(x_line_real, y_values_real, 'b-', label=f'Real Exp Fit (slope={exponential_fit_real:.4f})', linewidth=2)\n",
        "\n",
        "        # === PREDICTIONS CCDF AND FIT ===\n",
        "        if len(pred_durations) == 0:\n",
        "            print(\"No transitions detected in predictions with current bounds!\")\n",
        "        else:\n",
        "            pred_data_sorted = np.sort(pred_durations)\n",
        "            x_line_pred = np.linspace(min(pred_data_sorted), max(pred_data_sorted), 100)\n",
        "            exponential_fit_pred = 1/np.mean(pred_data_sorted)\n",
        "            y_values_pred = exponential_fit_pred*x_line_pred\n",
        "            plt.plot(x_line_pred, y_values_pred, 'r-', label=f'Pred Exp Fit (slope={exponential_fit_pred:.4f})', linewidth=2)\n",
        "\n",
        "        # Plot labels and formatting\n",
        "        plt.xlabel('Time Duration (Steps)')\n",
        "        plt.ylabel('CCDF')\n",
        "        plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "        plt.yscale(\"linear\")  # y-axis log scale\n",
        "        plt.xscale(\"linear\")  # x-axis linear scale\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(folder, \"CCDF\")\n",
        "        save_path = os.path.join(save_path, \"CCDF_plot\")\n",
        "        plt.savefig(save_path)\n",
        "        plt.show()\n",
        "\n",
        "CCDF_avg = CCDF_sum/num_ccdfs\n",
        "print(CCDF_avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Init pack\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "import numpy as np\n",
        "from scipy.integrate import solve_ivp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pre-processing\n",
        "psi = np.load('/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy')\n",
        "\n",
        "lead = 1\n",
        "\n",
        "trainN = 200000\n",
        "valN = 50000\n",
        "index = 63\n",
        "\n",
        "psi = psi[:,1,:]\n",
        "\n",
        "# After normalizing the data but before creating tensors\n",
        "upper_bound = 53.8 / 2.8935\n",
        "lower_bound = 7.41\n",
        "\n",
        "# Create a mask for values within bounds\n",
        "psi_filtered = psi[:,63]\n",
        "\n",
        "transitions = []\n",
        "above_upper = False  # Flag to track if we are above upper bound\n",
        "time_to_transition = []\n",
        "time_taken = 0\n",
        "time_to_transition_two = []\n",
        "\n",
        "transitions_two = []\n",
        "below_lower = False  # Flag to track if we are below lower bound\n",
        "\n",
        "time_taken = 0\n",
        "for i in range(1, len(psi_filtered)):\n",
        "    time_taken += 1\n",
        "\n",
        "\n",
        "    if psi_filtered[i] > upper_bound:\n",
        "        above_upper = True\n",
        "        \n",
        "\n",
        "    elif above_upper and psi_filtered[i] < lower_bound:\n",
        "\n",
        "        time_to_transition_two.append(time_taken)\n",
        "        transitions.append(i)\n",
        "        time_taken = 0\n",
        "        above_upper = False  # Reset flag after transition\n",
        "\n",
        "\n",
        "    if psi_filtered[i] < lower_bound:\n",
        "        below_lower = True\n",
        "\n",
        "    elif below_lower and psi_filtered[i] > upper_bound:\n",
        "        transitions_two.append(i)\n",
        "\n",
        "\n",
        "        time_to_transition.append(time_taken)\n",
        "        time_taken = 0\n",
        "        below_lower = False  # Reset flag after transition\n",
        "\n",
        "for val in transitions:\n",
        "    plt.axvline(x = val, color = 'r', label = 'axvline - full height')\n",
        "for val in transitions_two:\n",
        "    plt.axvline(x = val, color = 'b', label = 'axvline - full height')\n",
        "plt.show()\n",
        "\n",
        "print(\"Number of transitions from below lower to above upper bound:\", len(transitions_two))\n",
        "print(\"Number of transitions from above upper to below lower bound:\", len(transitions))\n",
        "transitions.extend(transitions_two)\n",
        "transitions.sort()\n",
        "\n",
        "print(len(transitions), transitions)\n",
        "\n",
        "hit_bound = False\n",
        "# THE STATE DEPENDS ON THE INITIAL CONDITION\n",
        "weak_to_strong = True\n",
        "strong_to_weak = False\n",
        "\n",
        "series = []\n",
        "for transition in transitions:\n",
        "    index = transition\n",
        "    if weak_to_strong:\n",
        "        while not hit_bound:\n",
        "            if psi_filtered[index] < lower_bound:\n",
        "                trans = psi[index-10:transition+5,:]\n",
        "                series.append(trans)\n",
        "                hit_bound = True\n",
        "            else:\n",
        "                index -= 1\n",
        "        weak_to_strong = False\n",
        "        strong_to_weak = True\n",
        "        hit_bound = False\n",
        "    elif strong_to_weak:\n",
        "        while not hit_bound:\n",
        "            if psi_filtered[index] > upper_bound:\n",
        "                trans = psi[index-10:transition+5,:]\n",
        "                series.append(trans)\n",
        "                hit_bound = True\n",
        "            else:\n",
        "                index -= 1\n",
        "        weak_to_strong = True\n",
        "        strong_to_weak = False\n",
        "        hit_bound = False\n",
        "\n",
        "print(psi.shape)\n",
        "mean_psi = np.mean(psi, axis=0, keepdims=True)\n",
        "std_psi = np.std(psi, axis=0, keepdims=True)\n",
        "psi = (psi - mean_psi) / std_psi\n",
        "\n",
        "psi_train_input = torch.tensor(psi[0:trainN,:])\n",
        "psi_train_label =  torch.tensor(psi[lead:trainN+lead,:])\n",
        "\n",
        "psi_val_input = torch.tensor(psi[trainN:trainN+valN,:])\n",
        "psi_val_label =  torch.tensor(psi[trainN+lead:trainN+valN+lead,:])\n",
        "\n",
        "len_series = []\n",
        "normalized_series = []\n",
        "for s in series:\n",
        "    print(len(s))\n",
        "    s = (s - mean_psi) / std_psi\n",
        "    s = torch.tensor(s)\n",
        "    len_series.append(len(s))\n",
        "    normalized_series.append(s)\n",
        "    plt.plot(s[:,63])\n",
        "\n",
        "plt.show()\n",
        "print(sum(len_series)/len(len_series))\n",
        "\n",
        "# Total Variation Distance\n",
        "def total_variation_distance(p,q):\n",
        "\tp = np.array(p)\n",
        "\tq = np.array(q)\n",
        "\treturn 0.5 * np.sum(np.abs(p-q))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "import math\n",
        "\n",
        "def set_model_finetune_mode():\n",
        "    # Encoder\n",
        "    model.encoder.fc1.weight.requires_grad = True\n",
        "    model.encoder.fc2.weight.requires_grad = True\n",
        "    model.encoder.fc3.weight.requires_grad = True\n",
        "    model.encoder.fc4.weight.requires_grad = False\n",
        "    model.encoder.fc5.weight.requires_grad = False\n",
        "    model.encoder.fc6.weight.requires_grad = False\n",
        "    model.encoder.fc_mu.weight.requires_grad = False\n",
        "    model.encoder.fc_logvar.weight.requires_grad = False\n",
        "\n",
        "    # Decoder\n",
        "    model.decoder.fc1.weight.requires_grad = False\n",
        "    model.decoder.fc2.weight.requires_grad = False\n",
        "    model.decoder.fc3.weight.requires_grad = False\n",
        "    model.decoder.fc4.weight.requires_grad = True\n",
        "    model.decoder.fc5.weight.requires_grad = True\n",
        "    model.decoder.fc6.weight.requires_grad = True\n",
        "\n",
        "def set_model_eval_mode():\n",
        "    # Encoder\n",
        "    model.encoder.fc1.weight.requires_grad = True\n",
        "    model.encoder.fc2.weight.requires_grad = True\n",
        "    model.encoder.fc3.weight.requires_grad = True\n",
        "    model.encoder.fc4.weight.requires_grad = True\n",
        "    model.encoder.fc5.weight.requires_grad = True\n",
        "    model.encoder.fc6.weight.requires_grad = True\n",
        "    model.encoder.fc_mu.weight.requires_grad = True\n",
        "    model.encoder.fc_logvar.weight.requires_grad = True\n",
        "\n",
        "    # Decoder\n",
        "    model.decoder.fc1.weight.requires_grad = True\n",
        "    model.decoder.fc2.weight.requires_grad = True\n",
        "    model.decoder.fc3.weight.requires_grad = True\n",
        "    model.decoder.fc4.weight.requires_grad = True\n",
        "    model.decoder.fc5.weight.requires_grad = True\n",
        "    model.decoder.fc6.weight.requires_grad = True\n",
        "\n",
        "latent_dims = [1024]\n",
        "num_cycles = 1\n",
        "\n",
        "tvds_by_dim_cycle = {dim: {cycle: [] for cycle in range(3)} for dim in latent_dims}\n",
        "expo_fits_by_dim_cycle = {dim: {cycle: [] for cycle in range(3)} for dim in latent_dims}\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    real_data = psi\n",
        "    lat_folder = f\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_lat{latent_dim}_at_{datetime.datetime.now()}\"\n",
        "    os.makedirs(lat_folder)\n",
        "    for cycle in range(0,num_cycles):\n",
        "\n",
        "        # Initialize the model, optimizer, and loss function\n",
        "        model = ConditionalVAE(latent_dim, output_dim, condition_dim)\n",
        "        model = model.cuda()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "        num_epochs = 100\n",
        "\n",
        "        model_weights_path = r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_KL_TEST_at_2025-04-24 15:43:51.612862/model_at_1_with_kl_10/checkpoint_2\"\n",
        "\n",
        "        if os.path.exists(model_weights_path):\n",
        "            model.load_state_dict(torch.load(model_weights_path))\n",
        "            print(f\"Model weights loaded from {model_weights_path}.\")\n",
        "        else:\n",
        "            print(\"can't find path\")\n",
        "\n",
        "        folder = f\"{lat_folder}/model_at_{cycle}\"\n",
        "        os.makedirs(folder)\n",
        "        subfolders = ['timeseries', 'expo_fit', '2D']\n",
        "\n",
        "        # Create each subdirectory inside the main folder\n",
        "        for subfolder in subfolders:\n",
        "            path = os.path.join(folder, subfolder)\n",
        "            os.mkdir(path)\n",
        "            print(f\"Created subfolder: {path}\")\n",
        "\n",
        "        # from torchsummary import summary\n",
        "\n",
        "        # summary(model, input_size = [(128, 1, 75), (128, 75)])\n",
        "        # Train the model\n",
        "        \n",
        "        for epoch in range(num_epochs):\n",
        "            for i,s in enumerate(normalized_series):\n",
        "                \n",
        "                # TRAINING\n",
        "                \n",
        "                model.train()\n",
        "                s_input = s[:-1,:]\n",
        "                s_label = s[1:,:]\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # Forward pass\n",
        "                output, mu, logvar = model(s_label.float().cuda(), s_input.float().cuda())\n",
        "                \n",
        "                # Reconstruction loss\n",
        "                reconstruction_loss = F.mse_loss(output, s_label.float().cuda(), reduction=\"sum\")\n",
        "\n",
        "                kl_loss = 0.5 * (mu ** 2 + torch.exp(logvar) - 1 - logvar).sum()\n",
        "                \n",
        "                # Total loss\n",
        "                loss = reconstruction_loss + 25 * kl_loss\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                # VALIDATION\n",
        "                \n",
        "                model.eval()\n",
        "                s_input = s[:-1,:]\n",
        "                s_label = s[1:,:]\n",
        "                \n",
        "                # Forward pass\n",
        "                output, mu, logvar = model(s_label.float().cuda(), s_input.float().cuda())\n",
        "                \n",
        "                # Reconstruction loss\n",
        "                reconstruction_val_loss = F.mse_loss(output, s_label.float().cuda(), reduction=\"sum\")\n",
        "\n",
        "                val_kl_loss = 0.5 * (mu ** 2 + torch.exp(logvar) - 1 - logvar).sum()\n",
        "                \n",
        "                # Total loss\n",
        "                val_loss = reconstruction_val_loss + 25 * kl_loss\n",
        "                \n",
        "            print(f'''Epoch {epoch+1}, transition {i+1},\n",
        "                    Reconstrunction Loss: {reconstruction_loss}\n",
        "                    KL Divergence Loss: {kl_loss}\n",
        "                    Validation Reconstrunction Loss: {reconstruction_val_loss}\n",
        "                    Validation KL Divergence Loss: {val_kl_loss}''')\n",
        "            # Inference\n",
        "\n",
        "            initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "            time_step = 30000\n",
        "            z = torch.zeros([1,latent_dim])\n",
        "            num_ens = 1\n",
        "            pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "            for k in range (0, time_step):\n",
        "\n",
        "                for ens in range (0, num_ens):\n",
        "                    if (k ==0):\n",
        "\n",
        "                        z = torch.randn_like(z)\n",
        "                        print(z.shape, initial_cond.shape)\n",
        "                        y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                        pred[k,:,ens] = y\n",
        "                        y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                        initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "                    else:\n",
        "                        select_ens = np.random.randint(0,num_ens,1)\n",
        "                        z = torch.randn_like(z)\n",
        "                        y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                        pred[k,:, ens] = y\n",
        "                        y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                        initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            # Denormalize final preds\n",
        "            print(std_psi[:, 63])\n",
        "            pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "            # Denormalize test labels\n",
        "            actual_values = psi_train_label[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "            print(actual_values)\n",
        "\n",
        "            plt.figure(figsize=(16, 6))\n",
        "            plt.plot(pred_mean[0:time_step,63],'r')\n",
        "            plt.plot(actual_values[0:time_step],'b')\n",
        "            plt.title(f\"Predictions vs Actual | Batch size of {batch_size}\")\n",
        "            plt.savefig(f'{folder}/prediction_epoch_{epoch+1}.png')\n",
        "            plt.show()\n",
        "\n",
        "            predictions_1d = pred_mean[:, 63]  # shape (300000,)\n",
        "            real_data_1d = real_data[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "            # Define bounds (assuming they apply to both datasets)\n",
        "            upper_bound = 53.8 / 2.8935\n",
        "            lower_bound = 7.41\n",
        "\n",
        "            # Function to calculate transition durations\n",
        "            def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "                times_between_transitions = []\n",
        "                transition_start = None\n",
        "                above_upper = False\n",
        "                below_lower = False\n",
        "\n",
        "                for i in range(1, len(y_values)):\n",
        "                    if y_values[i] <= lower_bound:  \n",
        "                        below_lower = True\n",
        "                        above_upper = False\n",
        "                    elif y_values[i] >= upper_bound:  \n",
        "                        if below_lower and transition_start is not None:\n",
        "                            times_between_transitions.append(i - transition_start)\n",
        "                            transition_start = None  \n",
        "                        above_upper = True\n",
        "                        below_lower = False\n",
        "\n",
        "                    if below_lower and transition_start is None:\n",
        "                        transition_start = i\n",
        "\n",
        "                return times_between_transitions\n",
        "\n",
        "            # Compute transition durations for real data\n",
        "            real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "\n",
        "            # Compute transition durations for predictions data\n",
        "            pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "\n",
        "            # Plot setup\n",
        "            plt.figure(figsize=(10, 6))\n",
        "\n",
        "            # === REAL DATA CCDF AND FIT ===\n",
        "            if len(real_durations) == 0:\n",
        "                print(\"No transitions detected in real data with current bounds!\")\n",
        "            else:\n",
        "                real_data_sorted = np.sort(real_durations)\n",
        "                x_line_real = np.linspace(min(real_data_sorted), max(real_data_sorted), 100)\n",
        "                exponential_fit_real = 1/np.mean(real_data_sorted)\n",
        "                y_values_real = exponential_fit_real*x_line_real\n",
        "                plt.plot(x_line_real, y_values_real, 'b-', label=f'Real Exp Fit (slope={exponential_fit_real:.4f})', linewidth=2)\n",
        "\n",
        "            # === PREDICTIONS CCDF AND FIT ===\n",
        "            exponential_fit_pred = 0\n",
        "            if len(pred_durations) == 0:\n",
        "                print(\"No transitions detected in predictions with current bounds!\")\n",
        "            else:\n",
        "                pred_data_sorted = np.sort(pred_durations)\n",
        "                x_line_pred = np.linspace(min(pred_data_sorted), max(pred_data_sorted), 100)\n",
        "                exponential_fit_pred = 1/np.mean(pred_data_sorted)\n",
        "                y_values_pred = exponential_fit_pred*x_line_pred\n",
        "                plt.plot(x_line_pred, y_values_pred, 'r-', label=f'Pred Exp Fit (slope={exponential_fit_pred:.4f})', linewidth=2)\n",
        "\n",
        "            # Plot labels and formatting\n",
        "            plt.xlabel('Time Duration (Steps)')\n",
        "            plt.ylabel('Exponential Fit')\n",
        "            plt.title('Exponential Fit of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "            plt.yscale(\"linear\")  # y-axis log scale\n",
        "            plt.xscale(\"linear\")  # x-axis linear scale\n",
        "            plt.grid()\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            save_path = os.path.join(folder, \"expo_fit\")\n",
        "            save_path = os.path.join(save_path, f\"expo_fit_plot_{epoch}.png\")\n",
        "            plt.savefig(save_path)\n",
        "            plt.show()\n",
        "\n",
        "            if pred_mean[:, 63].max() <= 100 or pred_mean[:, 63].min() >= -100:\n",
        "                pred_hist, _ = np.histogram(pred_mean, bins=50, density=True)\n",
        "                actual_hist, _ = np.histogram(actual_values,bins=50,density=True)\n",
        "\n",
        "                tvd = total_variation_distance(pred_hist,actual_hist)\n",
        "\n",
        "                save_path = folder\n",
        "                save_path = os.path.join(folder, \"2D\")\n",
        "                save_path = os.path.join(save_path, f\"2D_plot_{epoch}.png\")\n",
        "                plt.plot(tvd, exponential_fit_pred, \"ro\", label=f\"Point with {math.sqrt(tvd**2+(exponential_fit_pred-exponential_fit_real)**2)} distance from the optimal\")\n",
        "                plt.xlabel(\"Total Variation Distance\")\n",
        "                plt.ylabel(\"Exponential Fit\")\n",
        "                plt.title(\"2D Space of TVD and Exponential Fit\")\n",
        "                plt.xlim(0,1)\n",
        "                plt.ylim(0,exponential_fit_real*2)\n",
        "                plt.axhline(exponential_fit_real)\n",
        "                plt.grid()\n",
        "                plt.legend()\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(save_path)\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"Weights experienced explosion!\")\n",
        "\n",
        "            tvds_by_dim_cycle[latent_dim][cycle].append(tvd)\n",
        "            expo_fits_by_dim_cycle[latent_dim][cycle].append(exponential_fit_pred)\n",
        "\n",
        "            if cycle == 2 and epoch == num_epochs - 1:  # Last epoch of last cycle for this dimension\n",
        "                # Plot TVDs with cycles overlapped\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                for c in range(3):\n",
        "                    plt.plot(tvds_by_dim_cycle[latent_dim][c], 'o-', label=f'Cycle {c}')\n",
        "                \n",
        "                plt.xlabel('Epoch within Cycle')\n",
        "                plt.ylabel('Total Variation Distance')\n",
        "                plt.title(f'TVD Progress (Dim={latent_dim})')\n",
        "                plt.grid(True)\n",
        "                plt.legend()\n",
        "                plt.savefig(f'{lat_folder}/tvd_dim_{latent_dim}_all_cycles.png')\n",
        "                plt.close()\n",
        "                \n",
        "                # Plot Exponential Fits with cycles overlapped\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                for c in range(3):\n",
        "                    plt.plot(expo_fits_by_dim_cycle[latent_dim][c], 'o-', label=f'Cycle {c}')\n",
        "                \n",
        "                plt.axhline(y=exponential_fit_real, color='r', linestyle='--', label='Real Data')\n",
        "                plt.xlabel('Epoch within Cycle')\n",
        "                plt.ylabel('Exponential Fit Value')\n",
        "                plt.title(f'Exponential Fit Progress (Dim={latent_dim})')\n",
        "                plt.grid(True)\n",
        "                plt.legend()\n",
        "                plt.savefig(f'{lat_folder}/expo_fit_dim_{latent_dim}_all_cycles.png')\n",
        "                plt.close()\n",
        "                \n",
        "                # If this is the last latent dimension, create master graphs with all dimensions\n",
        "                if latent_dim == latent_dims[-1]:\n",
        "                    # Create a master folder for overlapping graphs\n",
        "                    master_folder = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/summary\"\n",
        "                    os.makedirs(master_folder, exist_ok=True)\n",
        "                    \n",
        "                    # Plot best TVD for each dimension (from last epoch of last cycle)\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    best_tvds = [tvds_by_dim_cycle[dim][2][-1] for dim in latent_dims]  # Last value from last cycle\n",
        "                    plt.bar(range(len(latent_dims)), best_tvds, tick_label=latent_dims)\n",
        "                    plt.xlabel('Latent Dimension')\n",
        "                    plt.ylabel('Final TVD Value')\n",
        "                    plt.title('Best TVD Across Latent Dimensions')\n",
        "                    plt.grid(axis='y')\n",
        "                    plt.savefig(f'{master_folder}/best_tvd_comparison.png')\n",
        "                    plt.close()\n",
        "                    \n",
        "                    # Plot best exponential fits for each dimension\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    best_expos = [expo_fits_by_dim_cycle[dim][2][-1] for dim in latent_dims]  # Last value from last cycle\n",
        "                    plt.bar(range(len(latent_dims)), best_expos, tick_label=latent_dims)\n",
        "                    plt.axhline(y=exponential_fit_real, color='r', linestyle='--', label='Real Data')\n",
        "                    plt.xlabel('Latent Dimension')\n",
        "                    plt.ylabel('Final Exponential Fit Value')\n",
        "                    plt.title('Best Exponential Fit Across Latent Dimensions')\n",
        "                    plt.grid(axis='y')\n",
        "                    plt.legend()\n",
        "                    plt.savefig(f'{master_folder}/best_expo_fit_comparison.png')\n",
        "                    plt.close()\n",
        "\n",
        "            torch.save(model.state_dict(), f\"{folder}/checkpoint_{epoch+1}\")\n",
        "            print(f\"Model weights saved to {folder} with point {epoch+1}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#FLAGS to determine testing\n",
        "plot_data = 1\n",
        "#what level do you want to plot\n",
        "level = 63\n",
        "CCDF = 1\n",
        "Bi_modal_distribution = 1\n",
        "single_step_profiles = 1\n",
        "#for the single_step_profiles\n",
        "NUM_SAMPLES = 5\n",
        "#what weights do you want to use?\n",
        "MODEL_PATH = r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_lat1024_at_2025-04-11 12:46:39.526973/model_at_0/checkpoint_3\"\n",
        "LEVEL = 63\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Load the data; shape = (300000, 2, 75)\n",
        "real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "predictions = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_lat1024_at_2025-04-11 12:46:39.526973/predictions_best_checkpoint_Finetuned_Resnet_VAE_1.npy\")\n",
        "\n",
        "#reshape the predictions so that it matches the real_data shape\n",
        "predictions = predictions.reshape(300000, 1, 75)\n",
        "print(predictions.shape)\n",
        "print(real_data.shape)\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S.%f\")\n",
        "folder = f\"testing_at_{timestamp}\"\n",
        "os.mkdir(folder)\n",
        "subfolders = ['timeseries', 'CCDF', 'bi_modal_distribution', 'single_step_profiles']\n",
        "# Create each subdirectory inside the main folder\n",
        "for subfolder in subfolders:\n",
        "    path = os.path.join(folder, subfolder)\n",
        "    os.mkdir(path)\n",
        "    print(f\"Created subfolder: {path}\")\n",
        "SAVE_DIR = os.path.join(folder, \"single_step_profiles\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LONG TRAINING RUN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "import math\n",
        "\n",
        "def normalize_transition_time(slope_value, delta, transition_real):\n",
        "    normalized = 1 - np.exp(-np.abs((slope_value - transition_real)) / delta)\n",
        "    return normalized\n",
        "\n",
        "def total_variation_distance(p, q):\n",
        "    p = np.array(p)\n",
        "    q = np.array(q)\n",
        "    return 0.5 * np.sum(np.abs(p - q))\n",
        "\n",
        "def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "    times_between_transitions = []\n",
        "    transition_start = None\n",
        "    above_upper = False\n",
        "    below_lower = False\n",
        "    for i in range(1, len(y_values)):\n",
        "        if y_values[i] < lower_bound:\n",
        "            below_lower = True\n",
        "            above_upper = False\n",
        "        elif y_values[i] > upper_bound:\n",
        "            if below_lower and transition_start is not None:\n",
        "                times_between_transitions.append(i - transition_start)\n",
        "                transition_start = None\n",
        "            above_upper = True\n",
        "            below_lower = False\n",
        "        if below_lower and transition_start is None:\n",
        "            transition_start = i\n",
        "    return times_between_transitions\n",
        "\n",
        "latent_dims = [1024]\n",
        "latent_dim = 1024\n",
        "kl_coefficients = [1]\n",
        "num_cycles = 1\n",
        "test_epochs = [5, 10, 20, 50, 100, 200, 500, 1000, 2000, 3000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
        "upper_bound = 53.8 / 2.8935\n",
        "lower_bound = 7.41\n",
        "level = 63\n",
        "\n",
        "best_distance = float('inf')\n",
        "tvd_list = []\n",
        "transition_list = []\n",
        "transition_list_unormalized = []\n",
        "\n",
        "real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "real_data_1d = real_data[:, 1, level]\n",
        "real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "real_data_sorted = np.sort(real_durations)\n",
        "transition_real = np.mean(real_data_sorted)\n",
        "actual_hist, bin_edges = np.histogram(real_data[:, 1, level], bins=50, density=True)\n",
        "print(f\"Reference Real Data average_transition_time: {transition_real}\")\n",
        "\n",
        "tvds_by_dim_cycle = {kl: {cycle: [] for cycle in range(num_cycles)} for kl in kl_coefficients}\n",
        "transitions_by_dim_cycle = {kl: {cycle: [] for cycle in range(num_cycles)} for kl in kl_coefficients}\n",
        "transitions_normalized_by_dim_cycle = {kl: {cycle: [] for cycle in range(num_cycles)} for kl in kl_coefficients}\n",
        "exp_by_dim_cycle = {kl: {cycle: [] for cycle in range(num_cycles)} for kl in kl_coefficients}\n",
        "\n",
        "lat_folder = f\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_KL_TEST_at_{datetime.datetime.now()}\"\n",
        "os.makedirs(lat_folder)\n",
        "\n",
        "for kl_coef in kl_coefficients:\n",
        "    print(f\"USING KL COEF OF {kl_coef}\")\n",
        "    best_models = []\n",
        "    best_models_saved = []\n",
        "    for cycle in range(0,num_cycles):\n",
        "        tvd_cycle_list = []\n",
        "        transition_cycle_list = []\n",
        "        transition_cycle_list_unormalized = []\n",
        "        \n",
        "        # Initialize the model, optimizer, and loss function\n",
        "        model = ConditionalVAE(latent_dim, output_dim, condition_dim)\n",
        "        model = model.cuda()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "        num_epochs = 10100\n",
        "\n",
        "        folder = f\"{lat_folder}/model_at_{cycle}_with_kl_{kl_coef}\"\n",
        "        os.makedirs(folder)\n",
        "        subfolders = ['timeseries', 'expo_fit', '2D', 'summary']\n",
        "\n",
        "        # Create each subdirectory inside the main folder\n",
        "        for subfolder in subfolders:\n",
        "            path = os.path.join(folder, subfolder)\n",
        "            os.mkdir(path)\n",
        "            print(f\"Created subfolder: {path}\")\n",
        "\n",
        "        # from torchsummary import summary\n",
        "\n",
        "        # summary(model, input_size = [(128, 1, 75), (128, 75)])\n",
        "        # Train the model\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            for batch in range (0, trainN, batch_size):\n",
        "\n",
        "                input_batch = psi_train_input[batch:batch + batch_size,:]\n",
        "                label_batch = psi_train_label[batch:batch + batch_size,:]\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                output, mu, logvar = model(label_batch.float().cuda(), input_batch.float().cuda())\n",
        "\n",
        "                # Reconstruction loss\n",
        "                reconstruction_loss = F.mse_loss(output, label_batch.float().cuda(), reduction=\"sum\")\n",
        "                # KL divergence loss\n",
        "                kl_loss = 0.5 * (mu ** 2 + torch.exp(logvar) - 1 - logvar).sum()\n",
        "                \n",
        "                # Total loss\n",
        "                loss = reconstruction_loss + kl_coef * kl_loss\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            print(f'''Epoch {epoch+1}, \n",
        "                Reconstrunction Loss: {reconstruction_loss},\n",
        "                KL Divergence Loss: {kl_loss}''')\n",
        "\n",
        "            # Validation Loss\n",
        "            for batch in range (0, valN, batch_size):\n",
        "\n",
        "                input_batch = psi_val_input[batch:batch + batch_size,:]\n",
        "                label_batch = psi_val_label[batch:batch + batch_size,:]\n",
        "                \n",
        "                output, mu, logvar = model(label_batch.float().cuda(), input_batch.float().cuda())\n",
        "                reconstruction_loss = F.mse_loss(output, label_batch.float().cuda(), reduction=\"sum\")\n",
        "                kl_loss = 0.5 * (mu ** 2 + torch.exp(logvar) - 1 - logvar).sum()\n",
        "                val_loss = reconstruction_loss + kl_coef * kl_loss # Experiment HIGHER coefficients\n",
        "                # Print both reconstruction_loss and kl_loss\n",
        "\n",
        "            print(f'''\n",
        "                Validation Reconstrunction Loss: {reconstruction_loss},\n",
        "                Validation KL Divergence Loss: {kl_loss}''')\n",
        "            \n",
        "            # Inference\n",
        "\n",
        "            if epoch-1 in test_epochs:\n",
        "                initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "                time_step = 300000\n",
        "                z = torch.zeros([1,latent_dim])\n",
        "                num_ens = 1\n",
        "                pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "                for k in range (0, time_step):\n",
        "\n",
        "                    for ens in range (0, num_ens):\n",
        "                        if (k ==0):\n",
        "\n",
        "                            z = torch.randn_like(z)\n",
        "                            print(z.shape, initial_cond.shape)\n",
        "                            y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                            pred[k,:,ens] = y\n",
        "                            y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                            initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "                        else:\n",
        "                            select_ens = np.random.randint(0,num_ens,1)\n",
        "                            z = torch.randn_like(z)\n",
        "                            y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                            pred[k,:, ens] = y\n",
        "                            y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                            initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "                # Denormalize final preds\n",
        "                print(std_psi[:, 63])\n",
        "                pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "                # Denormalize test labels\n",
        "                actual_values = psi_train_label[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "                print(actual_values)\n",
        "                \n",
        "                real_data_1d = real_data[:30000, 0, 63]  # Now shape is (309700,)\n",
        "                predictions_1d = pred_mean[:, 63]  # shape (300000,)\n",
        "\n",
        "                plt.figure(figsize=(20,8))\n",
        "                plt.plot(pred_mean[0:30000,63],'r')\n",
        "                plt.plot(real_data[0:30000, 0, 63])\n",
        "                plt.grid(True)\n",
        "                plt.title(f\"Predictions vs Actual | Epoch {epoch}\")\n",
        "                save_path = os.path.join(folder, \"timeseries\")\n",
        "                save_path = os.path.join(save_path, f\"timeseries_plot_{epoch}.png\")\n",
        "                plt.savefig(save_path)\n",
        "                plt.xlabel('Time Step')\n",
        "                plt.ylabel('Zonal Wind Value')\n",
        "                plt.legend(['Predictions', 'Actual'])\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "                \n",
        "                # Function to calculate transition durations\n",
        "                def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "                    times_between_transitions = []\n",
        "                    transition_start = None\n",
        "                    above_upper = False\n",
        "                    below_lower = False\n",
        "\n",
        "                    for i in range(1, len(y_values)):\n",
        "                        if y_values[i] < lower_bound:  \n",
        "                            below_lower = True\n",
        "                            above_upper = False\n",
        "                        elif y_values[i] > upper_bound:  \n",
        "                            if below_lower and transition_start is not None:\n",
        "                                times_between_transitions.append(i - transition_start)\n",
        "                                transition_start = None  \n",
        "                            above_upper = True\n",
        "                            below_lower = False\n",
        "\n",
        "                        if below_lower and transition_start is None:\n",
        "                            transition_start = i\n",
        "\n",
        "                    return times_between_transitions\n",
        "                \n",
        "                predictions_1d = pred_mean[:, level, 0]\n",
        "                pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "                print(pred_durations)\n",
        "                pred_hist, _ = np.histogram(predictions_1d, bins=bin_edges, density=True)\n",
        "\n",
        "                # === PREDICTIONS CCDF AND FIT ===\n",
        "                exponential_fit_pred = 0\n",
        "\n",
        "                # if len(pred_durations) > 0:\n",
        "                transition_pred = np.mean(pred_durations)\n",
        "                transition_cycle_list.append(normalize_transition_time(transition_pred, 1000, transition_real))\n",
        "                transition_cycle_list_unormalized.append(transition_pred)\n",
        "                transitions_by_dim_cycle[kl_coef][cycle].append(transition_pred)\n",
        "                transitions_normalized_by_dim_cycle[kl_coef][cycle].append(normalize_transition_time(transition_pred, 1000, transition_real))\n",
        "\n",
        "                tvd = total_variation_distance(pred_hist, actual_hist)\n",
        "                tvd_cycle_list.append(tvd)\n",
        "                tvds_by_dim_cycle[kl_coef][cycle].append(tvd)\n",
        "\n",
        "                distance = np.sqrt(tvd ** 2 + (normalize_transition_time(transition_pred, 1000, transition_real)) ** 2)\n",
        "\n",
        "                print(f\"Epoch {epoch+1}: TVD = {tvd:.6f}, Transition_Difference = {transition_pred-transition_real:.6f}, Combined Distance = {distance:.6f}\")\n",
        "                torch.save(model.state_dict(), f\"{folder}/model_at_epoch{epoch}\")\n",
        "\n",
        "                if distance < best_distance:\n",
        "                    best_distance = distance\n",
        "                    torch.save(model.state_dict(), f\"{folder}/best_model_combined_distance.pth\")\n",
        "                    print(\"New best model saved based on TVD + transition difference distance.\")\n",
        "                # else:\n",
        "                #     print(\"No transitions detected in predictions.\")\n",
        "                #     transitions_by_dim_cycle[kl_coef][cycle].append(np.nan)\n",
        "                #     tvds_by_dim_cycle[kl_coef][cycle].append(np.nan)\n",
        "                #     tvd_cycle_list.append(np.nan)\n",
        "                #     transition_cycle_list.append(np.nan)\n",
        "                #     transition_cycle_list_unormalized.append(np.nan)\n",
        "\n",
        "\n",
        "                # Plot labels and formatting\n",
        "\n",
        "                x_line_real = np.linspace(min(real_data_sorted), max(real_data_sorted), 100)\n",
        "                exponential_fit_real = 1/np.mean(real_data_sorted)\n",
        "                y_values_real = exponential_fit_real*x_line_real\n",
        "                plt.plot(x_line_real, y_values_real, 'b-', label=f'Real Exp Fit (slope={exponential_fit_real:.4f})', linewidth=2)\n",
        "\n",
        "                if len(pred_durations) > 0:\n",
        "                    x_line_pred = np.linspace(min(pred_durations), max(pred_durations), 100)\n",
        "                    exponential_fit_pred = 1/np.mean(pred_durations)\n",
        "                    y_values_pred = exponential_fit_pred*x_line_pred\n",
        "                    plt.plot(x_line_pred, y_values_pred, 'r-', label=f'Pred Exp Fit (slope={exponential_fit_pred:.4f})', linewidth=2)\n",
        "                    exp_by_dim_cycle[kl_coef][cycle].append(exponential_fit_pred)\n",
        "\n",
        "                plt.xlabel('Time Duration (Steps)')\n",
        "                plt.ylabel('Exponential Fit')\n",
        "                plt.title('Exponential Fit of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "                plt.yscale(\"linear\")  # y-axis log scale\n",
        "                plt.xscale(\"linear\")  # x-axis linear scale\n",
        "                plt.grid()\n",
        "                plt.legend()\n",
        "                plt.tight_layout()\n",
        "                save_path = os.path.join(folder, \"expo_fit\")\n",
        "                save_path = os.path.join(save_path, f\"expo_fit_plot_{epoch}.png\")\n",
        "                plt.savefig(save_path)\n",
        "                plt.show()\n",
        "\n",
        "                plt.figure(figsize=(12, 6))\n",
        "                plt.plot(tvd, transition_pred, 'o-', label=f'Cycle {cycle}')\n",
        "                plt.xlabel(\"Total Variation Distance\")\n",
        "                plt.ylabel(\"Average Transition Time\")\n",
        "                plt.axhline(y=transition_real, color='r', linestyle='--', label='Real Data')\n",
        "                plt.ylim(0.1,2000)\n",
        "                plt.xlim(0, 1)\n",
        "                plt.title(\"TVD vs. Avg Transition Time per Epoch\")\n",
        "                plt.grid(True)\n",
        "                save_path = os.path.join(folder, \"2D\")\n",
        "                save_path = os.path.join(save_path, f\"2D_plot_{epoch}.png\")\n",
        "                plt.savefig(save_path)\n",
        "                plt.show()\n",
        "                \n",
        "                if epoch == num_epochs - 1:  # Last epoch of last cycle for this dimension\n",
        "                    # Plot TVDs with cycles overlapped\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    for c in range(num_cycles):\n",
        "                        if c in tvds_by_dim_cycle[kl_coef]:\n",
        "                            plt.plot(tvds_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                        else:\n",
        "                            print(f\"Skipping cycle {c} as it is not in tvds_by_dim_cycle.\")\n",
        "                    \n",
        "                    plt.xlabel('Epoch within Cycle')\n",
        "                    plt.ylabel('Total Variation Distance')\n",
        "                    plt.title(f'TVD Progress (KL Coefficient={kl_coef})')\n",
        "                    plt.grid(True)\n",
        "                    plt.legend()\n",
        "                    save_path = os.path.join(folder, \"summary\")\n",
        "                    save_path = os.path.join(save_path, f\"tvd_plot_all_cycles.png\")\n",
        "                    plt.savefig(save_path)\n",
        "                    plt.show()\n",
        "                    for c in range(num_cycles):\n",
        "                        if c in transitions_by_dim_cycle[kl_coef]:\n",
        "                            plt.plot(transitions_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                        else:\n",
        "                            print(f\"Skipping cycle {c} as it is not in transitions_by_dim_cycle.\")\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    for c in range(num_cycles):\n",
        "                        plt.plot(transitions_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                    \n",
        "                    plt.axhline(y=transition_real, color='r', linestyle='--', label='Real Data')\n",
        "                    plt.xlabel('Epoch within Cycle')\n",
        "                    plt.ylabel('Average Transition Value')\n",
        "                    plt.ylim(0.1,2000)\n",
        "                    plt.title(f'Average Transition Progress (KL Coefficient={kl_coef})')\n",
        "                    plt.grid(True)\n",
        "                    plt.legend()\n",
        "                    save_path = os.path.join(folder, \"summary\")\n",
        "                    save_path = os.path.join(save_path, f\"transition_plot_all_cycles.png\")\n",
        "                    plt.savefig(save_path)\n",
        "                    plt.show()\n",
        "\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    for c in range(num_cycles):\n",
        "                        plt.plot(exp_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                    \n",
        "                    plt.axhline(y=exponential_fit_real, color='r', linestyle='--', label='Real Data')\n",
        "                    plt.xlabel('Epoch within Cycle')\n",
        "                    plt.ylabel('Exponential Fit Value')\n",
        "                    plt.title(f'Exponential Fit Progress (KL Coefficient={kl_coef})')\n",
        "                    plt.grid(True)\n",
        "                    plt.legend()\n",
        "                    save_path = os.path.join(folder, \"summary\")\n",
        "                    save_path = os.path.join(save_path, f\"exponential_fit_plot_all_cycles.png\")\n",
        "                    plt.savefig(save_path)\n",
        "                    plt.show()\n",
        "                    \n",
        "                    # Plot TVD and 1/average transition time per epoch\n",
        "                    plt.figure(figsize=(12, 6))\n",
        "                    plt.scatter(tvd_cycle_list, transition_cycle_list, c=range(len(tvd_cycle_list)), cmap='viridis')\n",
        "                    plt.colorbar(label='Epoch')\n",
        "                    plt.xlabel(\"Total Variation Distance\")\n",
        "                    plt.ylabel(\"Average Transition Time\")\n",
        "                    plt.title(\"TVD vs. Avg Transition Time per Epoch\")\n",
        "                    plt.grid(True)\n",
        "                    save_path = os.path.join(folder, \"summary\")\n",
        "                    save_path = os.path.join(save_path, f\"tvd_vs_transition_plot_all_cycles.png\")\n",
        "                    plt.savefig(save_path)\n",
        "                    plt.show()\n",
        "                    \n",
        "                    # If this is the last latent dimension, create master graphs with all dimensions\n",
        "                    if kl_coef == kl_coefficients[-1] and cycle == num_cycles - 1:\n",
        "                        # Create a master folder for overlapping graphs\n",
        "                            \n",
        "                            # Plot TVDs with cycles overlapped\n",
        "                        plt.figure(figsize=(10, 6))\n",
        "                        for c in range(num_cycles):\n",
        "                            plt.plot(tvds_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                        \n",
        "                        plt.xlabel('Epoch within Cycle')\n",
        "                        plt.ylabel('Total Variation Distance')\n",
        "                        plt.title(f'TVD Progress (KL Coefficient={kl_coef})')\n",
        "                        plt.grid(True)\n",
        "                        plt.legend()\n",
        "                        save_path = os.path.join(lat_folder, f\"tvd_plot_all_cycles.png\")\n",
        "                        plt.savefig(save_path)\n",
        "                        plt.show()\n",
        "                        \n",
        "                        # Plot Exponential Fits with cycles overlapped\n",
        "                        plt.figure(figsize=(10, 6))\n",
        "                        for c in range(num_cycles):\n",
        "                            plt.plot(transitions_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                        \n",
        "                        plt.axhline(y=transition_real, color='r', linestyle='--', label='Real Data')\n",
        "                        plt.xlabel('Epoch within Cycle')\n",
        "                        plt.ylabel('Average Transition Value')\n",
        "                        plt.ylim(0.1,2000)\n",
        "                        plt.title(f'Average Transition Progress (KL Coefficient={kl_coef})')\n",
        "                        plt.grid(True)\n",
        "                        plt.legend()\n",
        "                        save_path = os.path.join(lat_folder, f\"transition_plot_all_cycles.png\")\n",
        "                        plt.savefig(save_path)\n",
        "                        plt.show()\n",
        "\n",
        "                        plt.figure(figsize=(10, 6))\n",
        "                        for c in range(num_cycles):\n",
        "                            plt.plot(exp_by_dim_cycle[kl_coef][c], 'o-', label=f'Cycle {c}')\n",
        "                        \n",
        "                        plt.axhline(y=exponential_fit_real, color='r', linestyle='--', label='Real Data')\n",
        "                        plt.xlabel('Epoch within Cycle')\n",
        "                        plt.ylabel('Exponential Fit Value')\n",
        "                        plt.title(f'Exponential Fit Progress (KL Coefficient={kl_coef})')\n",
        "                        plt.grid(True)\n",
        "                        plt.legend()\n",
        "                        save_path = os.path.join(lat_folder, f\"exponential_fit_plot_all_cycles.png\")\n",
        "                        plt.savefig(save_path)\n",
        "                        plt.show()\n",
        "                        \n",
        "                        # Plot TVD and 1/average transition time per epoch\n",
        "                        plt.figure(figsize=(12, 6))\n",
        "                        plt.scatter(tvd_cycle_list, transition_cycle_list, c=range(len(tvd_cycle_list)), cmap='viridis')\n",
        "                        plt.colorbar(label='Epoch')\n",
        "                        plt.xlabel(\"Total Variation Distance\")\n",
        "                        plt.ylabel(\"Average Transition Time\")\n",
        "                        plt.title(\"TVD vs. Avg Transition Time per Epoch\")\n",
        "                        plt.grid(True)\n",
        "                        save_path = os.path.join(lat_folder, f\"tvd_vs_transition_plot_all_cycles.png\")\n",
        "                        plt.savefig(save_path)\n",
        "                        plt.show()\n",
        "\n",
        "                torch.save(model.state_dict(), f\"{folder}/checkpoint_{epoch+1}\")\n",
        "                print(f\"Model weights saved to {folder} with point {epoch+1}.\")\n",
        "            \n",
        "                tvd_list.append(tvd_cycle_list)\n",
        "                \n",
        "            for i in range(0, num_cycles):\n",
        "                # Ensure the index exists in the lists\n",
        "                if i < len(tvds_by_dim_cycle[kl_coef][cycle]) and i < len(transitions_normalized_by_dim_cycle[kl_coef][cycle]):\n",
        "                    distance = np.sqrt(tvds_by_dim_cycle[kl_coef][cycle][i] ** 2 + transitions_normalized_by_dim_cycle[kl_coef][cycle][i] ** 2)\n",
        "                    if distance < best_distance:\n",
        "                        best_distance = distance\n",
        "                        torch.save(model.state_dict(), f\"{folder}/best_model_combined_distance.pth\")\n",
        "                        print(\"New best model saved based on TVD + normalized average transition value.\")\n",
        "                        index = i\n",
        "                        best_models_saved.append(model.state_dict())\n",
        "                else:\n",
        "                    print(f\"Skipping index {i} as it is out of range.\")\n",
        "            best_models.append(index)\n",
        "\n",
        "\n",
        "        best_model_distance = float('inf')\n",
        "        for i,n in enumerate(best_models):\n",
        "            distance = np.sqrt(tvds_by_dim_cycle[kl_coef][i][n] ** 2 + transitions_normalized_by_dim_cycle[kl_coef][i][n] ** 2)\n",
        "            if distance < best_model_distance:\n",
        "                best_model_distance = distance\n",
        "                best_model = best_models_saved[i]\n",
        "                where_model = (i,n)\n",
        "        # Save the best model  \n",
        "        coordinates = where_model\n",
        "        cycle = i\n",
        "        epoch = n\n",
        "        torch.save(best_model, f\"{lat_folder}/best_model_combined_distance.pth\")\n",
        "        print(f\"Best model saved based on TVD + normalized average transition value with cycle {i+1} and epoch {n+1}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TESTING OF MODELS AND INFERENCES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#FLAGS to determine testing\n",
        "plot_data = 1\n",
        "#what level do you want to plot\n",
        "level = 63\n",
        "CCDF = 1\n",
        "Bi_modal_distribution = 1\n",
        "single_step_profiles = 1\n",
        "#for the single_step_profiles\n",
        "NUM_SAMPLES = 5\n",
        "#what weights do you want to use?\n",
        "MODEL_PATH = r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_lat1024_at_2025-04-11 12:46:39.526973/model_at_0/checkpoint_3\"\n",
        "LEVEL = 63\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Load the data; shape = (300000, 2, 75)\n",
        "real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "predictions = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_lat1024_at_2025-04-11 12:46:39.526973/predictions_best_checkpoint_Finetuned_Resnet_VAE_1.npy\")\n",
        "\n",
        "#reshape the predictions so that it matches the real_data shape\n",
        "predictions = predictions.reshape(300000, 1, 75)\n",
        "print(predictions.shape)\n",
        "print(real_data.shape)\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S.%f\")\n",
        "folder = f\"testing_at_{timestamp}\"\n",
        "os.mkdir(folder)\n",
        "subfolders = ['timeseries', 'CCDF', 'bi_modal_distribution', 'single_step_profiles']\n",
        "# Create each subdirectory inside the main folder\n",
        "for subfolder in subfolders:\n",
        "    path = os.path.join(folder, subfolder)\n",
        "    os.mkdir(path)\n",
        "    print(f\"Created subfolder: {path}\")\n",
        "SAVE_DIR = os.path.join(folder, \"single_step_profiles\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "model = ConditionalVAE(latent_dim, output_dim, condition_dim)\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# MODIFY THIS LINE FOR MODEL TESTING\n",
        "model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_lat1024_at_2025-04-11 12:46:39.526973/model_at_0/checkpoint_3\"\n",
        "\n",
        "if os.path.exists(model_weights_path):\n",
        "    model.load_state_dict(torch.load(model_weights_path))\n",
        "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
        "    \n",
        "if (plot_data):\n",
        "    #note that the value 300000 will have to change depending on the real and predictions data length\n",
        "    u_profile_real = real_data[:300000, 1, level]  # Match time length with predictions\n",
        "    u_profile_pred = predictions[:, 0, level]\n",
        "    time_steps = np.arange(len(u_profile_pred))\n",
        "\n",
        "    # === Plot ===\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    plt.plot(time_steps, u_profile_real, label='Real Data', alpha=0.7)\n",
        "    plt.plot(time_steps, u_profile_pred, label='Predictions', linestyle='--')\n",
        "\n",
        "\n",
        "    # Labels, legend, and formatting\n",
        "    plt.xlabel('Time step')\n",
        "    plt.ylabel('U (m/s)')\n",
        "    plt.title(f'Time Series of U at Vertical Level {level}')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(folder, \"timeseries\")\n",
        "    save_path = os.path.join(save_path, \"real_prediction_plot\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "\n",
        "if (CCDF):\n",
        "    real_data_1d = real_data[:, 1, 63]  # Now shape is (309700,)\n",
        "    predictions_1d = predictions[:, 0, 63]  # shape (300000,)\n",
        "\n",
        "    # Define bounds (assuming they apply to both datasets)\n",
        "    upper_bound = 53.8 / 2.8935\n",
        "    lower_bound = 1.75 / 2.8935\n",
        "\n",
        "    # Function to calculate transition durations\n",
        "    def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "        times_between_transitions = []\n",
        "        transition_start = None\n",
        "        above_upper = False\n",
        "        below_lower = False\n",
        "\n",
        "        for i in range(1, len(y_values)):\n",
        "            if y_values[i] < lower_bound:  \n",
        "                below_lower = True\n",
        "                above_upper = False\n",
        "            elif y_values[i] > upper_bound:  \n",
        "                if below_lower and transition_start is not None:\n",
        "                    times_between_transitions.append(i - transition_start)\n",
        "                    transition_start = None  \n",
        "                above_upper = True\n",
        "                below_lower = False\n",
        "\n",
        "            if below_lower and transition_start is None:\n",
        "                transition_start = i\n",
        "\n",
        "        return times_between_transitions\n",
        "\n",
        "    # Compute transition durations for real data\n",
        "    real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "\n",
        "    # Compute transition durations for predictions data\n",
        "    pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "\n",
        "    # Plot setup\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # === REAL DATA CCDF AND FIT ===\n",
        "    if len(real_durations) == 0:\n",
        "        print(\"No transitions detected in real data with current bounds!\")\n",
        "    else:\n",
        "        real_data_sorted = np.sort(real_durations)\n",
        "        x_line_real = np.linspace(min(real_data_sorted), max(real_data_sorted), 100)\n",
        "        exponential_fit_real = 1/np.mean(real_data_sorted)\n",
        "        y_values_real = exponential_fit_real*x_line_real\n",
        "        plt.plot(x_line_real, y_values_real, 'b-', label=f'Real Exp Fit (slope={exponential_fit_real:.4f})', linewidth=2)\n",
        "\n",
        "    # === PREDICTIONS CCDF AND FIT ===\n",
        "    if len(pred_durations) == 0:\n",
        "        print(\"No transitions detected in predictions with current bounds!\")\n",
        "    else:\n",
        "        pred_data_sorted = np.sort(pred_durations)\n",
        "        x_line_pred = np.linspace(min(pred_data_sorted), max(pred_data_sorted), 100)\n",
        "        exponential_fit_pred = 1/np.mean(pred_data_sorted)\n",
        "        y_values_pred = exponential_fit_pred*x_line_pred\n",
        "        plt.plot(x_line_pred, y_values_pred, 'r-', label=f'Pred Exp Fit (slope={exponential_fit_pred:.4f})', linewidth=2)\n",
        "\n",
        "    print(1/np.mean(real_data_sorted))\n",
        "    print(1/np.mean(pred_data_sorted))\n",
        "    # Plot labels and formatting\n",
        "    plt.xlabel('Time Duration (Steps)')\n",
        "    plt.ylabel('CCDF')\n",
        "    plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "    plt.yscale(\"linear\")  # y-axis log scale\n",
        "    plt.xscale(\"linear\")  # x-axis linear scale\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(folder, \"CCDF\")\n",
        "    save_path = os.path.join(save_path, \"CCDF_plot\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "if (Bi_modal_distribution):\n",
        "    zonal_wind_data_real = real_data[:, 1, 63]  # variable index 1 (e.g., zonal wind), level 60\n",
        "    zonal_wind_data_predictions = predictions[:, 0, 63]  # variable index 0 (predictions), level 60\n",
        "\n",
        "    print(f\"Shape of zonal_wind_data_real: {zonal_wind_data_real.shape}\")\n",
        "    print(f\"Shape of zonal_wind_data_predictions: {zonal_wind_data_predictions.shape}\")\n",
        "\n",
        "    # Plot the bimodal histogram\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Create histograms (overlaid)\n",
        "    sns.histplot(zonal_wind_data_real, bins=50, kde=True, color='black', alpha=0.6, element='step', label='Real Data')\n",
        "    sns.histplot(zonal_wind_data_predictions, bins=50, kde=True, color='red', alpha=0.6, element='step', label='Predictions')\n",
        "\n",
        "    # Customize plot labels and title\n",
        "    plt.title('Distribution of Zonal Winds For Real Data and Predictions', fontsize=16)\n",
        "    plt.xlabel('Zonal Wind (m/s)', fontsize=14)\n",
        "    plt.ylabel('Frequency', fontsize=14)\n",
        "\n",
        "    # Add vertical lines at means\n",
        "    plt.axvline(np.mean(zonal_wind_data_real), color='black', linestyle='--', label=f'Real Mean: {np.mean(zonal_wind_data_real):.2f}')\n",
        "    plt.axvline(np.mean(zonal_wind_data_predictions), color='red', linestyle='--', label=f'Pred Mean: {np.mean(zonal_wind_data_predictions):.2f}')\n",
        "\n",
        "    # Final plot settings\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(folder, \"bi_modal_distribution\")\n",
        "    save_path = os.path.join(save_path, \"bi_modal_distribution_plot\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "if (single_step_profiles):\n",
        "    # Ensure save directory exists\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    # === Load model weights ===\n",
        "    model.load_state_dict(torch.load(MODEL_PATH))\n",
        "    model.eval()\n",
        "\n",
        "    # === Randomly sample time points from real data ===\n",
        "    time_indices = random.sample(range(0, real_data.shape[0] - 2), NUM_SAMPLES)\n",
        "    print(f\"Randomly sampled time steps: {time_indices}\")\n",
        "\n",
        "    # === Time series visualization ===\n",
        "    real_data_timeseries = real_data[:, 1, LEVEL]\n",
        "    time_steps_all = np.arange(len(real_data_timeseries))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(time_steps_all, real_data_timeseries, label=\"Real Data at Level 61\", color='blue')\n",
        "\n",
        "    # Mark sample points\n",
        "    for idx_num, idx in enumerate(time_indices):\n",
        "        plt.axvline(x=idx, color='green', linestyle='--', linewidth=2)\n",
        "    if len(time_indices) > 0:\n",
        "        plt.axvline(x=time_indices[0], color='green', linestyle='--', linewidth=2, label='Sampled Points')\n",
        "\n",
        "    plt.title(\"Real Data Time Series with Sampled Points Highlighted\")\n",
        "    plt.xlabel(\"Time Step\")\n",
        "    plt.ylabel(\"U (m/s) at Level 61\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_path = os.path.join(SAVE_DIR, \"real_data_timeseries_with_samples.png\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n",
        "\n",
        "    # === Iterate over each sampled time point ===\n",
        "    for i, time_step in enumerate(time_indices):\n",
        "        next_time_step = time_step + 1\n",
        "\n",
        "        # === Real data: current and next ===\n",
        "        real_current = real_data[time_step, 1, :]       \n",
        "        real_next = real_data[next_time_step, 1, :]      \n",
        "\n",
        "        # === Normalize real_current and make prediction for next step ===\n",
        "        initial_cond = torch.reshape(torch.tensor(psi[time_step,:]), [1, 75])\n",
        "        z = torch.zeros([1,latent_dim])\n",
        "        num_ens = 1\n",
        "        pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn_like(z)\n",
        "            print(z.shape, initial_cond.shape)\n",
        "            y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "\n",
        "        # === Denormalize predicted next ===\n",
        "        pred_next_denorm = y.squeeze() * std_psi.squeeze() + mean_psi.squeeze()\n",
        "\n",
        "        # === Extract U, Re(Psi), Im(Psi) components ===\n",
        "        # U profiles\n",
        "        U_current_real = real_current[51:74]\n",
        "        U_next_real = real_next[51:74]\n",
        "        U_next_pred = pred_next_denorm[51:74]\n",
        "\n",
        "        # Re(Psi) profiles\n",
        "        RePsi_current_real = real_current[0:24]\n",
        "        RePsi_next_real = real_next[0:24]\n",
        "        RePsi_next_pred = pred_next_denorm[0:24]\n",
        "\n",
        "        # Im(Psi) profiles\n",
        "        ImPsi_current_real = real_current[25:50]\n",
        "        ImPsi_next_real = real_next[25:50]\n",
        "        ImPsi_next_pred = pred_next_denorm[25:50]\n",
        "\n",
        "        # === Differences ===\n",
        "        U_diff_real = U_next_real - U_current_real\n",
        "        U_diff_pred = U_next_pred - U_current_real\n",
        "\n",
        "        RePsi_diff_real = RePsi_next_real - RePsi_current_real\n",
        "        RePsi_diff_pred = RePsi_next_pred - RePsi_current_real\n",
        "\n",
        "        ImPsi_diff_real = ImPsi_next_real - ImPsi_current_real\n",
        "        ImPsi_diff_pred = ImPsi_next_pred - ImPsi_current_real\n",
        "\n",
        "        # === Create a single figure with 3 rows (U, Re(Psi), Im(Psi)) ===\n",
        "        fig, axes = plt.subplots(3, 2, figsize=(16, 18))  # 3 rows, 2 columns (Profile and Difference)\n",
        "\n",
        "        z_levels_U = np.linspace(0, 70, 23)\n",
        "        z_levels_RePsi = np.linspace(0, 70, 24)\n",
        "        z_levels_ImPsi = np.linspace(0, 70, 25)\n",
        "\n",
        "        # --- U ---\n",
        "        axes[0, 0].plot(U_current_real, z_levels_U, 'x-', label=\"Real Current\")\n",
        "        axes[0, 0].plot(U_next_real, z_levels_U, 'd-', label=\"Real Next\")\n",
        "        axes[0, 0].plot(U_next_pred, z_levels_U, 's--', label=\"Predicted Next\")\n",
        "        axes[0, 0].set_title(f\"U Profiles @ Step {time_step}\")\n",
        "        axes[0, 0].set_xlabel(\"U (m/s)\")\n",
        "        axes[0, 0].set_ylabel(\"Vertical Levels (km)\")\n",
        "        axes[0, 0].legend()\n",
        "\n",
        "        axes[0, 1].plot(U_diff_real, z_levels_U, 'xb', label=\"Real  (Next - Current)\")\n",
        "        axes[0, 1].plot(U_diff_pred, z_levels_U, 'o--r', label=\"Pred  (Next - Current)\")\n",
        "        axes[0, 1].set_title(\"U Difference (Next - Current)\")\n",
        "        axes[0, 1].set_xlabel(\"U (m/s)\")\n",
        "        axes[0, 1].legend()\n",
        "\n",
        "        # --- Re(Psi) ---\n",
        "        axes[1, 0].plot(RePsi_current_real, z_levels_RePsi, 'x-', label=\"Real Current\")\n",
        "        axes[1, 0].plot(RePsi_next_real, z_levels_RePsi, 'd-', label=\"Real Next\")\n",
        "        axes[1, 0].plot(RePsi_next_pred, z_levels_RePsi, 's--', label=\"Predicted Next\")\n",
        "        axes[1, 0].set_title(f\"Re(Psi) Profiles @ Step {time_step}\")\n",
        "        axes[1, 0].set_xlabel(\"Re(Psi)\")\n",
        "        axes[1, 0].set_ylabel(\"Vertical Levels (km)\")\n",
        "        axes[1, 0].legend()\n",
        "\n",
        "        axes[1, 1].plot(RePsi_diff_real, z_levels_RePsi, 'xb', label=\"Real  (Next - Current)\")\n",
        "        axes[1, 1].plot(RePsi_diff_pred, z_levels_RePsi, 'o--r', label=\"Pred  (Next - Current)\")\n",
        "        axes[1, 1].set_title(\"Re(Psi) Difference (Next - Current)\")\n",
        "        axes[1, 1].set_xlabel(\"Re(Psi)\")\n",
        "        axes[1, 1].legend()\n",
        "\n",
        "        # --- Im(Psi) ---\n",
        "        axes[2, 0].plot(ImPsi_current_real, z_levels_ImPsi, 'x-', label=\"Real Current\")\n",
        "        axes[2, 0].plot(ImPsi_next_real, z_levels_ImPsi, 'd-', label=\"Real Next\")\n",
        "        axes[2, 0].plot(ImPsi_next_pred, z_levels_ImPsi, 's--', label=\"Predicted Next\")\n",
        "        axes[2, 0].set_title(f\"Im(Psi) Profiles @ Step {time_step}\")\n",
        "        axes[2, 0].set_xlabel(\"Im(Psi)\")\n",
        "        axes[2, 0].set_ylabel(\"Vertical Levels (km)\")\n",
        "        axes[2, 0].legend()\n",
        "\n",
        "        axes[2, 1].plot(ImPsi_diff_real, z_levels_ImPsi, 'xb', label=\"Real  (Next - Current)\")\n",
        "        axes[2, 1].plot(ImPsi_diff_pred, z_levels_ImPsi, 'o--r', label=\"Pred  (Next - Current)\")\n",
        "        axes[2, 1].set_title(\"Im(Psi) Difference (Next - Current)\")\n",
        "        axes[2, 1].set_xlabel(\"Im(Psi)\")\n",
        "        axes[2, 1].legend()\n",
        "\n",
        "        # === Finalize and Save ===\n",
        "        plt.suptitle(f\"Single Step Profile Comparisons at Time Step {time_step}\", fontsize=18)\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "\n",
        "        save_path = os.path.join(SAVE_DIR, f\"Profile_Summary_point_{time_step}.png\")\n",
        "        plt.savefig(save_path)\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Combined plot saved for sampled point {time_step}\")\n",
        "\n",
        "    # Final debug\n",
        "    print(\"Finished processing all sampled points.\")\n",
        "        # Debugging prints\n",
        "    print(predictions.shape) \n",
        "    print(real_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EXPERIMENTAL (AVG CCDFs WITH ERROR BARS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CCDF Error bars\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "import seaborn as sns\n",
        "\n",
        "CCDF_sum = 0\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "num_ccdfs = 10\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = ConditionalVAE(latent_dim, output_dim, condition_dim)\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# MODIFY THIS LINE FOR MODEL TESTING\n",
        "model_weights_path = \"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/training_cycles/resnet/Resnet_VAE_model_at_2025-03-25 16:07:01.635719/checkpoint_4_promising\"\n",
        "\n",
        "if os.path.exists(model_weights_path):\n",
        "    model.load_state_dict(torch.load(model_weights_path))\n",
        "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
        "    \n",
        "for i in range(0, num_ccdfs):\n",
        "    # Inference\n",
        "    initial_cond = torch.reshape(torch.tensor(psi[0,:]), [1, 75])\n",
        "    time_step = 300000\n",
        "    z = torch.zeros([1,latent_dim])\n",
        "    num_ens = 1\n",
        "    pred = np.zeros ([time_step, 75, num_ens])\n",
        "\n",
        "    for k in range (0, time_step):\n",
        "\n",
        "        for ens in range (0, num_ens):\n",
        "            if (k ==0):\n",
        "\n",
        "                z = torch.randn_like(z)\n",
        "                print(z.shape, initial_cond.shape)\n",
        "                y = (model.decode(z.float().cuda(),initial_cond.float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:,ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "            else:\n",
        "                select_ens = np.random.randint(0,num_ens,1)\n",
        "                z = torch.randn_like(z)\n",
        "                y = (model.decode(z.float().cuda(),torch.reshape(torch.tensor(pred[k-1,:,select_ens]),[1,75]).float().cuda())).detach().cpu().numpy()\n",
        "                pred[k,:, ens] = y\n",
        "                y_denorm = (y * std_psi[:, :] + mean_psi[:, :])\n",
        "                initial_cond = torch.tensor((y_denorm - mean_psi[:, :]) / std_psi[:, :])\n",
        "\n",
        "    # Denormalize final preds\n",
        "    print(std_psi[:, 63])\n",
        "    pred_mean = pred * std_psi[:, 63] + mean_psi[:, 63]\n",
        "\n",
        "    # Denormalize test labels\n",
        "    actual_values = psi[:time_step, 63] * std_psi[:, 63] + mean_psi[:, 63]\n",
        "    print(actual_values)\n",
        "\n",
        "    # Load the data; shape = (300000, 2, 75)\n",
        "    real_data = np.load(r\"/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/data/actual/long_run_310k.npy\")\n",
        "    predictions = pred_mean.reshape(300000, 1, 75)\n",
        "\n",
        "    if (CCDF):\n",
        "        real_data_1d = real_data[:, 1, 61]  # Now shape is (309700,)\n",
        "        predictions_1d = predictions[:, 0, 61]  # shape (300000,)\n",
        "\n",
        "        # Define bounds (assuming they apply to both datasets)\n",
        "        upper_bound = 53.8 / 2.8935\n",
        "        lower_bound = 1.75 / 2.8935\n",
        "\n",
        "        # Function to calculate transition durations\n",
        "        def calculate_transition_durations(y_values, upper_bound, lower_bound):\n",
        "            times_between_transitions = []\n",
        "            transition_start = None\n",
        "            above_upper = False\n",
        "            below_lower = False\n",
        "\n",
        "            for i in range(1, len(y_values)):\n",
        "                if y_values[i] < lower_bound:  \n",
        "                    below_lower = True\n",
        "                    above_upper = False\n",
        "                elif y_values[i] > upper_bound:  \n",
        "                    if below_lower and transition_start is not None:\n",
        "                        times_between_transitions.append(i - transition_start)\n",
        "                        transition_start = None  \n",
        "                    above_upper = True\n",
        "                    below_lower = False\n",
        "\n",
        "                if below_lower and transition_start is None:\n",
        "                    transition_start = i\n",
        "\n",
        "            return times_between_transitions\n",
        "\n",
        "        # Compute transition durations for real data\n",
        "        real_durations = calculate_transition_durations(real_data_1d, upper_bound, lower_bound)\n",
        "\n",
        "        # Compute transition durations for predictions data\n",
        "        pred_durations = calculate_transition_durations(predictions_1d, upper_bound, lower_bound)\n",
        "\n",
        "        # Plot setup\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        # === REAL DATA CCDF AND FIT ===\n",
        "        if len(real_durations) == 0:\n",
        "            print(\"No transitions detected in real data with current bounds!\")\n",
        "        else:\n",
        "            real_data_sorted = np.sort(real_durations)\n",
        "            x_line_real = np.linspace(min(real_data_sorted), max(real_data_sorted), 100)\n",
        "            exponential_fit_real = 1/np.mean(real_data_sorted)\n",
        "            y_values_real = exponential_fit_real*x_line_real\n",
        "            plt.plot(x_line_real, y_values_real, 'b-', label=f'Real Exp Fit (slope={exponential_fit_real:.4f})', linewidth=2)\n",
        "\n",
        "        # === PREDICTIONS CCDF AND FIT ===\n",
        "        if len(pred_durations) == 0:\n",
        "            print(\"No transitions detected in predictions with current bounds!\")\n",
        "        else:\n",
        "            pred_data_sorted = np.sort(pred_durations)\n",
        "            x_line_pred = np.linspace(min(pred_data_sorted), max(pred_data_sorted), 100)\n",
        "            exponential_fit_pred = 1/np.mean(pred_data_sorted)\n",
        "            y_values_pred = exponential_fit_pred*x_line_pred\n",
        "            plt.plot(x_line_pred, y_values_pred, 'r-', label=f'Pred Exp Fit (slope={exponential_fit_pred:.4f})', linewidth=2)\n",
        "\n",
        "        # Plot labels and formatting\n",
        "        plt.xlabel('Time Duration (Steps)')\n",
        "        plt.ylabel('CCDF')\n",
        "        plt.title('CCDF of Time Between B->A and A->B Transitions (Exponential Fit)')\n",
        "        plt.yscale(\"linear\")  # y-axis log scale\n",
        "        plt.xscale(\"linear\")  # x-axis linear scale\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(folder, \"CCDF\")\n",
        "        save_path = os.path.join(save_path, \"CCDF_plot\")\n",
        "        plt.savefig(save_path)\n",
        "        plt.show()\n",
        "\n",
        "CCDF_avg = CCDF_sum/num_ccdfs\n",
        "print(CCDF_avg)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
