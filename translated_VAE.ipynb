{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# GPU initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model hyperparameters\n",
    "latent_dim = 512\n",
    "model_weights_path = f'model_weights_pytorch{datetime.datetime.now()}.pth'  # Changed extension for PyTorch\n",
    "\n",
    "# Custom callback equivalent for prediction evolution\n",
    "class PredictionTracker:\n",
    "    def __init__(self, encoder_model, decoder_model, initial_point, test_time, mean_psi, std_psi, actual_values, zonal_wind_idx=63):\n",
    "        self.encoder_model = encoder_model\n",
    "        self.decoder_model = decoder_model\n",
    "        self.initial_point = initial_point.clone()  # Use clone() instead of copy() for PyTorch tensors\n",
    "        self.test_time = test_time\n",
    "        print(f\"Debug: self.test_time = {self.test_time}\")\n",
    "        self.mean_psi = mean_psi\n",
    "        self.std_psi = std_psi\n",
    "        self.predictions_history = []\n",
    "        self.actual_values = actual_values\n",
    "        self.zonal_wind_idx = zonal_wind_idx\n",
    "        \n",
    "    def on_epoch_end(self, epoch, train_loss, val_loss):\n",
    "        print(f\"Epoch {epoch + 1}: Loss = {train_loss:.6f}, Validation Loss = {val_loss:.6f}\")\n",
    "        \n",
    "        # Set models to evaluation mode\n",
    "        self.encoder_model.eval()\n",
    "        self.decoder_model.eval()\n",
    "        \n",
    "        pred_mean = np.zeros((self.test_time, 75, 1))\n",
    "        initial = self.initial_point.clone()\n",
    "        \n",
    "        # No gradient tracking needed for inference\n",
    "        with torch.no_grad():\n",
    "            # Add labeled progress bar\n",
    "            for k in tqdm(range(self.test_time), desc=f\"Epoch {epoch + 1} Prediction Progress\"):\n",
    "                try:\n",
    "                    # Get latent encoding\n",
    "                    mu, log_var = self.encoder_model(initial)\n",
    "                    z = self.reparameterize(mu, log_var)\n",
    "                    \n",
    "                    # Decode\n",
    "                    pred_ens = self.decoder_model(z)\n",
    "                    \n",
    "                    pred_step = pred_ens.cpu().numpy().reshape(75, 1)\n",
    "                    pred_mean[k, :, :] = pred_step\n",
    "                    \n",
    "                    # Denormalize prediction (PyTorch version of the TF code)\n",
    "                    pred_denorm = (pred_step.squeeze() * self.std_psi.cpu().numpy() + \n",
    "                                   self.mean_psi.cpu().numpy()).reshape(1, 75, 1)\n",
    "                    \n",
    "                    # Normalize again for next input\n",
    "                    initial = torch.tensor(\n",
    "                        (pred_denorm - self.mean_psi.cpu().numpy().reshape(1, -1, 1)) / \n",
    "                        self.std_psi.cpu().numpy().reshape(1, -1, 1),\n",
    "                        dtype=torch.float32\n",
    "                    ).to(device)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error during prediction at step {k}: {e}\")\n",
    "                    break\n",
    "        \n",
    "        # Denormalize final predictions\n",
    "        pred_mean = pred_mean.squeeze() * self.std_psi.cpu().numpy().reshape(1, -1) + self.mean_psi.cpu().numpy().reshape(1, -1)\n",
    "        pred_mean = pred_mean.reshape(self.test_time, 75, 1)\n",
    "        self.predictions_history.append(pred_mean)\n",
    "        \n",
    "        # Save predictions and plot\n",
    "        np.save(f'predictions_epoch_{epoch+1}.npy', pred_mean)\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.plot(self.actual_values[:, self.zonal_wind_idx], 'b-', label='Actual', linewidth=2)\n",
    "        plt.plot(pred_mean[:, self.zonal_wind_idx], 'r--', label=f'Predicted', linewidth=2)\n",
    "        plt.title(f'Predictions vs Actual at Epoch {epoch+1}')\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Zonal Wind Speed')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'prediction_epoch_{epoch+1}.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Return models to training mode\n",
    "        self.encoder_model.train()\n",
    "        self.decoder_model.train()\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from N(0,1).\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "def plot_prediction_evolution(predictions_history, actual_values, zonal_wind_idx=63):\n",
    "    n_epochs = len(predictions_history)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(actual_values[:, zonal_wind_idx], 'k-', label='Actual', linewidth=2)\n",
    "    \n",
    "    for i, pred in enumerate(predictions_history):\n",
    "        alpha = (i + 1) / n_epochs\n",
    "        plt.plot(pred[:, zonal_wind_idx], alpha=alpha, \n",
    "                label=f'Epoch {i+1}', linestyle='--')\n",
    "    \n",
    "    plt.title(f'Evolution of Predictions at Index {zonal_wind_idx}')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Zonal Wind Speed')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('prediction_evolution.png')\n",
    "    plt.show()\n",
    "\n",
    "# Define PyTorch VAE model classes\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # Convolutional layers with pooling (equivalent to TF model)\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, padding=1) \n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        \n",
    "        # Calculate flattened size - original shape is (75, 1)\n",
    "        # After 3 pooling layers: 75 -> 38 -> 19 -> 9 (slightly different from TF due to PyTorch pooling)\n",
    "        self.flattened_size = 9 * 64\n",
    "        \n",
    "        # Latent space\n",
    "        self.fc_mu = nn.Linear(self.flattened_size, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.flattened_size, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # PyTorch expects [batch_size, channels, length] for Conv1d\n",
    "        # So we need to permute from [batch_size, length, channels]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # Apply convolution and pooling layers with ReLU activations\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Get latent parameters\n",
    "        mu = self.fc_mu(x)\n",
    "        log_var = self.fc_logvar(x)\n",
    "        \n",
    "        return mu, log_var\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # First reshape from latent space to match encoder's flattened shape\n",
    "        self.latent_to_features = nn.Linear(latent_dim, 10 * 64)\n",
    "        \n",
    "        # Transpose convolutions (equivalent to upsampling + conv in TensorFlow)\n",
    "        self.tconv1 = nn.ConvTranspose1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2)\n",
    "        self.tconv2 = nn.ConvTranspose1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2) \n",
    "        self.tconv3 = nn.ConvTranspose1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.upsample3 = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.tconv_final = nn.ConvTranspose1d(64, 1, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # Reshape from latent dimension\n",
    "        x = torch.relu(self.latent_to_features(z))\n",
    "        x = x.view(-1, 64, 10)  # Reshape to [batch, channels, length]\n",
    "        \n",
    "        # Apply transpose convolutions with upsampling\n",
    "        x = torch.relu(self.tconv1(x))\n",
    "        x = self.upsample1(x)\n",
    "        x = torch.relu(self.tconv2(x))\n",
    "        x = self.upsample2(x)\n",
    "        x = torch.relu(self.tconv3(x))\n",
    "        x = self.upsample3(x)\n",
    "        \n",
    "        # Final layer and crop to match input shape (75, 1)\n",
    "        x = self.tconv_final(x)\n",
    "        x = x[:, :, :75]  # Crop to ensure correct output size\n",
    "        \n",
    "        # Convert back to [batch, length, channels] format\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from N(0,1).\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, log_var\n",
    "    \n",
    "    def loss_function(self, recon_x, x, mu, log_var, beta=5):\n",
    "        \"\"\"\n",
    "        Calculates VAE loss = reconstruction loss + KL divergence loss\n",
    "        \"\"\"\n",
    "        # Reconstruction loss (MSE)\n",
    "        recon_loss = torch.nn.functional.mse_loss(recon_x, x, reduction='mean')\n",
    "        \n",
    "        # KL divergence loss\n",
    "        kl_loss = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Total loss with beta weighting for KL term\n",
    "        return recon_loss + beta * kl_loss, recon_loss, kl_loss\n",
    "\n",
    "# Load and preprocess data (similar to TF code)\n",
    "F = np.load('/home/constantino-daniel-boscu/Documents/research/AI-RES/modified-code-main3/x_stoch.npy')\n",
    "psi = F[3500:, 0, :]\n",
    "\n",
    "# Normalize data\n",
    "mean_psi = np.mean(psi, axis=0, keepdims=True)\n",
    "std_psi = np.std(psi, axis=0, keepdims=True)\n",
    "std_psi = np.maximum(std_psi, 1e-8) # Stop gradient explosion\n",
    "psi = (psi - mean_psi) / std_psi\n",
    "\n",
    "# Data preparation (same as TF code)\n",
    "train_size = 220000\n",
    "val_size = 50000\n",
    "test_time = 20000\n",
    "lead = 1\n",
    "\n",
    "# Define indices for splitting\n",
    "train_end = train_size\n",
    "val_start = train_end\n",
    "val_end = val_start + val_size\n",
    "\n",
    "# Training data\n",
    "psi_input_Tr = psi[:train_end, :].reshape(-1, 75, 1)\n",
    "psi_label_Tr = psi[:train_end, :].reshape(-1, 75, 1)\n",
    "\n",
    "# Validation data\n",
    "psi_input_val = psi[val_start:val_end, :].reshape(-1, 75, 1)\n",
    "psi_label_val = psi[val_start + lead:val_end + lead, :].reshape(-1, 75, 1)\n",
    "\n",
    "# Test set size (10% of the dataset)\n",
    "test_size = int(0.1 * psi.shape[0])\n",
    "\n",
    "# Define test inputs and labels\n",
    "psi_test_input = psi[val_end:val_end + test_size, :].reshape(-1, 75, 1)\n",
    "psi_test_label = psi[val_end + lead:val_end + lead + test_size, :].reshape(-1, 75, 1)\n",
    "\n",
    "# Define initial point for inference\n",
    "initial_point = psi[val_end, :].reshape(1, 75, 1)\n",
    "\n",
    "# Actual values corresponding to the test set for plotting\n",
    "actual_values = (psi_test_label[:test_time, :, :].squeeze() * std_psi + mean_psi)\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(f\"Shape of psi: {psi.shape}\")\n",
    "print(f\"Train input shape: {psi_input_Tr.shape}\")\n",
    "print(f\"Train label shape: {psi_label_Tr.shape}\")\n",
    "print(f\"Validation input shape: {psi_input_val.shape}\")\n",
    "print(f\"Validation label shape: {psi_label_val.shape}\")\n",
    "print(f\"Test input shape: {psi_test_input.shape}\")\n",
    "print(f\"Test label shape: {psi_test_label.shape}\")\n",
    "print(f\"Initial point shape: {initial_point.shape}\")\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "psi_input_Tr_tensor = torch.FloatTensor(psi_input_Tr).to(device)\n",
    "psi_label_Tr_tensor = torch.FloatTensor(psi_label_Tr).to(device)\n",
    "psi_input_val_tensor = torch.FloatTensor(psi_input_val).to(device)\n",
    "psi_label_val_tensor = torch.FloatTensor(psi_label_val).to(device)\n",
    "psi_test_input_tensor = torch.FloatTensor(psi_test_input).to(device)\n",
    "psi_test_label_tensor = torch.FloatTensor(psi_test_label).to(device)\n",
    "initial_point_tensor = torch.FloatTensor(initial_point).to(device)\n",
    "\n",
    "# Create data loaders for batched training\n",
    "train_dataset = TensorDataset(psi_input_Tr_tensor, psi_label_Tr_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "# Create validation dataset\n",
    "val_dataset = TensorDataset(psi_input_val_tensor, psi_label_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "# Convert mean and std to tensors\n",
    "mean_psi_tensor = torch.FloatTensor(mean_psi).to(device)\n",
    "std_psi_tensor = torch.FloatTensor(std_psi).to(device)\n",
    "\n",
    "# Initialize the model\n",
    "vae = VAE(latent_dim).to(device)\n",
    "optimizer = optim.Adam(vae.parameters())\n",
    "torch.nn.utils.clip_grad_norm_(vae.parameters(), max_norm=1.0)\n",
    "\n",
    "# Setup for early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "\n",
    "# Create prediction tracker (equivalent to TF callback)\n",
    "pred_tracker = PredictionTracker(\n",
    "    vae.encoder, \n",
    "    vae.decoder, \n",
    "    initial_point_tensor, \n",
    "    test_time, \n",
    "    mean_psi_tensor, \n",
    "    std_psi_tensor, \n",
    "    actual_values, \n",
    "    zonal_wind_idx=63\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "def train_epoch(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    recon_loss_sum = 0\n",
    "    kl_loss_sum = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\")):\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, log_var = model(data)\n",
    "        loss, recon_loss, kl_loss = model.loss_function(recon_batch, target, mu, log_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        recon_loss_sum += recon_loss.item()\n",
    "        kl_loss_sum += kl_loss.item()\n",
    "    \n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    avg_recon_loss = recon_loss_sum / len(train_loader)\n",
    "    avg_kl_loss = kl_loss_sum / len(train_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {avg_loss:.6f}, Recon Loss = {avg_recon_loss:.6f}, KL Loss = {avg_kl_loss:.6f}\")\n",
    "    return avg_loss\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(val_loader, desc=\"Validation\"):\n",
    "            recon_batch, mu, log_var = model(data)\n",
    "            loss, _, _ = model.loss_function(recon_batch, target, mu, log_var)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Validation Loss = {avg_val_loss:.6f}\")\n",
    "    return avg_val_loss\n",
    "\n",
    "# Training process\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "num_epochs = 6  # Same as in the TF code\n",
    "\n",
    "# Check if pre-trained weights exist\n",
    "if os.path.exists(model_weights_path):\n",
    "    vae.load_state_dict(torch.load(model_weights_path, weights_only=True))\n",
    "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
    "else:\n",
    "    print(f\"No pre-trained weights found. Training model...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train for one epoch\n",
    "        train_loss = train_epoch(vae, train_loader, optimizer, epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss = validate(vae, val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Run prediction tracking (like the TF callback)\n",
    "        pred_tracker.on_epoch_end(epoch, train_loss, val_loss)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(vae.state_dict(), model_weights_path)\n",
    "            print(f\"Model weights saved to {model_weights_path}.\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    # Save loss history for plotting\n",
    "    np.save('train_loss.npy', np.array(train_losses))\n",
    "    np.save('val_loss.npy', np.array(val_losses))\n",
    "\n",
    "# Plot prediction evolution if predictions were tracked\n",
    "if pred_tracker.predictions_history:\n",
    "    plot_prediction_evolution(pred_tracker.predictions_history, actual_values, 63)\n",
    "\n",
    "# Inference\n",
    "print(\"\\nStarting inference...\")\n",
    "pred_mean = np.zeros((test_time, 75, 1))\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "vae.eval()\n",
    "\n",
    "# Ensure correct shape of std_psi and mean_psi tensors\n",
    "std_psi_tensor = std_psi_tensor.view(1, 75)\n",
    "mean_psi_tensor = mean_psi_tensor.view(1, 75)\n",
    "\n",
    "with torch.amp.autocast(\"cuda\"):\n",
    "    with torch.no_grad():\n",
    "        current_input = initial_point_tensor.clone()\n",
    "        \n",
    "        # Inference loop with proper normalization\n",
    "        for k in tqdm(range(test_time), desc=\"Inference Progress\"):\n",
    "            # Get latent encoding\n",
    "            mu, log_var = vae.encoder(current_input)\n",
    "            z = vae.reparameterize(mu, log_var)\n",
    "            \n",
    "            # Decode\n",
    "            pred_step = vae.decoder(z)\n",
    "            pred_mean[k, :, :] = pred_step.cpu().numpy()\n",
    "            # Denormalize current prediction before using as next input\n",
    "            pred_denorm = (pred_step.squeeze().cpu().numpy() * std_psi.squeeze() + mean_psi.squeeze()).reshape(1, 75, 1)\n",
    "            \n",
    "            # Normalize again for next input\n",
    "            current_input = torch.tensor(\n",
    "                (pred_denorm - mean_psi.reshape(1, -1, 1)) / std_psi.reshape(1, -1, 1),\n",
    "                dtype=torch.float32\n",
    "            ).to(device)\n",
    "\n",
    "# Denormalize final predictions\n",
    "pred_mean = pred_mean.squeeze() * std_psi.reshape(1, -1) + mean_psi.reshape(1, -1)\n",
    "pred_mean = pred_mean.reshape(test_time, 75, 1)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "pred_flat = pred_mean.reshape(test_time, 75)\n",
    "actual_flat = actual_values\n",
    "mse_value = mean_squared_error(actual_flat, pred_flat)\n",
    "print(f\"\\nMean Squared Error: {mse_value}\")\n",
    "\n",
    "# Plot predictions vs actual for specific index\n",
    "zonal_wind_idx = 63\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(actual_values[:, zonal_wind_idx], label=\"Actual\", color=\"blue\")\n",
    "plt.plot(pred_mean[:, zonal_wind_idx], label=\"Predicted\", linestyle=\"dashed\", color=\"red\")\n",
    "plt.title(\"Predictions vs Actual Values\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Zonal Wind Speed\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('predictions_vs_actual.png')\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "torch.save({\n",
    "    'predictions': torch.tensor(pred_mean),\n",
    "    'mean_psi': mean_psi_tensor.cpu(),\n",
    "    'std_psi': std_psi_tensor.cpu(),\n",
    "    'actual_values': torch.tensor(actual_values)\n",
    "}, 'model_results.pt')\n",
    "\n",
    "# Plot training history if available\n",
    "try:\n",
    "    train_loss = np.load('train_loss.npy')\n",
    "    val_loss = np.load('val_loss.npy')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss vs Epochs')\n",
    "    plt.savefig('loss_plot.png')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not load or plot training history: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate inference\n",
    "\n",
    "Modify \"test_time\" based on the amount of time steps required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = \"model_weights_pytorch2025-03-16 22:17:48.397214.pth\"\n",
    "\n",
    "test_time = 100000\n",
    "\n",
    "if os.path.exists(model_weights_path):\n",
    "    vae.load_state_dict(torch.load(model_weights_path, weights_only=True))\n",
    "    print(f\"Model weights loaded from {model_weights_path}.\")\n",
    "\n",
    "# Inference\n",
    "print(\"\\nStarting inference...\")\n",
    "pred_mean = np.zeros((test_time, 75, 1))\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "vae.eval()\n",
    "initial_point = psi[0, :].reshape(1, 75, 1)\n",
    "initial_point_tensor = torch.FloatTensor(initial_point).to(device)\n",
    "psi_test_label = psi[:, :].reshape(-1, 75, 1)\n",
    "print(psi_test_label[:test_time, :, :].shape)\n",
    "actual_values = (psi_test_label[:test_time, :, :].squeeze() * std_psi + mean_psi)\n",
    "print(actual_values.shape)\n",
    "# Ensure correct shape of std_psi and mean_psi tensors\n",
    "std_psi_tensor = std_psi_tensor.view(1, 75)\n",
    "mean_psi_tensor = mean_psi_tensor.view(1, 75)\n",
    "\n",
    "with torch.amp.autocast(\"cuda\"):\n",
    "# No gradient tracking needed for inference\n",
    "    with torch.no_grad():\n",
    "        # Set initial point\n",
    "        current_input = initial_point_tensor.clone()\n",
    "        \n",
    "        # Inference loop with proper normalization\n",
    "        for k in tqdm(range(test_time), desc=\"Inference Progress\"):\n",
    "            # Get latent encoding\n",
    "            mu, log_var = vae.encoder(current_input)\n",
    "            z = vae.reparameterize(mu, log_var)\n",
    "            \n",
    "            # Decode\n",
    "            pred_step = vae.decoder(z)\n",
    "            if torch.isnan(pred_step).any():\n",
    "                print(f\"NaN detected at step {k}\")\n",
    "                print(f\"mu values: {mu}\")\n",
    "                print(f\"log_var values: {log_var}\")\n",
    "                print(f\"z values: {z}\")\n",
    "                break\n",
    "            pred_mean[k, :, :] = pred_step.cpu().numpy()\n",
    "            # Denormalize current prediction before using as next input\n",
    "            pred_denorm = (pred_step.squeeze().cpu().numpy() * std_psi.squeeze() + mean_psi.squeeze()).reshape(1, 75, 1)\n",
    "            \n",
    "            # Normalize again for next input\n",
    "            current_input = torch.tensor(\n",
    "                (pred_denorm - mean_psi.reshape(1, -1, 1)) / std_psi.reshape(1, -1, 1),\n",
    "                dtype=torch.float32\n",
    "            ).to(device)\n",
    "\n",
    "# Denormalize final predictions\n",
    "pred_mean = pred_mean.squeeze() * std_psi.reshape(1, -1) + mean_psi.reshape(1, -1)\n",
    "pred_mean = pred_mean.reshape(test_time, 75, 1)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "pred_flat = pred_mean.reshape(test_time, 75)\n",
    "actual_flat = actual_values\n",
    "mse_value = mean_squared_error(actual_flat, pred_flat)\n",
    "print(f\"\\nMean Squared Error: {mse_value}\")\n",
    "\n",
    "# Plot predictions vs actual for specific index\n",
    "zonal_wind_idx = 63\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(actual_values[:, zonal_wind_idx], label=\"Actual\", color=\"blue\")\n",
    "plt.plot(pred_mean[:, zonal_wind_idx], label=\"Predicted\", linestyle=\"dashed\", color=\"red\")\n",
    "plt.title(\"Predictions vs Actual Values\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Zonal Wind Speed\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('predictions_vs_actual.png')\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "torch.save({\n",
    "    'predictions': torch.tensor(pred_mean),\n",
    "    'mean_psi': mean_psi_tensor.cpu(),\n",
    "    'std_psi': std_psi_tensor.cpu(),\n",
    "    'actual_values': torch.tensor(actual_values)\n",
    "}, 'model_results.pt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
